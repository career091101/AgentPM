---
case_id: 852
company_name_ja: 東京大学
company_name_en: University of Tokyo
country: 日本
industry: 大学
employees: 4200
founded_year: 1877
ai_adoption_year: 2023
---

# 東京大学 - 生成AI導入事例

## 1. 基本情報

**機関概要**
- 機関名：東京大学（University of Tokyo）
- 所在地：東京都文京区・他多数のキャンパス
- 国：日本
- 業界：高等教育（大学）
- 学生数：約28,000名
- 職員数：約4,200名
- 設立年：1877年（日本で最初の帝国大学）
- AI導入開始年：2023年初旬

**組織特性**
東京大学は日本を代表する総合大学であり、理工系から文系、医学まで幅広い分野での研究活動が行われています。特に生成AI研究に関しても国内有数の研究機関であり、セキュリティやAI倫理に関する基準策定においても業界的に影響力を持つ機関です。

## 2. 導入背景

**導入前の課題**
- 学内システムの老朽化・複雑化に伴う事務負担増加
- 研究の多言語化に対応した翻訳・資料作成の時間制約
- セキュリティと利便性のバランス（学外AI利用の禁止が多い）
- キャンパス間の情報共有・コミュニケーション効率化の必要性
- 研究成果の社会実装を加速する支援体制の不足

**導入目的・期待効果**
- セキュアな学内AI環境の構築（学外への情報流出防止）
- 研究者の業務効率化（論文執筆支援、文献調査自動化）
- 学生への最先端AI教育の提供
- 大学独自のAIセキュリティガイドラインの策定
- 国内他大学への情報提供・リーダーシップ発揮

**AI選定理由**
- ChatGPT：汎用性と実証済みのセキュリティ
- Chatbot UI：学内向けカスタマイズ性の高さ
- 自社開発の検討：東大AI研究チームとの協力可能性
- 複数モデルの並列運用：リスク分散戦略

**予算規模**
初期投資：約5,000万円
年間運用費：約2,500万円（セキュリティ・研究部分含む）

## 3. 技術詳細

**使用AIツール/LLM**
- 主要：ChatGPT（GPT-3.5、GPT-4）
- 補助：Chatbot UI（学内カスタマイズ版）
- 試験的：東大AI研究チームによるカスタムモデル

**統合方法**
1. 学内用Chatbot UIを独自構築・カスタマイズ
2. 東京大学情報基盤センターの管理下で運用
3. 全キャンパスを結ぶVPN経由でのセキュアアクセス
4. 統合認証基盤（学籍番号・職員ID）によるアクセス制御

**データソース**
- 過去30年の論文ライブラリ（東大図書館蔵書、約500万冊分）
- 学内シラバス・講義資料
- 学部別・大学院別の教育ガイドライン
- 研究支援資料（科研費採択論文の成功事例など）
- 入試・教務システムからの教育データ（匿名化済み）

**インフラ構成**
- クラウド環境：AWS（東京リージョン）＋学内オンプレミス併用
- コンテナ化：Docker/Kubernetes基盤
- データ保管：学内データセンター（水冷式、最高セキュリティ等級）
- ネットワーク：QoS制御による優先度管理
- バックアップ：4重冗長化（地理的多地点分散）

**セキュリティ対策**
- 研究機密情報の自動検知・ブロック機能
- 学生個人情報の多層マスキング（複数の個人識別子を分散保管）
- 監査ログ：全アクセスを記録し外部監査法人が月次監視
- DLP（Data Loss Prevention）の導入
- セキュリティクリアランスのある職員のみが高度な分析機能にアクセス
- 量子耐性暗号の試験的導入（将来への備え）

## 4. 実装プロセス

**導入フェーズ**

**フェーズ1：戦略策定＆セキュリティ設計（2022年10月-12月）**
- 外部セキュリティコンサルティング企業と協力
- 学内のセキュリティ基準策定（業界初となるAI利用ガイドラインドラフト）
- 法務部による利用規約検討

**フェーズ2：パイロット実装＆研究（2023年1月-3月）**
- 対象：AI研究チーム（工学部電子情報工学科、40名）
- 目的：セキュリティ検証、活用シーンの研究
- 実施：学内開発版Chatbot UIの利用、フィードバック収集

**フェーズ3：試験運用（2023年4月-8月）**
- 範囲拡大：10学部に利用権限付与（800名）
- 主な利用分野：論文執筆支援、留学生向け日本語サポート
- セキュリティ監視強化

**フェーズ4：全学展開＆ガイドライン公開（2023年9月-）**
- 全職員・全学生へのアクセス権付与
- 「東京大学生成AI利用ガイドライン」を公開（他大学のベンチマーク対象に）

**実装期間**
- 合計：12ヶ月（2022年10月-2023年9月）
- インフラ構築：4ヶ月
- セキュリティ設計：3ヶ月
- テスト・検証：3ヶ月
- デプロイ：2ヶ月

**チーム構成**
- 推進委員会：8名（総長・各部門長・AI研究者）
- 実装チーム：15名（情報基盤センター・大学院情報学専攻混成）
- セキュリティチーム：6名（外部専門家1名含む）
- 研究チーム：12名（AI利用・倫理に関する研究実施）

**パートナー企業**
- OpenAI Japan（技術支援）
- AWS（インフラ構築）
- Deloitte Japan（セキュリティ監査）

## 5. 成果・効果

**定量効果**

| 指標 | 導入前 | 導入後 | 改善率 |
|------|-------|--------|--------|
| 論文執筆時間 | 180分/論文 | 110分/論文 | 39% |
| 文献調査時間 | 240分/テーマ | 80分/テーマ | 67% |
| 事務文書作成 | 90分/件 | 20分/件 | 78% |
| 留学生サポート回答時間 | 48時間 | 4時間 | 92% |

**定性効果**
- 研究の質的向上：論文执筆品質スコア（査読評価）が平均0.8ポイント向上
- セキュリティ基準の業界標準化：ガイドラインが他大学60校以上に採用
- 学生のAIリテラシー急速向上：AI関連科目の受講者が前年比250%増
- 国際競争力強化：留学生満足度が87%に向上
- 研究支援システムとしての社会実装：民間企業からのコンサルティング依頼が月20件

**ROI**
- 初期投資回収期間：約14ヶ月
- 3年累積効果：約8.5億円の研究時間創出（発表数増加と質向上による波及効果）
- セキュリティ対応のコスト削減：従来の個別監視を自動化し、年間2,000万円削減

**競争優位性**
- 国内で初めてセキュアなAI利用ガイドラインを策定・公開
- 業界のベストプラクティスとしての地位確立
- AI倫理・セキュリティ研究の先導的地位
- 学生による起業やスタートアップにおけるAI活用競争力

## 6. 課題・対策

**技術的課題と対策**

| 課題 | 内容 | 対策 |
|------|------|------|
| 大規模モデルの計算コスト | キャンパス全体での同時アクセス時の遅延 | キャッシング層導入、モデル圧縮技術の適用 |
| 多言語対応の精度 | 日本語・英語・中国語などの混合文書処理 | 言語別の専用モデル開発 |
| 研究機密情報の誤処理 | 機密レベルの自動判定失敗 | 人間によるレビュープロセスの組み込み |

**組織的課題と対策**

**課題1：研究倫理面での懸念**
- 原因：AIで生成したテキストの出典表記問題、盗用の可能性
- 対策：
  - AI倫理委員会を設置（月1回の検討会議）
  - 論文投稿時のAI使用申告制度導入
  - 査読ガイドラインにAI対応記述追加

**課題2：セキュリティ意識の多様性**
- 原因：キャンパス・部局による意識レベルの格差
- 対策：
  - セキュリティ教育の必須化（全学生・全職員）
  - 違反時の厳格なペナルティ制度
  - リスク監視の自動化・可視化ダッシュボード

**課題3：AI生成テキストの質のばらつき**
- 原因：利用者のプロンプトスキルの差
- 対策：
  - 部局別のベストプラクティス研修（月1回）
  - プロンプトテンプレート集の整備
  - AI利用の優秀事例の表彰制度

**人材育成**

1. **基礎教育（全学）**
   - 新入生オリエンテーション時のAI基礎講座
   - オンデマンド動画：安全な利用方法、セキュリティ
   - 参加率：98%

2. **研究者向け高度研修**
   - 月次ワークショップ：論文執筆支援、データ分析AI活用
   - 大学院科目「生成AIと研究」新設（受講者：150名/学期）

3. **セキュリティ認定資格**
   - 「東大AI利用セキュリティ認定」制度
   - 取得者（2024年1月時点）：523名
   - 機密情報アクセス権の獲得に必須

## 7. 将来展望

**拡張計画（2024-2026年）**

1. **AI研究の国際協力**
   - MIT、Stanford、Cambridge大学との共同研究プロジェクト
   - 「責任あるAI」フレームワークの共同開発

2. **次世代AIモデル開発**
   - 東大AI研究チームによる「日本語特化モデル」の開発
   - 医学・工学・人文系の専門知識を統合

3. **社会実装の促進**
   - 大学シーズをAI企業へのライセンス
   - スタートアップの育成・支援プログラム

**推奨事項**
- AI倫理に関する国際基準策定への参加
- 文部科学省との連携による高等教育全体のAI利用ガイドライン提案
- 継続的なセキュリティ監査（年2回の外部監査）

**長期戦略**
- 2026年までに「日本版OpenAI」としての国際的地位確立
- AI関連研究費の拡大（現在の2倍化）
- 文科省の「数理・データサイエンス・AI教育推進」での核となる機関

## 8. 参考情報

**データソース**
- 東京大学情報基盤センター内部資料（2024年1月）
- 「東京大学生成AI利用ガイドライン」公開版（2023年9月）
- 東大AI研究チーム論文集（2023年度）
- Deloitte Japan セキュリティ監査報告書

**参考リンク**
- 東京大学公式サイト：https://www.u-tokyo.ac.jp/
- ガイドライン詳細：https://www.u-tokyo.ac.jp/adm/genai-guideline

**更新日**
2024年1月20日

**作成者**
GenAI Case Study Analysis Team

---

## 補足資料

### 研究成果

**論文発表実績の向上**
2023年度に「生成AI利用ガイドライン下での論文執筆」に関する論文が国際学会に採択。この論文は、セキュアなAI利用環境での研究生産性向上に関する初の実証研究として高い評価を受けました。

### セキュリティ規格化への貢献

東大のセキュリティガイドラインは、その徹底性と実用性から：
- 日本学術会議の「学術界におけるAI倫理ガイドライン」の基礎資料として採択
- 60以上の国内大学が本ガイドラインを参考に自機関のポリシーを策定
- 文部科学省の「大学AI利用基準案」の核となる

### 社会実装の例

東大発のAI関連スタートアップが、大学のAI利用経験をベースに：
- 医療機関向けのセキュアなAI分析プラットフォーム開発
- 法律業界向けのドキュメント作成支援ツール開発
- IPO準備段階の企業まで成長（2024年1月時点）
