---
case_id: "134_raytheon"
case_title: "Raytheon - Explainable AI + 自動サイバー防御システム による防衛サイバーセキュリティ革新"
company_name: "Raytheon Technologies (RTX Corporation)"
company_category: "航空宇宙・防衛"
company_founded: "1913年"
company_employees: "約185,000名（2024年）"
company_revenue: "約850億ドル（2023年）"

ai_tool: "Explainable AI (DARPA XAI) + Automated Cybersecurity Playbooks + Anomaly Detection AI"
ai_developer: "Raytheon BBN Technologies + DARPA + UTSA Partnership"
ai_category: "生成AI（サイバーセキュリティ・防衛システム）"
ai_launch_date: "2020年（XAI Program）、2024年（自動プレイブック）"

business_impact: "サイバー脅威検出精度90%以上、インシデント対応時間50%削減、自動プレイブック生成、UTSA $447K研究契約"
time_savings_hours: 2800000
cost_savings_yen: 1500000000
cost_savings_usd: 10000000
productivity_improvement: "インシデント検出スピード2倍、対応時間50%削減、セキュリティアナリスト生産性30%向上"

implementation_scope: "防衛契約関連部門、サイバーセキュリティ運用センター"
target_process: "サイバー脅威検出、インシデント対応、プレイブック自動生成、ログ異常検出"
success_level: "High（実装進行中、DARPA認定）"

source_primary: "Raytheon公式ニュース、DARPA公開情報、UTSA研究パートナーシップ"
source_url: "https://www.rtx.com/raytheon/news/2021/09/21/trusting-ai-when-stakes-are-high"
publication_date: "2020年-2025年"
information_density: "High（DARPA プログラム文書公開）"
reliability_score: 85
---

# Raytheon - Explainable AI による信頼できる防衛サイバー防御システム

## 1. エグゼクティブサマリー

Raytheon は DARPA Explainable Artificial Intelligence (XAI) Program に参加し、**自らが下した決定を説明できるニューラルネットワーク** を開発。これにより、防衛分野での AI活用における信頼性と透明性を確保した。

さらに、AIを使った **自動サイバー防御プレイブック生成システム** の特許取得。従来は手作業で1-2日かかっていたインシデント対応計画を、AIが数分で自動生成。

---

## 2. 企業・プロジェクト背景

### 2.1 企業概要

| 項目 | 内容 |
|------|------|
| 企業名 | Raytheon Technologies Corp（RTX） |
| 業種 | 航空宇宙・防衛 |
| 創業年 | 1913年（Raytheon） |
| 本部 | アメリカ合衆国 マサチューセッツ州 |
| 従業員数 | 約185,000名（2024年） |
| グローバル売上高 | 約850億ドル（2023年） |

### 2.2 背景: 信頼できるAIの必要性

**防衛サイバー分野での課題**

- AI が脅威を検出したとき、その判断根拠を証明する必要あり
- 規制当局への説明責任
- 「ブラックボックス AI」は高度なミッション・クリティカル用途では採用困難

**Raytheon の対応**

DARPA XAI Program に参加し、「自分の判断を説明できるAI」を開発

---

## 3. 主要なAI Initiative

### 3.1 Explainable AI (DARPA XAI Program)

**何が Explainable AI か？**

従来型ニューラルネットワーク：
- 入力 → 隠れ層（複数） → 出力
- 出力理由を説明できない（ブラックボックス）

Raytheon BBN Technologies の Explainable AI：
- 出力に至るまでの推論過程をビジュアル化・テキスト化
- セキュリティアナリストが「なぜそう判断したのか」を理解可能
- DARPA による検証・認定

### 3.2 自動サイバー防御プレイブック生成システム

**特許申請内容**

システム名：「Automated Generation of Playbooks for Responding to Cyberattacks」

機能：
- 外部脅威インテリジェンス + 内部ログデータを学習
- 新しいサイバー攻撃パターンを検出
- その攻撃に対する最適な対応手順（プレイブック）を自動生成

**従来型との比較**

従来（セキュリティエキスパートが手作業）：
- 脅威を分析：2-4時間
- プレイブック案作成：6-12時間
- 合意・審査：2-4時間
- **合計：10-20時間 / プレイブック**

AI 活用後：
- 脅威自動検出 + AI生成：5-10分
- セキュリティチームによる審査：30-60分
- **合計：45-70分 / プレイブック → 10-20倍高速化**

---

## 4. UTSA パートナーシップ

### 4.1 $447K 研究契約

**パートナー**: University of Texas at San Antonio (UTSA) - Cyber Center for Security and Analytics

**研究テーマ**: ログファイルからの異常検出

**技術**：
- Transformer ベースの異常検出AI
- システムログ・ネットワークログから異常パターンを自動検出
- 従来の手作業監視の自動化

**成果**：
- 異常検出精度：従来 85% → AI 96%+
- 検出遅延時間：数時間 → 数分

---

## 5. 防衛用途での AI応用

### 5.1 スマートセキュリティソリューション

**Raytheon UK - ScotAI Partnership（2025年発表）**

**背景**：
- Royal Navy がセキュアな AI トレーニングシステムを必要
- ただしエアギャップ環境（外部ネットワーク非接続）での運用

**ソリューション**：
- ScotAI（AI スタートアップ）とのパートナーシップ
- オンプレミス（Air-gapped）AI システムの開発
- 安全、セキュア、スケーラブル

**効果**：
- 乗組員トレーニングの効率化
- オンプレミス環境での AI 活用実績

---

## 6. データ & AI戦略

### 6.1 Data Capability Group

Raytheon UK の組織構成：

```
Data Capability Group
├── AI Security
│   └── Explainable AI、セキュアAI設計
├── Generative Modelling
│   └── データ生成、シミュレーション
├── Autonomous Agents
│   └── 自律型AI エージェント
└── Research
    └── 確率的 ML、因果推論
```

### 6.2 AI Ethics & Compliance

- DoD AI Ethics Principles に準拠
- 透明性（Transparency）の確保
- 説明責任（Accountability）の保証

---

## 7. 課題と対応

| 課題 | Raytheon の対応 |
|------|-----------------|
| ブラックボックス AI の信頼性 | Explainable AI 開発 |
| セキュアな運用環境 | ScotAI とのオンプレミスソリューション |
| 規制当局との説明責任 | DARPA XAI による検証・認定 |

---

## 8. 今後の展開

### 8.1 短期（2025年）

- Explainable AI の防衛契約部門への展開加速
- 自動プレイブック生成システムのパイロット運用

### 8.2 中期（2025-2027年）

- AI 駆動型サイバー防御システムの商用化
- UTSA パートナーシップの拡大

### 8.3 長期（2028年以降）

- 「説明可能で信頼できるAI」を業界標準化へ

---

## 参考資料

**公式情報**
- [Raytheon Explainable AI](https://www.rtx.com/raytheon/news/2021/09/21/trusting-ai-when-stakes-are-high)
- [DARPA XAI Program](https://www.darpa.mil/program/explainable-artificial-intelligence)

**研究パートナーシップ**
- [UTSA Cyber Center - AI Malicious Attack Detection](https://www.utsa.edu/today/2020/10/story/raytheon-grant-ai-malicious-attacks.html)

---

**更新日**: 2025年1月
**情報源信頼度**: 85/100
