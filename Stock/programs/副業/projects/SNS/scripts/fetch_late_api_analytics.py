#!/usr/bin/env python3
"""
Late API Analytics ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Analytics APIã‚’ä½¿ç”¨ã—ã¦2026å¹´1æœˆ1æ—¥ï½10æ—¥ã®å®Ÿéš›ã®ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°ã¨ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã‚’å–å¾—
"""

import os
import json
import requests
from datetime import datetime, timezone
from pathlib import Path
from dotenv import load_dotenv

# .envèª­ã¿è¾¼ã¿
project_root = Path(__file__).parent.parent
load_dotenv(project_root / ".env")


class LateAPIAnalyticsClient:
    """Late API Analytics ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""

    def __init__(self):
        self.api_key = os.getenv("LATE_API_KEY")
        if not self.api_key:
            raise ValueError("LATE_API_KEY not found in .env file")

        self.base_url = "https://getlate.dev/api/v1"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

    def get_posts_list(self, platform: str = None) -> list:
        """
        æŠ•ç¨¿ä¸€è¦§ã‚’å–å¾—ï¼ˆ/posts ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰

        Args:
            platform: ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æŒ‡å®šï¼ˆx, threads, linkedinï¼‰

        Returns:
            list: æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ãƒˆ
        """
        endpoint = f"{self.base_url}/posts"

        params = {"limit": 100, "sortBy": "date", "order": "desc"}

        if platform:
            params["platform"] = platform

        print(f"ğŸ“‹ æŠ•ç¨¿ä¸€è¦§å–å¾—: {endpoint}")
        print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {params}")

        response = requests.get(endpoint, headers=self.headers, params=params)

        if response.status_code != 200:
            error_msg = (
                f"Late API Error: {response.status_code} - {response.text}"
            )
            raise Exception(error_msg)

        data = response.json()
        posts = data.get("posts", []) if isinstance(data, dict) else data

        print(f"âœ… {len(posts)}ä»¶ã®æŠ•ç¨¿ã‚’å–å¾—")
        return posts

    def get_analytics(self, from_date: str, to_date: str, platform: str) -> dict:
        """
        Analytics APIã‹ã‚‰ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        Args:
            from_date: é–‹å§‹æ—¥ (YYYY-MM-DD)
            to_date: çµ‚äº†æ—¥ (YYYY-MM-DD)
            platform: ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 

        Returns:
            dict: Analyticsãƒ‡ãƒ¼ã‚¿
        """
        endpoint = f"{self.base_url}/analytics"

        params = {
            "fromDate": from_date,
            "toDate": to_date,
            "platform": platform,
            "sortBy": "date",
            "order": "desc",
            "limit": 100,
        }

        print(f"ğŸ“Š Analytics APIå‘¼ã³å‡ºã—: {endpoint}")
        print(f"   ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {params}")

        response = requests.get(endpoint, headers=self.headers, params=params)

        if response.status_code == 402:
            print("âš ï¸  Analytics AddonãŒæœ‰åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼ˆ$10/æœˆï¼‰")
            print(
                "   Late Dashboard (https://app.getlate.dev/settings/billing) ã§æœ‰åŠ¹åŒ–ã—ã¦ãã ã•ã„"
            )
            return {}

        if response.status_code != 200:
            error_msg = (
                f"Analytics API Error: {response.status_code} - {response.text}"
            )
            raise Exception(error_msg)

        data = response.json()
        print(f"âœ… Analyticsãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ")

        return data

    def fetch_all_platforms(self, start_date: str, end_date: str) -> dict:
        """
        å…¨ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—

        Args:
            start_date: é–‹å§‹æ—¥
            end_date: çµ‚äº†æ—¥

        Returns:
            dict: ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥ãƒ‡ãƒ¼ã‚¿
        """
        platforms = ["x", "threads", "linkedin"]
        all_data = []
        platform_stats = {}

        for platform in platforms:
            print(f"\nğŸ” {platform.upper()} ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­...")

            try:
                # Step 1: æŠ•ç¨¿ä¸€è¦§å–å¾—
                posts = self.get_posts_list(platform=platform)

                # æœŸé–“å†…ã®æŠ•ç¨¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿
                start_dt = datetime.fromisoformat(start_date + "T00:00:00Z")
                end_dt = datetime.fromisoformat(end_date + "T23:59:59Z")

                filtered_posts = []
                for post in posts:
                    published_at_str = post.get("publishedAt") or post.get(
                        "published_at"
                    )
                    if published_at_str:
                        published_at = datetime.fromisoformat(
                            published_at_str.replace("Z", "+00:00")
                        )
                        if start_dt <= published_at <= end_dt:
                            filtered_posts.append(post)

                print(
                    f"   ğŸ“… æœŸé–“å†…ã®æŠ•ç¨¿: {len(filtered_posts)}ä»¶ï¼ˆå…¨{len(posts)}ä»¶ä¸­ï¼‰"
                )

                # Step 2: Analytics ãƒ‡ãƒ¼ã‚¿å–å¾—
                analytics_data = self.get_analytics(
                    start_date, end_date, platform
                )

                # Analyticsãƒ‡ãƒ¼ã‚¿ã‚’æŠ•ç¨¿IDã§ãƒãƒƒãƒ”ãƒ³ã‚°
                analytics_map = {}
                if "analytics" in analytics_data:
                    for item in analytics_data.get("analytics", []):
                        post_id = item.get("postId") or item.get("post_id")
                        if post_id:
                            analytics_map[post_id] = item

                # Step 3: æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã¨Analyticsãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
                total_impressions = 0
                total_engagement = 0

                for post in filtered_posts:
                    post_id = post.get("_id") or post.get("id")

                    # Analyticsãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
                    if post_id in analytics_map:
                        post["analytics"] = analytics_map[post_id]

                    # æ¨™æº–åŒ–ãƒ‡ãƒ¼ã‚¿ä½œæˆ
                    normalized = self._normalize_post_data(post, platform)
                    all_data.append(normalized)

                    total_impressions += normalized["impressions"]
                    total_engagement += (
                        normalized["likes"]
                        + normalized["comments"]
                        + normalized["shares"]
                    )

                platform_stats[platform] = {
                    "total_posts": len(filtered_posts),
                    "impressions": total_impressions,
                    "total_engagement": total_engagement,
                }

                print(
                    f"   âœ… {len(filtered_posts)}ä»¶å–å¾— | ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³: {total_impressions:,}"
                )

            except Exception as e:
                print(f"   âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                platform_stats[platform] = {
                    "total_posts": 0,
                    "impressions": 0,
                    "total_engagement": 0,
                    "error": str(e),
                }

        return {
            "metadata": {
                "fetched_at": datetime.now(timezone.utc).isoformat(),
                "period_start": start_date,
                "period_end": end_date,
                "platforms": platforms,
                "total_posts": len(all_data),
                "platform_stats": platform_stats,
            },
            "data": all_data,
        }

    def _normalize_post_data(self, post: dict, platform: str) -> dict:
        """
        æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‚’æ¨™æº–åŒ–

        Args:
            post: Late APIãƒ¬ã‚¹ãƒãƒ³ã‚¹
            platform: ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å

        Returns:
            dict: æ¨™æº–åŒ–ã•ã‚ŒãŸæŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿
        """
        # Late APIã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°
        post_id = post.get("_id") or post.get("id")
        published_at = post.get("publishedAt") or post.get("published_at")
        text = post.get("post") or post.get("text") or post.get("content", "")

        # Analytics ãƒ‡ãƒ¼ã‚¿ï¼ˆanalytics ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¾ãŸã¯ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ï¼‰
        analytics = post.get("analytics", {})

        impressions = (
            analytics.get("impressions")
            or post.get("impressions")
            or post.get("views")
            or 0
        )

        likes = (
            analytics.get("likes")
            or post.get("likes")
            or post.get("reactions")
            or 0
        )

        comments = (
            analytics.get("comments")
            or post.get("comments")
            or post.get("replies")
            or 0
        )

        shares = (
            analytics.get("shares")
            or post.get("shares")
            or post.get("reposts")
            or 0
        )

        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡è¨ˆç®—
        total_engagement = likes + comments + shares
        engagement_rate = (
            (total_engagement / impressions * 100) if impressions > 0 else 0
        )

        # ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—åˆ¤å®š
        media = post.get("media", [])
        media_type = "image" if media else "text"

        return {
            "post_id": post_id,
            "platform": platform,
            "published_at": published_at,
            "text": text[:200] + "..." if len(text) > 200 else text,
            "impressions": impressions,
            "engagement_rate": round(engagement_rate, 2),
            "likes": likes,
            "comments": comments,
            "shares": shares,
            "media_type": media_type,
            "raw_data": post,  # ãƒ‡ãƒãƒƒã‚°ç”¨ã«å…ƒãƒ‡ãƒ¼ã‚¿ã‚‚ä¿å­˜
        }


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    start_date = "2026-01-01"
    end_date = "2026-01-10"

    print("=" * 60)
    print("Late API Analytics ãƒ‡ãƒ¼ã‚¿åé›†")
    print("=" * 60)
    print(f"æœŸé–“: {start_date} ï½ {end_date}")
    print(f"ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : X, Threads, LinkedIn")
    print()

    try:
        # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        client = LateAPIAnalyticsClient()

        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        result = client.fetch_all_platforms(start_date, end_date)

        # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
        output_dir = project_root / "data"
        output_dir.mkdir(exist_ok=True)
        output_file = output_dir / "late_api_analytics_20260101-0110.json"

        # JSONä¿å­˜
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)

        print("\n" + "=" * 60)
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
        print("=" * 60)
        print(f"ç·æŠ•ç¨¿æ•°: {result['metadata']['total_posts']}")
        print(
            f"ç·ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³: {sum(p['impressions'] for p in result['data']):,}"
        )
        print(f"ä¿å­˜å…ˆ: {output_file}")
        print()

        # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥ã‚µãƒãƒªãƒ¼
        print("ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥çµ±è¨ˆ:")
        for platform, stats in result["metadata"]["platform_stats"].items():
            print(
                f"  {platform.upper()}: {stats['total_posts']}ä»¶ | ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³: {stats['impressions']:,}"
            )

        # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
        zero_impressions = [
            p for p in result["data"] if p["impressions"] == 0
        ]
        if zero_impressions:
            print(
                f"\nâš ï¸  è­¦å‘Š: {len(zero_impressions)}ä»¶ã®æŠ•ç¨¿ã®ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°ãŒ0ã§ã™"
            )
            print("   â†’ Late APIãŒAnalyticsãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
        else:
            print("\nâœ… å…¨æŠ•ç¨¿ã§æœ‰åŠ¹ãªã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°ã‚’å–å¾—ã—ã¾ã—ãŸ")

    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback

        traceback.print_exc()
        exit(1)


if __name__ == "__main__":
    main()
