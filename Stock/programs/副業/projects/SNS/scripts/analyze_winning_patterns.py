#!/usr/bin/env python3
"""
å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³è‡ªå‹•åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ãƒˆãƒƒãƒ—/ãƒœãƒˆãƒ æŠ•ç¨¿ã®5W1Håˆ†æã‚’è‡ªå‹•åŒ–
"""

import sqlite3
import pandas as pd
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List


# ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
BASE_DIR = Path(__file__).parent.parent
DB_PATH = BASE_DIR / "data" / "analytics.db"
OUTPUT_DIR = BASE_DIR / "data" / "insights"


def load_top_bottom_posts(period_days=30, top_n=10, bottom_n=10) -> Dict:
    """ãƒˆãƒƒãƒ—/ãƒœãƒˆãƒ æŠ•ç¨¿ã‚’å–å¾—"""
    conn = sqlite3.connect(DB_PATH)

    # ãƒˆãƒƒãƒ—æŠ•ç¨¿
    query_top = f"""
        SELECT
            post_id,
            platform,
            published_at,
            impressions,
            reach,
            likes,
            comments,
            shares,
            engagement_rate,
            raw_data
        FROM analytics
        WHERE DATE(published_at) >= DATE('now', '-{period_days} days')
        ORDER BY impressions DESC
        LIMIT {top_n}
    """

    df_top = pd.read_sql_query(query_top, conn)

    # ãƒœãƒˆãƒ æŠ•ç¨¿
    query_bottom = f"""
        SELECT
            post_id,
            platform,
            published_at,
            impressions,
            reach,
            likes,
            comments,
            shares,
            engagement_rate,
            raw_data
        FROM analytics
        WHERE DATE(published_at) >= DATE('now', '-{period_days} days')
        ORDER BY impressions ASC
        LIMIT {bottom_n}
    """

    df_bottom = pd.read_sql_query(query_bottom, conn)

    conn.close()

    return {
        "top_posts": df_top.to_dict('records'),
        "bottom_posts": df_bottom.to_dict('records')
    }


def analyze_5w1h(post: Dict) -> Dict:
    """
    5W1Håˆ†æã‚’å®Ÿæ–½

    What: ãƒˆãƒ”ãƒƒã‚¯åˆ†é¡
    When: æŠ•ç¨¿æ™‚é–“å¸¯ã€æ›œæ—¥
    Why: ã‚¿ã‚¤ãƒ ãƒªãƒ¼æ€§ã€æ„å¤–æ€§
    How: æ–‡ä½“ã€æ–‡å­—æ•°
    """
    published_at = pd.to_datetime(post['published_at'])

    analysis = {
        "post_id": post['post_id'],
        "platform": post['platform'],
        "impressions": post['impressions'],
        "engagement_rate": post['engagement_rate'],

        # Whenåˆ†æ
        "weekday": published_at.strftime("%A"),  # Monday, Tuesday...
        "weekday_num": published_at.weekday(),   # 0=æœˆæ›œ, 6=æ—¥æ›œ
        "hour": published_at.hour,
        "time_slot": get_time_slot(published_at.hour),

        # Whatåˆ†æï¼ˆãƒˆãƒ”ãƒƒã‚¯åˆ†é¡ã¯å¾Œã§LLMæ´»ç”¨ï¼‰
        "topic": "æœªåˆ†é¡",  # TODO: LLMåˆ†æ

        # Whyåˆ†æï¼ˆå‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¤å®šï¼‰
        "has_shocking_numbers": False,  # TODO: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æ
        "has_authority_citation": False,  # TODO: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æ
        "is_ceo_oriented": False,  # TODO: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æ

        # Howåˆ†æ
        "character_count": 0,  # TODO: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æ
        "has_image": False,  # TODO: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æ
        "has_video": False,  # TODO: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ†æ
    }

    return analysis


def get_time_slot(hour: int) -> str:
    """æ™‚é–“å¸¯ã‚¹ãƒ­ãƒƒãƒˆå–å¾—"""
    if 0 <= hour < 6:
        return "æ·±å¤œ(0-6æ™‚)"
    elif 6 <= hour < 12:
        return "åˆå‰(6-12æ™‚)"
    elif 12 <= hour < 18:
        return "åˆå¾Œ(12-18æ™‚)"
    else:
        return "å¤œ(18-24æ™‚)"


def analyze_time_performance(posts: List[Dict]) -> pd.DataFrame:
    """æ™‚é–“å¸¯ãƒ»æ›œæ—¥åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ"""
    analyses = [analyze_5w1h(post) for post in posts]
    df = pd.DataFrame(analyses)

    # æ™‚é–“å¸¯Ã—æ›œæ—¥ã®ã‚¯ãƒ­ã‚¹é›†è¨ˆ
    pivot_time = df.pivot_table(
        values='impressions',
        index='time_slot',
        columns='weekday',
        aggfunc='mean'
    )

    return pivot_time


def identify_winning_patterns(top_posts: List[Dict]) -> Dict:
    """å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®š"""
    analyses = [analyze_5w1h(post) for post in top_posts]
    df = pd.DataFrame(analyses)

    # æœ€é »å‡ºæ™‚é–“å¸¯
    top_time_slot = df['time_slot'].mode()[0] if not df.empty else "ä¸æ˜"

    # æœ€é »å‡ºæ›œæ—¥
    top_weekday = df['weekday'].mode()[0] if not df.empty else "ä¸æ˜"

    # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
    platform_performance = df.groupby('platform')['impressions'].mean().to_dict()

    patterns = {
        "optimal_time_slot": top_time_slot,
        "optimal_weekday": top_weekday,
        "platform_performance": platform_performance,
        "avg_impressions": df['impressions'].mean(),
        "avg_engagement_rate": df['engagement_rate'].mean(),
    }

    return patterns


def identify_anti_patterns(bottom_posts: List[Dict]) -> Dict:
    """ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç‰¹å®š"""
    analyses = [analyze_5w1h(post) for post in bottom_posts]
    df = pd.DataFrame(analyses)

    # å¤±æ•—æ™‚é–“å¸¯
    worst_time_slot = df['time_slot'].mode()[0] if not df.empty else "ä¸æ˜"

    # å¤±æ•—æ›œæ—¥
    worst_weekday = df['weekday'].mode()[0] if not df.empty else "ä¸æ˜"

    anti_patterns = {
        "worst_time_slot": worst_time_slot,
        "worst_weekday": worst_weekday,
        "avg_impressions": df['impressions'].mean(),
        "avg_engagement_rate": df['engagement_rate'].mean(),
    }

    return anti_patterns


def generate_insights_report(
    top_posts: List[Dict],
    bottom_posts: List[Dict],
    winning_patterns: Dict,
    anti_patterns: Dict,
    output_path: Path
):
    """ã‚¤ãƒ³ã‚µã‚¤ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆMarkdownï¼‰"""
    report = f"""# SNSæŠ•ç¨¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ“Š ã‚µãƒãƒªãƒ¼

### ãƒˆãƒƒãƒ—10æŠ•ç¨¿ã®ç‰¹å¾´
- **å¹³å‡ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³**: {winning_patterns['avg_impressions']:,.0f}
- **å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡**: {winning_patterns['avg_engagement_rate']:.2f}%
- **æœ€é©æ™‚é–“å¸¯**: {winning_patterns['optimal_time_slot']}
- **æœ€é©æ›œæ—¥**: {winning_patterns['optimal_weekday']}

### ãƒœãƒˆãƒ 10æŠ•ç¨¿ã®ç‰¹å¾´
- **å¹³å‡ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³**: {anti_patterns['avg_impressions']:,.0f}
- **å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡**: {anti_patterns['avg_engagement_rate']:.2f}%
- **å¤±æ•—æ™‚é–“å¸¯**: {anti_patterns['worst_time_slot']}
- **å¤±æ•—æ›œæ—¥**: {anti_patterns['worst_weekday']}

---

## ğŸ† ãƒˆãƒƒãƒ—10æŠ•ç¨¿è©³ç´°

| Rank | Platform | Impressions | ER (%) | æŠ•ç¨¿æ—¥æ™‚ |
|------|----------|-------------|--------|----------|
"""

    for i, post in enumerate(top_posts, 1):
        dt = pd.to_datetime(post['published_at'])
        report += f"| {i} | {post['platform']} | {post['impressions']:,} | {post['engagement_rate']:.2f} | {dt.strftime('%Y-%m-%d %H:%M')} |\n"

    report += """
---

## âš ï¸ ãƒœãƒˆãƒ 10æŠ•ç¨¿è©³ç´°

| Rank | Platform | Impressions | ER (%) | æŠ•ç¨¿æ—¥æ™‚ |
|------|----------|-------------|--------|----------|
"""

    for i, post in enumerate(bottom_posts, 1):
        dt = pd.to_datetime(post['published_at'])
        report += f"| {i} | {post['platform']} | {post['impressions']:,} | {post['engagement_rate']:.2f} | {dt.strftime('%Y-%m-%d %H:%M')} |\n"

    report += """
---

## ğŸ¯ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

### å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³æ´»ç”¨
1. **æœ€é©æŠ•ç¨¿æ™‚é–“å¸¯**: {optimal_time_slot}ã«æŠ•ç¨¿
2. **æœ€é©æ›œæ—¥**: {optimal_weekday}ã‚’å„ªå…ˆ
3. **ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æœ€é©åŒ–**: {best_platform}ã‚’å¼·åŒ–

### ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³å›é¿
1. **é¿ã‘ã‚‹ã¹ãæ™‚é–“å¸¯**: {worst_time_slot}
2. **é¿ã‘ã‚‹ã¹ãæ›œæ—¥**: {worst_weekday}

---

**æ¬¡å›æ›´æ–°**: 1é€±é–“å¾Œ
""".format(
        optimal_time_slot=winning_patterns['optimal_time_slot'],
        optimal_weekday=winning_patterns['optimal_weekday'],
        best_platform=max(winning_patterns['platform_performance'], key=winning_patterns['platform_performance'].get),
        worst_time_slot=anti_patterns['worst_time_slot'],
        worst_weekday=anti_patterns['worst_weekday']
    )

    # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f"âœ… ã‚¤ãƒ³ã‚µã‚¤ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {output_path}")


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\n" + "=" * 80)
    print("ğŸ” å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³è‡ªå‹•åˆ†æé–‹å§‹")
    print("=" * 80)
    print(f"å®Ÿè¡Œæ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    OUTPUT_DIR.mkdir(exist_ok=True)

    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    print("ğŸ“Š ãƒˆãƒƒãƒ—/ãƒœãƒˆãƒ æŠ•ç¨¿ã‚’å–å¾—ä¸­...")
    data = load_top_bottom_posts(period_days=30, top_n=10, bottom_n=10)

    top_posts = data['top_posts']
    bottom_posts = data['bottom_posts']

    print(f"   ãƒˆãƒƒãƒ—æŠ•ç¨¿: {len(top_posts)}ä»¶")
    print(f"   ãƒœãƒˆãƒ æŠ•ç¨¿: {len(bottom_posts)}ä»¶\n")

    if not top_posts:
        print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚`daily_analytics_collection.py`ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return

    # å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    print("ğŸ† å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æä¸­...")
    winning_patterns = identify_winning_patterns(top_posts)
    print(f"   æœ€é©æ™‚é–“å¸¯: {winning_patterns['optimal_time_slot']}")
    print(f"   æœ€é©æ›œæ—¥: {winning_patterns['optimal_weekday']}\n")

    # ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
    print("âš ï¸  ã‚¢ãƒ³ãƒãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æä¸­...")
    anti_patterns = identify_anti_patterns(bottom_posts)
    print(f"   å¤±æ•—æ™‚é–“å¸¯: {anti_patterns['worst_time_slot']}")
    print(f"   å¤±æ•—æ›œæ—¥: {anti_patterns['worst_weekday']}\n")

    # æ™‚é–“å¸¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
    print("ğŸ“ˆ æ™‚é–“å¸¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’åˆ†æä¸­...")
    time_performance = analyze_time_performance(top_posts + bottom_posts)
    print(time_performance)
    print()

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("ğŸ“ ã‚¤ãƒ³ã‚µã‚¤ãƒˆãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
    report_path = OUTPUT_DIR / f"insights_report_{datetime.now().strftime('%Y%m%d')}.md"
    generate_insights_report(top_posts, bottom_posts, winning_patterns, anti_patterns, report_path)

    # JSONå‡ºåŠ›
    json_path = OUTPUT_DIR / f"insights_data_{datetime.now().strftime('%Y%m%d')}.json"
    insights_data = {
        "generated_at": datetime.now().isoformat(),
        "winning_patterns": winning_patterns,
        "anti_patterns": anti_patterns,
        "top_posts": [
            {k: v for k, v in post.items() if k != 'raw_data'}
            for post in top_posts
        ],
        "bottom_posts": [
            {k: v for k, v in post.items() if k != 'raw_data'}
            for post in bottom_posts
        ]
    }

    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(insights_data, f, indent=2, ensure_ascii=False)

    print(f"âœ… JSONãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {json_path}")

    print("\n" + "=" * 80)
    print("âœ… å‹ã¡ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æå®Œäº†")
    print("=" * 80 + "\n")


if __name__ == "__main__":
    main()
