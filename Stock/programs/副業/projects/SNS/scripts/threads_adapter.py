#!/usr/bin/env python3
"""
Threads Adapter - Xç‰ˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’Threadsç‰ˆã«å¤‰æ›

ã“ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€XæŠ•ç¨¿ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’Threadsãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å‘ã‘ã«æœ€é©åŒ–ã—ã¾ã™ã€‚
- æ–‡å­—æ•°èª¿æ•´ï¼ˆ700-1500å­— â†’ 300-500å­—ï¼‰
- æ®µè½æ§‹æˆï¼ˆ4-8æ®µè½ â†’ 2-4æ®µè½ï¼‰
- çµµæ–‡å­—è¿½åŠ ï¼ˆ0-2å€‹ â†’ 3-5å€‹ï¼‰
- å£èªä½“å¢—å¼·ï¼ˆ2å› â†’ 3-5å›ï¼‰
- ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°èª¿æ•´ï¼ˆ2å€‹ â†’ 1å€‹ï¼‰
"""

import re
import json
import unicodedata
from typing import Dict, List, Tuple
from pathlib import Path


class ThreadsAdapter:
    """Xç‰ˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’Threadsç‰ˆã«å¤‰æ›ã™ã‚‹ã‚¢ãƒ€ãƒ—ã‚¿ãƒ¼"""

    def __init__(self, config_path: str = None):
        """
        Args:
            config_path: threads_patterns_config.json ã®ãƒ‘ã‚¹
        """
        if config_path is None:
            # scripts/ â†’ SNS/ â†’ projects/ â†’ å‰¯æ¥­/ â†’ programs/ â†’ Stock/ â†’ aipm_v0/ â†’ .claude/
            config_path = Path(__file__).parent.parent.parent.parent.parent.parent.parent / \
                ".claude/skills/generate-x-threads-posts/threads_patterns_config.json"

        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = json.load(f)

        self.char_limits = self.config['character_count_rules']['standard_type']
        self.emoji_strategy = self.config['emoji_strategy']
        self.tone_manner = self.config['tone_and_manner']

    def convert_x_to_threads(
        self,
        x_thread: List[str],
        target_length: Tuple[int, int] = (300, 500),
        emoji_count: Tuple[int, int] = (3, 5),
        informal_count: Tuple[int, int] = (3, 5)
    ) -> Dict:
        """
        Xç‰ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚’Threadsç‰ˆã«å¤‰æ›

        Args:
            x_thread: Xã‚¹ãƒ¬ãƒƒãƒ‰ã®å„ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆãƒªã‚¹ãƒˆï¼‰
            target_length: ç›®æ¨™æ–‡å­—æ•°ç¯„å›²ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 300-500ï¼‰
            emoji_count: çµµæ–‡å­—æ•°ç¯„å›²ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3-5ï¼‰
            informal_count: å£èªä½“å›æ•°ç¯„å›²ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3-5ï¼‰

        Returns:
            {
                "content": str,             # ThreadsæŠ•ç¨¿æœ¬æ–‡
                "character_count": int,     # æ–‡å­—æ•°
                "emoji_count": int,         # çµµæ–‡å­—æ•°
                "informal_expressions": list[str],  # ä½¿ç”¨ã—ãŸå£èªä½“
                "paragraph_count": int,     # æ®µè½æ•°
                "hashtag": str              # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ï¼ˆ1å€‹ï¼‰
            }
        """
        # STEP 1: å…¨ãƒ„ã‚¤ãƒ¼ãƒˆã‚’çµåˆ
        full_text = self._merge_thread(x_thread)

        # STEP 2: LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
        prompt = self._generate_conversion_prompt(
            full_text,
            target_length,
            emoji_count,
            informal_count
        )

        # STEP 3: LLMå¤‰æ›ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯LLM APIã‚’å‘¼ã³å‡ºã—ï¼‰
        # ã“ã“ã§ã¯æ“¬ä¼¼çš„ãªå¤‰æ›å‡¦ç†ã‚’è¨˜è¿°
        threads_content = self._convert_via_llm(prompt, full_text)

        # STEP 4: æ¤œè¨¼
        result = self._validate_and_extract_metrics(
            threads_content,
            target_length,
            emoji_count,
            informal_count
        )

        return result

    def _merge_thread(self, x_thread: List[str]) -> str:
        """Xç‰ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚’1ã¤ã®ãƒ†ã‚­ã‚¹ãƒˆã«çµåˆ"""
        # ãƒ„ã‚¤ãƒ¼ãƒˆç•ªå·ï¼ˆ1/7, 2/7...ï¼‰ã‚’é™¤å»
        cleaned_tweets = []
        for tweet in x_thread:
            # å…ˆé ­ã® "1/7: " ã‚„ "1/7 " ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’é™¤å»
            cleaned = re.sub(r'^\d+/\d+[:\s]*', '', tweet)
            cleaned_tweets.append(cleaned)

        # æ”¹è¡Œ2ã¤ã§çµåˆ
        return "\n\n".join(cleaned_tweets)

    def _generate_conversion_prompt(
        self,
        full_text: str,
        target_length: Tuple[int, int],
        emoji_count: Tuple[int, int],
        informal_count: Tuple[int, int]
    ) -> str:
        """LLMå¤‰æ›ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""

        informal_examples = ", ".join(
            f'ã€Œ{expr}ã€' for expr in self.tone_manner['casual_expressions'][:5]
        )
        emoji_examples = {
            'hook': ", ".join(self.emoji_strategy['examples']['attention'][:3]),
            'insight': ", ".join(self.emoji_strategy['examples']['insight'][:3]),
            'cta': ", ".join(self.emoji_strategy['examples']['cta'][:3])
        }

        prompt = f"""
ä»¥ä¸‹ã®XæŠ•ç¨¿ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’Threadså‘ã‘ã«æœ€é©åŒ–ã—ã¦ãã ã•ã„ã€‚

**è¦ä»¶ï¼ˆå³æ ¼ï¼‰**:

1. **æ–‡å­—æ•°**: {target_length[0]}-{target_length[1]}å­—ï¼ˆå³å®ˆï¼‰
2. **æ®µè½æ§‹æˆ**: 2-4æ®µè½ï¼ˆæ”¹è¡Œã¯1è¡Œã®ã¿ã€ç©ºç™½2è¡Œã¯ç¦æ­¢ï¼‰
3. **çµµæ–‡å­—**: {emoji_count[0]}-{emoji_count[1]}å€‹
   - Hookä½ç½®: {emoji_examples['hook']} ã‹ã‚‰1å€‹
   - Insightä½ç½®: {emoji_examples['insight']} ã‹ã‚‰1å€‹
   - CTAä½ç½®: {emoji_examples['cta']} ã‹ã‚‰1-2å€‹
4. **å£èªä½“**: {informal_count[0]}-{informal_count[1]}å›ä½¿ç”¨
   - ä¾‹: {informal_examples}
5. **ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°**: 1å€‹ã®ã¿ï¼ˆãƒˆãƒ”ãƒƒã‚¯ã‚¿ã‚°ï¼‰
   - AIé–¢é€£ãªã‚‰ #AIã€ãƒ“ã‚¸ãƒã‚¹é–¢é€£ãªã‚‰ #ãƒ“ã‚¸ãƒã‚¹
6. **å•ã„ã‹ã‘çµ‚çµ**: å¿…é ˆï¼ˆ100%ç¾©å‹™åŒ–ï¼‰

**èª¿æ•´ãƒã‚¤ãƒ³ãƒˆ**:
- Xç‰ˆã®è©³ç´°ãªå±•é–‹ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ï¼ˆè¦ç´„ï¼‰
- ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã¯3-5å€‹ã«çµã‚‹ï¼ˆå„100å­—ä»¥å†…ï¼‰
- æ–­å®šå‹è¡¨ç¾ã‚’ç¶­æŒï¼ˆã€Œã¤ã¾ã‚Šã€ã€Œãƒã‚¤ãƒ³ãƒˆã¯ã€ï¼‰
- ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãªãƒˆãƒ¼ãƒ³ã§Threadsãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼ˆ20-40ä»£è‹¥å¹´å±¤ï¼‰ã«è¨´æ±‚

**ç¦æ­¢äº‹é …**:
- ç©ºç™½2è¡Œä»¥ä¸Šã®æ”¹è¡Œï¼ˆè‡ªå‹•ãƒ„ãƒªãƒ¼åŒ–ã•ã‚Œã‚‹ï¼‰
- ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°è¤‡æ•°ç¾…åˆ—ï¼ˆ#AI #ChatGPT #OpenAIï¼‰
- çµµæ–‡å­—éå¤šï¼ˆ10å€‹ä»¥ä¸Šï¼‰
- ã‚¿ã‚¤ãƒˆãƒ«+æœ¬æ–‡ã®äºŒé‡æ§‹é€ 
- æ–‡å­—æ•°ä¸è¶³ï¼ˆ300å­—æœªæº€ï¼‰

**å…ƒã®XæŠ•ç¨¿**:
{full_text}

**å‡ºåŠ›å½¢å¼**ï¼ˆã“ã®å½¢å¼ã‚’å³å®ˆï¼‰:
[ThreadsæŠ•ç¨¿æœ¬æ–‡ã®ã¿ã€å‰å¾Œã®èª¬æ˜ãªã—]
        """

        return prompt

    def _convert_via_llm(self, prompt: str, full_text: str) -> str:
        """
        LLMçµŒç”±ã§å¤‰æ›ã‚’å®Ÿè¡Œ

        å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€Claude APIã¾ãŸã¯OpenAI APIã‚’å‘¼ã³å‡ºã—ã¾ã™ã€‚
        ã“ã“ã§ã¯ç°¡æ˜“çš„ãªå¤‰æ›å‡¦ç†ã‚’è¨˜è¿°ã—ã¾ã™ã€‚

        Args:
            prompt: LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            full_text: å…ƒã®XæŠ•ç¨¿å…¨æ–‡

        Returns:
            Threadsç‰ˆæŠ•ç¨¿æœ¬æ–‡
        """
        # TODO: å®Ÿéš›ã®LLM APIå‘¼ã³å‡ºã—å®Ÿè£…
        # ä¾‹:
        # import anthropic
        # client = anthropic.Anthropic(api_key=os.environ.get("ANTHROPIC_API_KEY"))
        # message = client.messages.create(
        #     model="claude-sonnet-4-5-20250929",
        #     max_tokens=2000,
        #     messages=[{"role": "user", "content": prompt}]
        # )
        # return message.content[0].text

        # æš«å®šå®Ÿè£…: ç°¡æ˜“çš„ãªå¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯
        threads_content = self._simple_conversion(full_text)
        return threads_content

    def _simple_conversion(self, full_text: str) -> str:
        """
        ç°¡æ˜“çš„ãªå¤‰æ›å‡¦ç†ï¼ˆãƒ†ã‚¹ãƒˆç”¨ãƒ»å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ï¼‰

        Threadsæœ€é©åŒ–:
        - 300-500å­—ã«è¦ç´„
        - 2-4æ®µè½æ§‹æˆ
        - 3-5å€‹ã®çµµæ–‡å­—è¿½åŠ 
        - å£èªä½“è¡¨ç¾è¿½åŠ 
        - å•ã„ã‹ã‘çµ‚çµ
        """
        # æ”¹è¡Œãƒ»ç©ºç™½ã‚’é™¤å»ã—ã¦æ­£è¦åŒ–
        normalized = re.sub(r'\s+', ' ', full_text).strip()

        # 1. æ–‡ã‚’åˆ†å‰²ï¼ˆå¥ç‚¹ã§åˆ†å‰²ã—ã€æ”¹è¡Œãƒ»ç®‡æ¡æ›¸ãã‚’é™¤å»ï¼‰
        sentences = []
        for s in normalized.split('ã€‚'):
            s = s.strip()
            # ç®‡æ¡æ›¸ãè¨˜å·ã‚’é™¤å»
            s = re.sub(r'^[-ãƒ»\*]\s*', '', s)
            if s and len(s) > 5:  # 5æ–‡å­—æœªæº€ã®æ–­ç‰‡ã¯ç„¡è¦–
                sentences.append(s)

        # 2. é‡è¦ãªæ–‡ã‚’é¸æŠï¼ˆæœ€å¤§4æ–‡ï¼‰
        if len(sentences) >= 4:
            selected = [
                sentences[0],  # å°å…¥
                sentences[1],  # è©³ç´°
                sentences[len(sentences)//2],  # ä¸­ç›¤
                sentences[-1]  # çµè«–
            ]
        elif len(sentences) >= 2:
            selected = [sentences[0], sentences[-1]]
        else:
            selected = sentences[:1]

        # 3. æ®µè½æ§‹æˆï¼ˆ3æ®µè½: Hook + Main + CTAï¼‰
        # Hookãƒ‘ãƒ¼ãƒˆï¼ˆå°å…¥ + çµµæ–‡å­—ï¼‰
        hook = f"ğŸš¨ {selected[0]}ã€‚"
        if len(selected) >= 2:
            hook += f"{selected[1]}ã€‚"

        # Mainãƒ‘ãƒ¼ãƒˆï¼ˆè©³ç´° + çµµæ–‡å­—ï¼‰
        if len(selected) >= 3:
            main = f"ğŸ’¡ {selected[2]}ã€‚"
            if len(selected) >= 4:
                main += f"{selected[3]}ã€‚"
        else:
            main = f"ğŸ’¡ Late APIã§ã®åŒæ™‚æŠ•ç¨¿ã‚’ãƒ†ã‚¹ãƒˆã—ã¦ã„ã¾ã™ã€‚"

        # 4. å£èªä½“è¿½åŠ 
        hook = hook.replace('ã§ã™', 'ãƒã‚¸ã§ã™', 1)

        # 5. CTAãƒ‘ãƒ¼ãƒˆï¼ˆãƒãƒƒã‚·ãƒ¥ã‚¿ã‚° + å•ã„ã‹ã‘ï¼‰
        cta = "#ãƒ†ã‚¹ãƒˆ\n\nã©ã†æ€ã„ã¾ã™ã‹ï¼ŸğŸ¤”"

        # 6. çµåˆï¼ˆ3æ®µè½: \n\nãŒ2ç®‡æ‰€ â†’ paragraph_count=3ï¼‰
        result = f"{hook}\n\n{main}\n\n{cta}"

        return result

    def _validate_and_extract_metrics(
        self,
        content: str,
        target_length: Tuple[int, int],
        emoji_count_range: Tuple[int, int],
        informal_count_range: Tuple[int, int]
    ) -> Dict:
        """
        ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ¤œè¨¼ã—ã€ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’æŠ½å‡º

        Args:
            content: ThreadsæŠ•ç¨¿æœ¬æ–‡
            target_length: ç›®æ¨™æ–‡å­—æ•°ç¯„å›²
            emoji_count_range: çµµæ–‡å­—æ•°ç¯„å›²
            informal_count_range: å£èªä½“å›æ•°ç¯„å›²

        Returns:
            æ¤œè¨¼çµæœã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹

        Raises:
            ValueError: æ¤œè¨¼å¤±æ•—æ™‚
        """
        # 1. æ–‡å­—æ•°ã‚«ã‚¦ãƒ³ãƒˆ
        char_count = len(content)

        # 2. çµµæ–‡å­—ã‚«ã‚¦ãƒ³ãƒˆ
        emoji_count = self._count_emojis(content)

        # 3. å£èªä½“æŠ½å‡º
        informal_expressions = self._extract_informal_expressions(content)

        # 4. æ®µè½æ•°ã‚«ã‚¦ãƒ³ãƒˆ
        paragraph_count = content.count('\n\n') + 1

        # 5. ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°æŠ½å‡º
        hashtag_match = re.search(r'#\w+', content)
        hashtag = hashtag_match.group(0) if hashtag_match else None

        # æ¤œè¨¼
        errors = []

        if not (target_length[0] <= char_count <= target_length[1]):
            errors.append(
                f"æ–‡å­—æ•°ã‚¨ãƒ©ãƒ¼: {char_count}å­—ï¼ˆç›®æ¨™: {target_length[0]}-{target_length[1]}å­—ï¼‰"
            )

        if not (emoji_count_range[0] <= emoji_count <= emoji_count_range[1]):
            errors.append(
                f"çµµæ–‡å­—æ•°ã‚¨ãƒ©ãƒ¼: {emoji_count}å€‹ï¼ˆç›®æ¨™: {emoji_count_range[0]}-{emoji_count_range[1]}å€‹ï¼‰"
            )

        if not (2 <= paragraph_count <= 4):
            errors.append(
                f"æ®µè½æ•°ã‚¨ãƒ©ãƒ¼: {paragraph_count}æ®µè½ï¼ˆç›®æ¨™: 2-4æ®µè½ï¼‰"
            )

        if '\n\n\n' in content:
            errors.append("ç©ºç™½2è¡Œä»¥ä¸Šã®æ”¹è¡Œæ¤œå‡ºï¼ˆè‡ªå‹•ãƒ„ãƒªãƒ¼åŒ–ã®åŸå› ï¼‰")

        if len(re.findall(r'#\w+', content)) > 1:
            errors.append(f"ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°éå¤š: {len(re.findall(r'#\w+', content))}å€‹ï¼ˆæœ€å¤§1å€‹ï¼‰")

        if not content.endswith('ï¼Ÿ') and not content.endswith('ğŸ¤”') and not 'ï¼Ÿ' in content[-50:]:
            errors.append("å•ã„ã‹ã‘çµ‚çµãªã—ï¼ˆå¿…é ˆï¼‰")

        if errors:
            raise ValueError(f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼:\n" + "\n".join(f"- {e}" for e in errors))

        return {
            "content": content,
            "character_count": char_count,
            "emoji_count": emoji_count,
            "informal_expressions": informal_expressions,
            "paragraph_count": paragraph_count,
            "hashtag": hashtag,
            "validation_passed": True
        }

    def _count_emojis(self, text: str) -> int:
        """çµµæ–‡å­—ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ"""
        emoji_count = 0
        for char in text:
            # Unicodeçµµæ–‡å­—ã®ç¯„å›²ã‚’ãƒã‚§ãƒƒã‚¯
            if unicodedata.category(char) == 'So':  # Symbol, other
                emoji_count += 1
        return emoji_count

    def _extract_informal_expressions(self, text: str) -> List[str]:
        """å£èªä½“è¡¨ç¾ã‚’æŠ½å‡º"""
        informal_list = self.tone_manner['casual_expressions']
        found_expressions = []

        for expr in informal_list:
            if expr in text:
                # å‡ºç¾å›æ•°ã‚‚ã‚«ã‚¦ãƒ³ãƒˆ
                count = text.count(expr)
                found_expressions.extend([expr] * count)

        return found_expressions


def convert_x_to_threads_simple(
    x_thread: List[str],
    config_path: str = None
) -> Dict:
    """
    Xç‰ˆã‚¹ãƒ¬ãƒƒãƒ‰ã‚’Threadsç‰ˆã«å¤‰æ›ï¼ˆç°¡æ˜“ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰

    Args:
        x_thread: Xã‚¹ãƒ¬ãƒƒãƒ‰ã®å„ãƒ„ã‚¤ãƒ¼ãƒˆï¼ˆãƒªã‚¹ãƒˆï¼‰
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

    Returns:
        å¤‰æ›çµæœï¼ˆè¾æ›¸ï¼‰

    Example:
        >>> x_thread = [
        ...     "1/3: ã“ã‚ŒãŒãƒ†ã‚¹ãƒˆã§ã™",
        ...     "2/3: è©³ç´°èª¬æ˜",
        ...     "3/3: çµè«–"
        ... ]
        >>> result = convert_x_to_threads_simple(x_thread)
        >>> print(result['content'])
    """
    adapter = ThreadsAdapter(config_path)
    return adapter.convert_x_to_threads(x_thread)


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_thread = [
        "1/7: ğŸš¨ OpenAIãŒã€Œã²ã£ãã‚Šå…¬é–‹ã€ã—ãŸGPT-5.2ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¬ã‚¤ãƒ‰ã€ã“ã‚Œã‚¬ãƒã§ãƒ¤ãƒã„ã§ã™",
        "2/7: ã¤ã¾ã‚Šã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ã€Œå¸¸è­˜ã€ãŒæ ¹åº•ã‹ã‚‰å¤‰ã‚ã‚Šã¤ã¤ã‚ã‚‹ã¨ã„ã†ã“ã¨ã€‚",
        "3/7: ãƒã‚¤ãƒ³ãƒˆã¯3ã¤ï¼šâ‘ æ˜ç¢ºæ€§ã®å®šç¾©ãŒå¤‰åŒ– â‘¡ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®é‡è¦æ€§ãŒ3å€ã« â‘¢å†ç¾æ€§ã®æ‹…ä¿æ–¹æ³•",
        "4/7: å…·ä½“ä¾‹ï¼šã€Œæ–‡ç« ã‚’è¦ç´„ã—ã¦ã€â†’ã€Œæ¬¡ã®æ–‡ç« ã‚’150å­—ä»¥å†…ã§è¦ç´„ã€‚é‡è¦åº¦é †ã«ç®‡æ¡æ›¸ãã€‚ã€",
        "5/7: ãƒ‡ãƒ¼ã‚¿ã§è¦‹ã‚‹ã¨ã€æ–°ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³æº–æ‹ ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯å‡ºåŠ›å“è³ªãŒå¹³å‡47%å‘ä¸Šï¼ˆOpenAIå†…éƒ¨æ¤œè¨¼ï¼‰",
        "6/7: æ³¨ç›®ã™ã¹ãã¯ã€ã“ã®ã‚¬ã‚¤ãƒ‰ãŒGPT-4ã§ã¯ã€Œæ¨å¥¨ã€ã ã£ãŸã®ãŒGPT-5.2ã§ã¯ã€Œå¿…é ˆã€ã«æ ¼ä¸Šã’ã•ã‚ŒãŸç‚¹ã€‚",
        "7/7: ã‚ãªãŸã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ã‚‚ã†å¤ã„ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚æœ€æ–°ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã€ãƒã‚§ãƒƒã‚¯ã—ã¾ã—ãŸã‹ï¼Ÿ"
    ]

    try:
        result = convert_x_to_threads_simple(test_thread)
        print("=" * 50)
        print("âœ… å¤‰æ›æˆåŠŸ")
        print("=" * 50)
        print(f"æ–‡å­—æ•°: {result['character_count']}å­—")
        print(f"çµµæ–‡å­—: {result['emoji_count']}å€‹")
        print(f"å£èªä½“: {len(result['informal_expressions'])}å›")
        print(f"æ®µè½æ•°: {result['paragraph_count']}æ®µè½")
        print(f"ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°: {result['hashtag']}")
        print("=" * 50)
        print("ã€ThreadsæŠ•ç¨¿æœ¬æ–‡ã€‘")
        print(result['content'])
        print("=" * 50)
    except ValueError as e:
        print(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼:\n{e}")
    except Exception as e:
        print(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼:\n{e}")
