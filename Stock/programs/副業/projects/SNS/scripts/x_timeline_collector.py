#!/usr/bin/env python3
"""
X Timeline Collector
====================

AIæ¥­ç•Œã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼50åã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’ç›£è¦–ã—ã€
é«˜ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã‚’è‡ªå‹•åé›†ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

ä¸»è¦æ©Ÿèƒ½:
- Twitter API v2ã§ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å–å¾—
- ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã«ã‚ˆã‚‹ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆimp>1000, ER>5%, 24æ™‚é–“ä»¥å†…ï¼‰
- ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°: (likes + RTs + replies) / impressions
- ä¸Šä½5-10ä»¶ã®æŠ•ç¨¿ã‚’æŠ½å‡º
- JSONå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿ä¿å­˜

ä½¿ç”¨æ–¹æ³•:
    python x_timeline_collector.py --config ../config/automation_config.yaml --output ../data/x_timeline_$(date +%Y%m%d).json

å¿…é ˆç’°å¢ƒå¤‰æ•°:
    TWITTER_API_KEY: Twitter API Key
    TWITTER_API_SECRET: Twitter API Secret
    TWITTER_ACCESS_TOKEN: Twitter Access Token
    TWITTER_ACCESS_SECRET: Twitter Access Token Secret
    TWITTER_BEARER_TOKEN: Twitter Bearer Token (API v2ç”¨)

ä½œæˆæ—¥: 2026-01-01
ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: SNSé‹ç”¨æˆ¦ç•¥ Month 1 Week 1
"""

import os
import sys
import json
import yaml
import logging
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass, asdict
import argparse

# Twitter API v2ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆtweepyã‚’ä½¿ç”¨ï¼‰
try:
    import tweepy
except ImportError:
    print("âŒ tweepyãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    print("   ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install tweepy")
    sys.exit(1)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


@dataclass
class Tweet:
    """ãƒ„ã‚¤ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹"""
    tweet_id: str
    author_id: str
    author_username: str
    author_name: str
    text: str
    created_at: str
    impressions: int
    likes: int
    retweets: int
    replies: int
    engagement_rate: float
    engagement_score: float
    url: str


class XTimelineCollector:
    """Xã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼"""

    def __init__(self, config_path: Optional[Path] = None):
        """
        åˆæœŸåŒ–

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆautomation_config.yamlï¼‰
        """
        self.config = self._load_config(config_path)
        self.client = self._initialize_api_client()
        self.influencers = self.config.get('influencers', [])
        self.filters = self.config.get('filters', {})

    def _load_config(self, config_path: Optional[Path]) -> Dict:
        """
        è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿

        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            è¨­å®šè¾æ›¸
        """
        if config_path and config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            logger.info(f"âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {config_path}")
            return config
        else:
            logger.warning("âš ï¸  è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return self._default_config()

    def _default_config(self) -> Dict:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š"""
        return {
            'influencers': [],
            'filters': {
                'min_impressions': 1000,
                'min_engagement_rate': 0.05,  # 5%
                'time_window_hours': 24,
                'top_n': 10
            }
        }

    def _initialize_api_client(self) -> tweepy.Client:
        """
        Twitter API v2ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–

        Returns:
            tweepy.Client ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹

        Raises:
            ValueError: ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆ
        """
        bearer_token = os.environ.get('TWITTER_BEARER_TOKEN')

        if not bearer_token:
            raise ValueError(
                "âŒ TWITTER_BEARER_TOKENç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n"
                "   .envãƒ•ã‚¡ã‚¤ãƒ«ã«ä»¥ä¸‹ã‚’è¿½åŠ ã—ã¦ãã ã•ã„:\n"
                "   TWITTER_BEARER_TOKEN=your_bearer_token_here"
            )

        client = tweepy.Client(
            bearer_token=bearer_token,
            wait_on_rate_limit=True
        )
        logger.info("âœ… Twitter API v2ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
        return client

    def fetch_user_timeline(self, username: str, max_results: int = 100) -> List[Dict]:
        """
        ç‰¹å®šãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å–å¾—

        Args:
            username: Xãƒ¦ãƒ¼ã‚¶ãƒ¼åï¼ˆ@ãªã—ï¼‰
            max_results: å–å¾—æœ€å¤§ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ100ã€æœ€å¤§100ï¼‰

        Returns:
            ãƒ„ã‚¤ãƒ¼ãƒˆãƒªã‚¹ãƒˆ
        """
        try:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼IDå–å¾—
            user = self.client.get_user(username=username)
            if not user.data:
                logger.warning(f"âš ï¸  ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: @{username}")
                return []

            user_id = user.data.id

            # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å–å¾—ï¼ˆéå»24æ™‚é–“ï¼‰
            cutoff_time = datetime.now(timezone.utc) - timedelta(
                hours=self.filters['time_window_hours']
            )

            tweets = self.client.get_users_tweets(
                id=user_id,
                max_results=max_results,
                tweet_fields=[
                    'created_at', 'public_metrics', 'author_id',
                    'conversation_id', 'entities'
                ],
                expansions=['author_id'],
                start_time=cutoff_time.isoformat()
            )

            if not tweets.data:
                logger.info(f"   @{username}: æ–°è¦ãƒ„ã‚¤ãƒ¼ãƒˆãªã—ï¼ˆ24æ™‚é–“ä»¥å†…ï¼‰")
                return []

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±å–å¾—
            users_dict = {user.id: user for user in tweets.includes.get('users', [])}

            tweet_list = []
            for tweet in tweets.data:
                author = users_dict.get(tweet.author_id)
                metrics = tweet.public_metrics

                # ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°ï¼ˆAPI v2ã§ã¯å–å¾—ä¸å¯ã®ãŸã‚ã€è¿‘ä¼¼å€¤ã‚’ä½¿ç”¨ï¼‰
                # å®Ÿéš›ã«ã¯X Premium APIã¾ãŸã¯Analytics APIãŒå¿…è¦
                # ã“ã“ã§ã¯ likes + retweets + replies ã‚’åŸºã«ã—ãŸæ¨å®šå€¤ã‚’ä½¿ç”¨
                estimated_impressions = self._estimate_impressions(metrics)

                tweet_data = {
                    'tweet_id': tweet.id,
                    'author_id': tweet.author_id,
                    'author_username': author.username if author else username,
                    'author_name': author.name if author else username,
                    'text': tweet.text,
                    'created_at': tweet.created_at.isoformat(),
                    'likes': metrics['like_count'],
                    'retweets': metrics['retweet_count'],
                    'replies': metrics['reply_count'],
                    'impressions': estimated_impressions,
                    'url': f"https://x.com/{author.username if author else username}/status/{tweet.id}"
                }
                tweet_list.append(tweet_data)

            logger.info(f"   @{username}: {len(tweet_list)}ä»¶ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’å–å¾—")
            return tweet_list

        except tweepy.errors.TweepyException as e:
            logger.error(f"âŒ @{username}ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return []

    def _estimate_impressions(self, metrics: Dict) -> int:
        """
        ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°ã®æ¨å®š

        Twitter API v2ã®ç„¡æ–™ç‰ˆã§ã¯ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°ãŒå–å¾—ã§ããªã„ãŸã‚ã€
        ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæ•°ã‹ã‚‰æ¨å®šå€¤ã‚’è¨ˆç®—ã€‚

        æ¨å®šãƒ­ã‚¸ãƒƒã‚¯:
        - ä¸€èˆ¬çš„ãªã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡: 1-3%
        - ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç·æ•° = likes + retweets + replies
        - æ¨å®šimp = ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç·æ•° / 0.02ï¼ˆ2%ã¨ä»®å®šï¼‰

        Args:
            metrics: public_metricsè¾æ›¸

        Returns:
            æ¨å®šã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°
        """
        engagement = (
            metrics['like_count'] +
            metrics['retweet_count'] +
            metrics['reply_count']
        )

        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡2%ã¨ä»®å®š
        estimated_impressions = int(engagement / 0.02) if engagement > 0 else 0

        # æœ€å°å€¤ã‚’è¨­å®šï¼ˆã‚¼ãƒ­é™¤ç®—å›é¿ï¼‰
        return max(estimated_impressions, engagement * 10)

    def calculate_engagement_metrics(self, tweet_data: Dict) -> Tweet:
        """
        ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™ã‚’è¨ˆç®—

        Args:
            tweet_data: ãƒ„ã‚¤ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿è¾æ›¸

        Returns:
            Tweetãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹
        """
        impressions = tweet_data['impressions']
        likes = tweet_data['likes']
        retweets = tweet_data['retweets']
        replies = tweet_data['replies']

        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡: (likes + RTs + replies) / impressions
        engagement_rate = (
            (likes + retweets + replies) / impressions
            if impressions > 0 else 0
        )

        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢: é‡ã¿ä»˜ã‘åˆè¨ˆ
        # ã„ã„ã­: 1å€, RT: 3å€, ãƒªãƒ—ãƒ©ã‚¤: 5å€
        engagement_score = likes + (retweets * 3) + (replies * 5)

        return Tweet(
            tweet_id=tweet_data['tweet_id'],
            author_id=tweet_data['author_id'],
            author_username=tweet_data['author_username'],
            author_name=tweet_data['author_name'],
            text=tweet_data['text'],
            created_at=tweet_data['created_at'],
            impressions=impressions,
            likes=likes,
            retweets=retweets,
            replies=replies,
            engagement_rate=engagement_rate,
            engagement_score=engagement_score,
            url=tweet_data['url']
        )

    def filter_tweets(self, tweets: List[Tweet]) -> List[Tweet]:
        """
        ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¡ä»¶ã‚’é©ç”¨

        Args:
            tweets: ãƒ„ã‚¤ãƒ¼ãƒˆãƒªã‚¹ãƒˆ

        Returns:
            ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å¾Œã®ãƒ„ã‚¤ãƒ¼ãƒˆãƒªã‚¹ãƒˆ
        """
        min_impressions = self.filters['min_impressions']
        min_engagement_rate = self.filters['min_engagement_rate']

        filtered = [
            tweet for tweet in tweets
            if (
                tweet.impressions >= min_impressions and
                tweet.engagement_rate >= min_engagement_rate
            )
        ]

        logger.info(
            f"ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµæœ: {len(tweets)}ä»¶ â†’ {len(filtered)}ä»¶ "
            f"(impâ‰¥{min_impressions}, ERâ‰¥{min_engagement_rate*100}%)"
        )
        return filtered

    def collect_all_timelines(self) -> List[Tweet]:
        """
        å…¨ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’åé›†

        Returns:
            å…¨ãƒ„ã‚¤ãƒ¼ãƒˆãƒªã‚¹ãƒˆ
        """
        all_tweets = []

        logger.info(f"ğŸ” {len(self.influencers)}åã®ã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³åé›†é–‹å§‹...")

        for influencer in self.influencers:
            username = influencer.get('username')
            if not username:
                continue

            # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³å–å¾—
            tweet_list = self.fetch_user_timeline(username)

            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™è¨ˆç®—
            for tweet_data in tweet_list:
                tweet = self.calculate_engagement_metrics(tweet_data)
                all_tweets.append(tweet)

        logger.info(f"âœ… åé›†å®Œäº†: {len(all_tweets)}ä»¶ã®ãƒ„ã‚¤ãƒ¼ãƒˆ")
        return all_tweets

    def get_top_tweets(self, tweets: List[Tweet], top_n: Optional[int] = None) -> List[Tweet]:
        """
        ä¸Šä½Nä»¶ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’å–å¾—

        Args:
            tweets: ãƒ„ã‚¤ãƒ¼ãƒˆãƒªã‚¹ãƒˆ
            top_n: å–å¾—ä»¶æ•°ï¼ˆNoneã®å ´åˆã¯è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ï¼‰

        Returns:
            ä¸Šä½ãƒ„ã‚¤ãƒ¼ãƒˆãƒªã‚¹ãƒˆ
        """
        if top_n is None:
            top_n = self.filters['top_n']

        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆ
        sorted_tweets = sorted(
            tweets,
            key=lambda t: t.engagement_score,
            reverse=True
        )

        top_tweets = sorted_tweets[:top_n]

        logger.info(f"ğŸ† ä¸Šä½{len(top_tweets)}ä»¶ã‚’æŠ½å‡ºï¼ˆã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢é †ï¼‰")
        return top_tweets

    def save_results(self, tweets: List[Tweet], output_path: Path):
        """
        çµæœã‚’JSONå½¢å¼ã§ä¿å­˜

        Args:
            tweets: ãƒ„ã‚¤ãƒ¼ãƒˆãƒªã‚¹ãƒˆ
            output_path: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        output_path.parent.mkdir(parents=True, exist_ok=True)

        data = {
            'collected_at': datetime.now(timezone.utc).isoformat(),
            'total_tweets': len(tweets),
            'tweets': [asdict(tweet) for tweet in tweets]
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        logger.info(f"ğŸ’¾ çµæœã‚’ä¿å­˜: {output_path}")

    def print_summary(self, tweets: List[Tweet]):
        """
        åé›†çµæœã®ã‚µãƒãƒªãƒ¼è¡¨ç¤º

        Args:
            tweets: ãƒ„ã‚¤ãƒ¼ãƒˆãƒªã‚¹ãƒˆ
        """
        if not tweets:
            logger.warning("âš ï¸  åé›†ã•ã‚ŒãŸãƒ„ã‚¤ãƒ¼ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        print("\n" + "="*80)
        print("ğŸ“Š åé›†çµæœã‚µãƒãƒªãƒ¼")
        print("="*80)
        print(f"ç·ãƒ„ã‚¤ãƒ¼ãƒˆæ•°: {len(tweets)}ä»¶\n")

        for i, tweet in enumerate(tweets, 1):
            print(f"ã€{i}ä½ã€‘ @{tweet.author_username}")
            print(f"   ãƒ†ã‚­ã‚¹ãƒˆ: {tweet.text[:100]}{'...' if len(tweet.text) > 100 else ''}")
            print(f"   ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³: {tweet.impressions:,}")
            print(f"   ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡: {tweet.engagement_rate*100:.2f}%")
            print(f"   ã‚¹ã‚³ã‚¢: {tweet.engagement_score:,} (â¤ï¸{tweet.likes} ğŸ”{tweet.retweets} ğŸ’¬{tweet.replies})")
            print(f"   URL: {tweet.url}")
            print()


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description='X Timeline Collector - AIæ¥­ç•Œã‚¤ãƒ³ãƒ•ãƒ«ã‚¨ãƒ³ã‚µãƒ¼ã®é«˜ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã‚’åé›†'
    )
    parser.add_argument(
        '--config',
        type=Path,
        default=Path(__file__).parent.parent / 'config' / 'automation_config.yaml',
        help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ../config/automation_config.yamlï¼‰'
    )
    parser.add_argument(
        '--output',
        type=Path,
        default=Path(__file__).parent.parent / 'data' / f'x_timeline_{datetime.now().strftime("%Y%m%d")}.json',
        help='å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ../data/x_timeline_YYYYMMDD.jsonï¼‰'
    )
    parser.add_argument(
        '--top-n',
        type=int,
        help='ä¸Šä½Nä»¶ã®ã¿ä¿å­˜ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®å€¤ï¼‰'
    )

    args = parser.parse_args()

    try:
        # ã‚³ãƒ¬ã‚¯ã‚¿ãƒ¼åˆæœŸåŒ–
        collector = XTimelineCollector(config_path=args.config)

        # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³åé›†
        all_tweets = collector.collect_all_timelines()

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_tweets = collector.filter_tweets(all_tweets)

        # ä¸Šä½Nä»¶å–å¾—
        top_tweets = collector.get_top_tweets(filtered_tweets, top_n=args.top_n)

        # çµæœä¿å­˜
        collector.save_results(top_tweets, args.output)

        # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
        collector.print_summary(top_tweets)

        logger.info("âœ… åé›†å‡¦ç†ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸã€‚")

    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}", exc_info=True)
        sys.exit(1)


if __name__ == '__main__':
    main()
