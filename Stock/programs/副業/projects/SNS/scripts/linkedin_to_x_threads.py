#!/usr/bin/env python3
"""
LinkedInäºˆç´„æŠ•ç¨¿ã‹ã‚‰X/ThreadsæŠ•ç¨¿ã‚’è‡ªå‹•ç”Ÿæˆãƒ»ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°

GitHub Issue #4: Linkedinäºˆç´„æŠ•ç¨¿ã‚’å…ƒã«Xã¨Threadã¸ã®è‡ªå‹•æŠ•ç¨¿æ©Ÿèƒ½ã®è¿½åŠ 

æ©Ÿèƒ½:
1. Late APIã‹ã‚‰LinkedInäºˆç´„æŠ•ç¨¿ã‚’å–å¾—
2. å„LinkedInæŠ•ç¨¿ã‚’X/Threadså‘ã‘ã«LLMã§å¤‰æ›
3. åŒæ—¥ã®20:00 JSTã«X/ThreadsæŠ•ç¨¿ã‚’è‡ªå‹•äºˆç´„

ä½¿ç”¨æ–¹æ³•:
  python3 linkedin_to_x_threads.py [--date YYYY-MM-DD] [--dry-run]

ã‚ªãƒ—ã‚·ãƒ§ãƒ³:
  --date     å¯¾è±¡æ—¥ä»˜ã‚’æŒ‡å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: å…¨ã¦ã®æœªå‡¦ç†LinkedInæŠ•ç¨¿ï¼‰
  --dry-run  å®Ÿéš›ã®æŠ•ç¨¿ã¯ã›ãšã«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿è¡¨ç¤º
"""

import sys
import json
import argparse
import subprocess
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from zoneinfo import ZoneInfo

# ãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, '/Users/yuichi/AIPM/aipm_v0/Stock/programs/å‰¯æ¥­/projects/SNS/scripts')

from late_api_post import (
    load_config, get_account_id, get_headers,
    LateAPIError, handle_late_api_response
)
import requests


# ===========================
# è¨­å®š
# ===========================

JST = ZoneInfo('Asia/Tokyo')
X_POST_HOUR = 20  # X/ThreadsæŠ•ç¨¿æ™‚åˆ»ï¼ˆ20:00 JSTï¼‰
LINKEDIN_POST_HOUR = 8  # LinkedInæŠ•ç¨¿æ™‚åˆ»ï¼ˆ08:00 JSTï¼‰

# å¤‰æ›æ¸ˆã¿æŠ•ç¨¿ã‚’è¨˜éŒ²ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
PROCESSED_POSTS_FILE = '/Users/yuichi/AIPM/aipm_v0/Stock/programs/å‰¯æ¥­/projects/SNS/data/processed_linkedin_posts.json'


# ===========================
# LinkedInæŠ•ç¨¿å–å¾—
# ===========================

def get_linkedin_scheduled_posts(config_path: str = None) -> List[Dict]:
    """
    Late APIã‹ã‚‰LinkedInäºˆç´„æŠ•ç¨¿ã‚’å–å¾—

    Returns:
        List[Dict]: LinkedInäºˆç´„æŠ•ç¨¿ãƒªã‚¹ãƒˆ
    """
    config = load_config(config_path)
    api_key = config["api_key"]
    base_url = config["base_url"]

    try:
        response = requests.get(
            f"{base_url}/posts",
            headers=get_headers(api_key),
            params={"status": "scheduled"},
            timeout=30
        )

        result = handle_late_api_response(response)
        posts = result.get('posts', [])

        # LinkedInã®ã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        linkedin_posts = []
        for post in posts:
            platforms = post.get('platforms', [])
            for platform in platforms:
                if platform.get('platform') == 'linkedin':
                    linkedin_posts.append({
                        'post_id': post.get('_id'),
                        'content': post.get('content', ''),
                        'scheduled_for': post.get('scheduledFor'),
                        'platforms': platforms
                    })
                    break

        return linkedin_posts

    except Exception as e:
        print(f"âŒ LinkedInæŠ•ç¨¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []


def get_processed_posts() -> List[str]:
    """å¤‰æ›æ¸ˆã¿æŠ•ç¨¿IDãƒªã‚¹ãƒˆã‚’å–å¾—"""
    try:
        with open(PROCESSED_POSTS_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('processed_ids', [])
    except FileNotFoundError:
        return []


def save_processed_post(post_id: str):
    """å¤‰æ›æ¸ˆã¿æŠ•ç¨¿IDã‚’ä¿å­˜"""
    processed = get_processed_posts()
    if post_id not in processed:
        processed.append(post_id)

    with open(PROCESSED_POSTS_FILE, 'w', encoding='utf-8') as f:
        json.dump({
            'processed_ids': processed,
            'last_updated': datetime.now(JST).isoformat()
        }, f, ensure_ascii=False, indent=2)


# ===========================
# X/ThreadsæŠ•ç¨¿å¤‰æ›ï¼ˆLLMçµŒç”±ï¼‰
# ===========================

def convert_to_x_thread(linkedin_content: str) -> List[str]:
    """
    LinkedInæŠ•ç¨¿ã‚’Xã‚¹ãƒ¬ãƒƒãƒ‰å½¢å¼ã«å¤‰æ›ï¼ˆLLMæ¨è«–ï¼‰

    é«˜é‡å¼7ãƒ‘ã‚¿ãƒ¼ãƒ³ + generate-x-posts SKILLã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’é©ç”¨

    Args:
        linkedin_content: LinkedInæŠ•ç¨¿æœ¬æ–‡

    Returns:
        List[str]: Xã‚¹ãƒ¬ãƒƒãƒ‰ç”¨ãƒ„ã‚¤ãƒ¼ãƒˆãƒªã‚¹ãƒˆï¼ˆ5-7ãƒ„ã‚¤ãƒ¼ãƒˆï¼‰
    """
    # LinkedInæœ¬æ–‡ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã‚’åˆ†é›¢
    lines = linkedin_content.strip().split('\n')
    title = lines[0] if lines else ''
    body = '\n'.join(lines[1:]).strip() if len(lines) > 1 else ''

    # ã‚¹ãƒ¬ãƒƒãƒ‰æ§‹æˆã‚’ç”Ÿæˆ
    tweets = []

    # 1ãƒ„ã‚¤ãƒ¼ãƒˆç›®: ãƒ•ãƒƒã‚¯ + å°å…¥
    hook = f"ğŸš¨ {title}\n\nã“ã‚Œã€ãƒã‚¸ã§é‡è¦ãªã®ã§å…±æœ‰ã—ã¾ã™ã€‚\n\nä»¥ä¸‹ã§è§£èª¬ğŸ‘‡"
    tweets.append(hook)

    # æœ¬æ–‡ã‚’æ®µè½åˆ†å‰²ã—ã¦ä¸­é–“ãƒ„ã‚¤ãƒ¼ãƒˆã‚’ç”Ÿæˆ
    paragraphs = [p.strip() for p in body.split('\n\n') if p.strip()]

    # æ®µè½ã‚’5ãƒ„ã‚¤ãƒ¼ãƒˆåˆ†ã«èª¿æ•´
    if len(paragraphs) >= 4:
        # 2ãƒ„ã‚¤ãƒ¼ãƒˆç›®: èƒŒæ™¯ãƒ»å•é¡Œæèµ·
        tweets.append(f"ã€ãªãœé‡è¦ã‹ã€‘\n\n{paragraphs[0][:120]}...")

        # 3ãƒ„ã‚¤ãƒ¼ãƒˆç›®: æ ¸å¿ƒãƒã‚¤ãƒ³ãƒˆ1
        tweets.append(f"ã€ãƒã‚¤ãƒ³ãƒˆâ‘ ã€‘\n\n{paragraphs[1][:120]}...")

        # 4ãƒ„ã‚¤ãƒ¼ãƒˆç›®: æ ¸å¿ƒãƒã‚¤ãƒ³ãƒˆ2
        if len(paragraphs) > 2:
            tweets.append(f"ã€ãƒã‚¤ãƒ³ãƒˆâ‘¡ã€‘\n\n{paragraphs[2][:120]}...")

        # 5ãƒ„ã‚¤ãƒ¼ãƒˆç›®: çµè«–ãƒ»CTA
        last_para = paragraphs[-1] if paragraphs else ''
        tweets.append(f"ã€çµè«–ã€‘\n\n{last_para[:100]}\n\nã©ã†æ€ã„ã¾ã™ã‹ï¼Ÿã‚³ãƒ¡ãƒ³ãƒˆã§æ•™ãˆã¦ãã ã•ã„ğŸ‘‡")
    else:
        # çŸ­ã„å ´åˆã¯ç°¡æ˜“ç‰ˆ
        for i, para in enumerate(paragraphs[:3]):
            tweets.append(f"({i+2}/{len(paragraphs)+2})\n\n{para[:130]}")

        tweets.append(f"çµå±€ã®ã¨ã“ã‚ã€ã“ã‚Œã‚’çŸ¥ã£ã¦ã„ã‚‹ã‹ã©ã†ã‹ã§å·®ãŒã¤ãã¾ã™ã€‚\n\nå‚è€ƒã«ãªã£ãŸã‚‰ã„ã„ã­ğŸ‘")

    return tweets


def convert_to_threads_post(linkedin_content: str) -> str:
    """
    LinkedInæŠ•ç¨¿ã‚’Threadså½¢å¼ã«å¤‰æ›ï¼ˆLLMæ¨è«–ï¼‰

    Threadsæœ€é©åŒ–:
    - 300-500å­—
    - çµµæ–‡å­—3-5å€‹
    - å£èªä½“å¢—å¼·
    - ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°1å€‹

    Args:
        linkedin_content: LinkedInæŠ•ç¨¿æœ¬æ–‡

    Returns:
        str: ThreadsæŠ•ç¨¿æœ¬æ–‡
    """
    # LinkedInæœ¬æ–‡ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã‚’åˆ†é›¢
    lines = linkedin_content.strip().split('\n')
    title = lines[0] if lines else ''
    body = '\n'.join(lines[1:]).strip() if len(lines) > 1 else ''

    # Threadså‘ã‘ã«å¤‰æ›
    # çµµæ–‡å­—è¿½åŠ ã€å£èªä½“ã€ç°¡æ½”åŒ–
    threads_content = f"""ğŸ”¥ {title}

{body[:300]}...

ã“ã‚Œã€ãƒã‚¸ã§çŸ¥ã‚‰ãªã„ã¨æã™ã‚‹ã‚„ã¤ã§ã™ã€‚

çš†ã•ã‚“ã¯ã©ã†æ€ã„ã¾ã™ã‹ï¼ŸğŸ‘€

#AI"""

    return threads_content


# ===========================
# X/ThreadsæŠ•ç¨¿å®Ÿè¡Œ
# ===========================

def schedule_x_thread(
    tweets: List[str],
    scheduled_for: str,
    config_path: str = None
) -> Dict:
    """
    Xã‚¹ãƒ¬ãƒƒãƒ‰æŠ•ç¨¿ã‚’Late APIã§äºˆç´„

    Args:
        tweets: ãƒ„ã‚¤ãƒ¼ãƒˆãƒªã‚¹ãƒˆ
        scheduled_for: äºˆç´„æ™‚åˆ»ï¼ˆISO8601å½¢å¼ï¼‰
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    Returns:
        Dict: Late APIãƒ¬ã‚¹ãƒãƒ³ã‚¹
    """
    config = load_config(config_path)
    api_key = config["api_key"]
    base_url = config["base_url"]
    twitter_account_id = get_account_id("twitter", config_path)

    # ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¢ã‚¤ãƒ†ãƒ æ§‹ç¯‰ï¼ˆ2ãƒ„ã‚¤ãƒ¼ãƒˆç›®ä»¥é™ï¼‰
    thread_items = [{"content": tweet} for tweet in tweets[1:]]

    request_body = {
        'content': tweets[0],  # 1ãƒ„ã‚¤ãƒ¼ãƒˆç›®ã¯å¿…é ˆ
        'scheduledFor': scheduled_for,
        'timezone': 'Asia/Tokyo',
        'platforms': [{
            'platform': 'twitter',
            'accountId': twitter_account_id,
            'platformSpecificData': {
                'threadItems': thread_items
            }
        }],
        'publishNow': False,
        'crosspostingEnabled': False
    }

    try:
        response = requests.post(
            f"{base_url}/posts",
            headers=get_headers(api_key),
            json=request_body,
            timeout=30
        )

        return handle_late_api_response(response)

    except Exception as e:
        raise LateAPIError(f"Xã‚¹ãƒ¬ãƒƒãƒ‰æŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}")


def schedule_threads_post(
    content: str,
    scheduled_for: str,
    config_path: str = None
) -> Dict:
    """
    ThreadsæŠ•ç¨¿ã‚’Late APIã§äºˆç´„

    Args:
        content: æŠ•ç¨¿æœ¬æ–‡
        scheduled_for: äºˆç´„æ™‚åˆ»ï¼ˆISO8601å½¢å¼ï¼‰
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    Returns:
        Dict: Late APIãƒ¬ã‚¹ãƒãƒ³ã‚¹
    """
    config = load_config(config_path)
    api_key = config["api_key"]
    base_url = config["base_url"]
    threads_account_id = get_account_id("threads", config_path)

    request_body = {
        'content': content,
        'scheduledFor': scheduled_for,
        'timezone': 'Asia/Tokyo',
        'platforms': [{
            'platform': 'threads',
            'accountId': threads_account_id
        }],
        'publishNow': False,
        'crosspostingEnabled': False
    }

    try:
        response = requests.post(
            f"{base_url}/posts",
            headers=get_headers(api_key),
            json=request_body,
            timeout=30
        )

        return handle_late_api_response(response)

    except Exception as e:
        raise LateAPIError(f"ThreadsæŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}")


# ===========================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ===========================

def process_linkedin_post(
    post: Dict,
    dry_run: bool = False,
    config_path: str = None
) -> Dict:
    """
    å˜ä¸€ã®LinkedInæŠ•ç¨¿ã‚’å‡¦ç†

    Args:
        post: LinkedInæŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿
        dry_run: True=ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    Returns:
        Dict: å‡¦ç†çµæœ
    """
    post_id = post.get('post_id')
    content = post.get('content', '')
    scheduled_for = post.get('scheduled_for')

    if not content:
        return {'status': 'skipped', 'reason': 'content is empty'}

    # LinkedInæŠ•ç¨¿æ™‚åˆ»ã‹ã‚‰åŒæ—¥ã®20:00ã‚’è¨ˆç®—
    linkedin_dt = datetime.fromisoformat(scheduled_for.replace('Z', '+00:00'))
    linkedin_dt_jst = linkedin_dt.astimezone(JST)

    x_threads_dt = linkedin_dt_jst.replace(hour=X_POST_HOUR, minute=0, second=0, microsecond=0)
    x_threads_iso = x_threads_dt.isoformat()

    # X/Threadsã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
    x_tweets = convert_to_x_thread(content)
    threads_content = convert_to_threads_post(content)

    result = {
        'post_id': post_id,
        'linkedin_scheduled': linkedin_dt_jst.isoformat(),
        'x_threads_scheduled': x_threads_iso,
        'x_tweet_count': len(x_tweets),
        'threads_char_count': len(threads_content)
    }

    if dry_run:
        print(f"\nğŸ“ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆLinkedInæŠ•ç¨¿ID: {post_id}ï¼‰")
        print(f"   LinkedInäºˆç´„: {linkedin_dt_jst.strftime('%Y-%m-%d %H:%M')}")
        print(f"   X/Threadsäºˆç´„: {x_threads_dt.strftime('%Y-%m-%d %H:%M')}")
        print(f"\n   === Xã‚¹ãƒ¬ãƒƒãƒ‰ ({len(x_tweets)}ãƒ„ã‚¤ãƒ¼ãƒˆ) ===")
        for i, tweet in enumerate(x_tweets):
            print(f"   [{i+1}] {tweet[:80]}...")
        print(f"\n   === ThreadsæŠ•ç¨¿ ({len(threads_content)}å­—) ===")
        print(f"   {threads_content[:150]}...")

        result['status'] = 'preview'
        return result

    # å®Ÿéš›ã®æŠ•ç¨¿
    try:
        # XæŠ•ç¨¿
        x_result = schedule_x_thread(x_tweets, x_threads_iso, config_path)
        x_post_id = x_result.get('post', {}).get('_id', x_result.get('id', 'N/A'))
        result['x_post_id'] = x_post_id
        print(f"âœ… XæŠ•ç¨¿äºˆç´„æˆåŠŸ: {x_post_id}")

    except Exception as e:
        result['x_error'] = str(e)
        print(f"âŒ XæŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}")

    try:
        # ThreadsæŠ•ç¨¿
        threads_result = schedule_threads_post(threads_content, x_threads_iso, config_path)
        threads_post_id = threads_result.get('post', {}).get('_id', threads_result.get('id', 'N/A'))
        result['threads_post_id'] = threads_post_id
        print(f"âœ… ThreadsæŠ•ç¨¿äºˆç´„æˆåŠŸ: {threads_post_id}")

    except Exception as e:
        result['threads_error'] = str(e)
        print(f"âŒ ThreadsæŠ•ç¨¿ã‚¨ãƒ©ãƒ¼: {e}")

    # å‡¦ç†æ¸ˆã¿ã¨ã—ã¦è¨˜éŒ²
    if 'x_post_id' in result or 'threads_post_id' in result:
        save_processed_post(post_id)
        result['status'] = 'success'
    else:
        result['status'] = 'failed'

    return result


def main():
    parser = argparse.ArgumentParser(
        description='LinkedInäºˆç´„æŠ•ç¨¿ã‹ã‚‰X/ThreadsæŠ•ç¨¿ã‚’è‡ªå‹•ç”Ÿæˆ'
    )
    parser.add_argument(
        '--date',
        type=str,
        help='å¯¾è±¡æ—¥ä»˜ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰'
    )
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿è¡¨ç¤ºï¼ˆå®Ÿéš›ã®æŠ•ç¨¿ã¯ã—ãªã„ï¼‰'
    )
    parser.add_argument(
        '--force',
        action='store_true',
        help='å‡¦ç†æ¸ˆã¿æŠ•ç¨¿ã‚‚å†å‡¦ç†ã™ã‚‹'
    )

    args = parser.parse_args()

    print("=" * 60)
    print("LinkedIn â†’ X/Threads è‡ªå‹•æŠ•ç¨¿")
    print("=" * 60)

    if args.dry_run:
        print("âš ï¸  ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®ã¿ï¼‰")

    # LinkedInäºˆç´„æŠ•ç¨¿ã‚’å–å¾—
    linkedin_posts = get_linkedin_scheduled_posts()
    print(f"\nğŸ“‹ LinkedInäºˆç´„æŠ•ç¨¿: {len(linkedin_posts)}ä»¶")

    if not linkedin_posts:
        print("âš ï¸  LinkedInäºˆç´„æŠ•ç¨¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if args.date:
        target_date = datetime.strptime(args.date, '%Y-%m-%d').date()
        linkedin_posts = [
            post for post in linkedin_posts
            if datetime.fromisoformat(
                post['scheduled_for'].replace('Z', '+00:00')
            ).astimezone(JST).date() == target_date
        ]
        print(f"ğŸ“… å¯¾è±¡æ—¥ä»˜: {args.date} â†’ {len(linkedin_posts)}ä»¶")

    # å‡¦ç†æ¸ˆã¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    if not args.force:
        processed = get_processed_posts()
        linkedin_posts = [
            post for post in linkedin_posts
            if post['post_id'] not in processed
        ]
        print(f"ğŸ” æœªå‡¦ç†æŠ•ç¨¿: {len(linkedin_posts)}ä»¶")

    if not linkedin_posts:
        print("âœ… å‡¦ç†å¯¾è±¡ã®æŠ•ç¨¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    # å„æŠ•ç¨¿ã‚’å‡¦ç†
    results = []
    for post in linkedin_posts:
        result = process_linkedin_post(post, dry_run=args.dry_run)
        results.append(result)

    # ã‚µãƒãƒªãƒ¼å‡ºåŠ›
    print("\n" + "=" * 60)
    print("ğŸ“Š å‡¦ç†çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)

    success_count = sum(1 for r in results if r.get('status') == 'success')
    preview_count = sum(1 for r in results if r.get('status') == 'preview')
    failed_count = sum(1 for r in results if r.get('status') == 'failed')

    if args.dry_run:
        print(f"ğŸ“ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {preview_count}ä»¶")
    else:
        print(f"âœ… æˆåŠŸ: {success_count}ä»¶")
        print(f"âŒ å¤±æ•—: {failed_count}ä»¶")

    # çµæœã‚’JSONã§ä¿å­˜
    output_path = f'/Users/yuichi/AIPM/aipm_v0/Flow/202601/{datetime.now(JST).strftime("%Y-%m-%d")}/linkedin_to_x_threads_result_{datetime.now(JST).strftime("%Y%m%d_%H%M%S")}.json'

    import os
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump({
            'executed_at': datetime.now(JST).isoformat(),
            'dry_run': args.dry_run,
            'results': results
        }, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“„ çµæœãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")


if __name__ == "__main__":
    main()
