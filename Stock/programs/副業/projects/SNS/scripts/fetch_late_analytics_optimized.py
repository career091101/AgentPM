#!/usr/bin/env python3
"""
Late API Analytics æœ€é©åŒ–ç‰ˆãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Issue Report (2026-01-10) ã§ç‰¹å®šã•ã‚ŒãŸèª²é¡Œã‚’ä¿®æ­£:
- Critical Issue #1: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åä¿®æ­£ (dateFrom/dateTo)
- High Issue #2: N+1ã‚¯ã‚¨ãƒªå•é¡Œè§£æ±º (/v1/analyticsç›´æ¥ä½¿ç”¨)
- High Issue #3: ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè£…
- High Issue #4: Dual ID Systemå¯¾å¿œ

Usage:
    python3 fetch_late_analytics_optimized.py --from-date 2026-01-01 --to-date 2026-01-10
"""

import requests
import json
import argparse
import time
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_config(config_path: Optional[str] = None) -> Dict:
    """Late APIè¨­å®šã‚’ãƒ­ãƒ¼ãƒ‰"""
    if config_path is None:
        config_path = Path(__file__).parent.parent / "config/late_api_config.json"

    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)


def get_headers(api_key: str) -> Dict:
    """APIãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼"""
    return {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }


def check_analytics_addon(base_url: str, api_key: str) -> bool:
    """
    Analytics Addonå¥‘ç´„ç¢ºèª
    
    Issue #10 å¯¾å¿œ: äº‹å‰ã«402ã‚¨ãƒ©ãƒ¼ã‚’æ¤œå‡º
    """
    try:
        response = requests.get(
            f"{base_url}/analytics",
            headers=get_headers(api_key),
            params={"postId": "dummy_check"},
            timeout=10
        )
        
        if response.status_code == 402:
            logger.error("âŒ Analytics Addonå¥‘ç´„ãŒå¿…è¦ã§ã™")
            logger.error("   https://app.getlate.dev/settings/billing ã§å¥‘ç´„ã—ã¦ãã ã•ã„")
            return False
        
        return True
    except Exception as e:
        logger.warning(f"Analytics Addonç¢ºèªä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return True  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç¶šè¡Œã‚’è¨±å¯


def fetch_analytics_page(
    base_url: str,
    api_key: str,
    from_date: str,
    to_date: str,
    platform: Optional[str] = None,
    page: int = 1,
    limit: int = 100,
    sort_by: str = "date",
    order: str = "desc"
) -> Dict:
    """
    /v1/analytics ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰1ãƒšãƒ¼ã‚¸åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    
    Issue #2 å¯¾å¿œ: /v1/analytics ã‚’ç›´æ¥ä½¿ç”¨ï¼ˆN+1å•é¡Œè§£æ±ºï¼‰
    Issue #6 å¯¾å¿œ: sortBy/order ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ´»ç”¨
    
    Args:
        base_url: Late API Base URL
        api_key: API Key
        from_date: é–‹å§‹æ—¥ (YYYY-MM-DD)
        to_date: çµ‚äº†æ—¥ (YYYY-MM-DD)
        platform: ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å (x, threads, linkedin, facebook)
        page: ãƒšãƒ¼ã‚¸ç•ªå·ï¼ˆ1ã‹ã‚‰é–‹å§‹ï¼‰
        limit: 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®ä»¶æ•°ï¼ˆ1-100ï¼‰
        sort_by: ã‚½ãƒ¼ãƒˆåŸºæº– ("date" ã¾ãŸã¯ "engagement")
        order: ã‚½ãƒ¼ãƒˆé †åº ("asc" ã¾ãŸã¯ "desc")
    
    Returns:
        APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆpostsé…åˆ—ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼‰
    """
    params = {
        "dateFrom": from_date,  # âœ… ä¿®æ­£: Late API OpenAPIä»•æ§˜ã§ã¯ dateFrom ãŒæ­£ã—ã„
        "dateTo": to_date,      # âœ… ä¿®æ­£: Late API OpenAPIä»•æ§˜ã§ã¯ dateTo ãŒæ­£ã—ã„
        "limit": limit,
        "page": page,
        "sortBy": sort_by,
        "order": order
    }
    
    if platform:
        params["platform"] = platform
    
    try:
        response = requests.get(
            f"{base_url}/analytics",
            headers=get_headers(api_key),
            params=params,
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()
        elif response.status_code == 202:
            logger.info(f"â³ Page {page} - ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­ (202)")
            return {"posts": [], "hasMore": False}
        elif response.status_code == 400:
            error_body = response.json()
            logger.error(f"âŒ ç„¡åŠ¹ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆ (400): {error_body}")
            return {"posts": [], "hasMore": False}
        elif response.status_code == 402:
            logger.error(f"âŒ Analytics Addonæœªå¥‘ç´„ (402)")
            return {"posts": [], "hasMore": False}
        elif response.status_code == 404:
            logger.warning(f"âš ï¸  ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ (404)")
            return {"posts": [], "hasMore": False}
        elif response.status_code >= 500:
            logger.error(f"âŒ ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ ({response.status_code})")
            return {"posts": [], "hasMore": False}
        else:
            logger.warning(f"âš ï¸  äºˆæœŸã—ãªã„ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}")
            return {"posts": [], "hasMore": False}
    
    except requests.exceptions.Timeout:
        logger.error(f"âŒ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (Page {page})")
        return {"posts": [], "hasMore": False}
    except Exception as e:
        logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ (Page {page}): {e}")
        return {"posts": [], "hasMore": False}


def fetch_all_analytics(
    from_date: str,
    to_date: str,
    platform: Optional[str] = None,
    config_path: Optional[str] = None,
    sort_by: str = "date",
    order: str = "desc"
) -> Dict:
    """
    å…¨æŠ•ç¨¿ã®ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ã‚’å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰
    
    Issue #3 å¯¾å¿œ: ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè£…
    
    Args:
        from_date: é–‹å§‹æ—¥ (YYYY-MM-DD)
        to_date: çµ‚äº†æ—¥ (YYYY-MM-DD)
        platform: ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ å (x, threads, linkedin, facebook)
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        sort_by: ã‚½ãƒ¼ãƒˆåŸºæº– ("date" ã¾ãŸã¯ "engagement")
        order: ã‚½ãƒ¼ãƒˆé †åº ("asc" ã¾ãŸã¯ "desc")
    
    Returns:
        ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å«ã‚€ï¼‰
    """
    config = load_config(config_path)
    api_key = config["api_key"]
    base_url = config["base_url"]

    logger.info(f"\nğŸš€ Late API Analytics æœ€é©åŒ–ç‰ˆãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")
    logger.info(f"   æœŸé–“: {from_date} ï½ {to_date}")
    if platform:
        logger.info(f"   ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {platform}")
    logger.info(f"   ã‚½ãƒ¼ãƒˆ: {sort_by} ({order})")
    logger.info("")
    
    # Analytics Addonå¥‘ç´„ç¢ºèª
    if not check_analytics_addon(base_url, api_key):
        return {
            "metadata": {
                "fetched_at": datetime.now().isoformat(),
                "period_start": from_date,
                "period_end": to_date,
                "total_posts": 0,
                "error": "Analytics Addonæœªå¥‘ç´„"
            },
            "data": []
        }
    
    # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã§ãƒ‡ãƒ¼ã‚¿å–å¾—
    all_analytics_data = []
    page = 1
    total_posts_count = 0
    
    while True:
        logger.info(f"   ğŸ“„ Page {page} ã‚’å–å¾—ä¸­...")
        
        page_data = fetch_analytics_page(
            base_url, api_key, from_date, to_date, platform,
            page=page, limit=100, sort_by=sort_by, order=order
        )
        
        posts = page_data.get("posts", [])
        
        if not posts:
            logger.info(f"   âœ… Page {page} - ãƒ‡ãƒ¼ã‚¿ãªã—ï¼ˆå–å¾—å®Œäº†ï¼‰")
            break
        
        total_posts_count += len(posts)
        logger.info(f"   âœ… Page {page} - {len(posts)}ä»¶å–å¾—ï¼ˆç´¯è¨ˆ: {total_posts_count}ä»¶ï¼‰")
        
        # å„æŠ•ç¨¿ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
        for post in posts:
            # Issue #4 å¯¾å¿œ: Dual ID System
            post_id = post.get("postId") or post.get("_id")
            is_external = post.get("isExternal", False)
            platform_post_url = post.get("platformPostUrl")
            
            analytics_obj = post.get("analytics", {})
            platform_analytics = post.get("platformAnalytics", [])
            
            # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æƒ…å ±ã‚’å–å¾—
            detected_platform = post.get("platform")
            if not detected_platform and platform_analytics:
                detected_platform = platform_analytics[0].get("platform")
            
            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ã®å–å¾—
            engagement_rate = 0
            if platform_analytics:
                engagement_rate = platform_analytics[0].get("analytics", {}).get("engagementRate", 0)
            
            # Issue #8 å¯¾å¿œ: lastUpdated ã‚’è¨˜éŒ²
            last_updated = analytics_obj.get("lastUpdated")
            
            # Issue #9 å¯¾å¿œ: å…¨æ–‡ã¨è¦ç´„ã®ä¸¡æ–¹ã‚’ä¿å­˜
            content_full = post.get("content", "")
            
            all_analytics_data.append({
                "post_id": post_id,
                "is_external": is_external,  # âœ… Issue #4 å¯¾å¿œ
                "platform_post_url": platform_post_url,  # âœ… Issue #4 å¯¾å¿œ
                "platform": detected_platform,
                "published_at": post.get("publishedAt"),
                "scheduled_for": post.get("scheduledFor"),
                "status": post.get("status"),
                "text_full": content_full,  # âœ… Issue #9 å¯¾å¿œ
                "text_preview": content_full[:100],
                "impressions": analytics_obj.get("impressions", 0),
                "engagement_rate": engagement_rate,
                "likes": analytics_obj.get("likes", 0),
                "comments": analytics_obj.get("comments", 0),
                "shares": analytics_obj.get("shares", 0),
                "reach": analytics_obj.get("reach", 0),
                "clicks": analytics_obj.get("clicks", 0),
                "views": analytics_obj.get("views", 0),
                "last_updated": last_updated,  # âœ… Issue #8 å¯¾å¿œ
                "raw_analytics": post  # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            })
        
        # æ¬¡ãƒšãƒ¼ã‚¸ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        # hasMore ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°å–å¾—ä»¶æ•°ã§åˆ¤å®š
        has_more = page_data.get("hasMore")
        if has_more is not None:
            if not has_more:
                break
        else:
            # hasMore ãŒãªã„å ´åˆã¯å–å¾—ä»¶æ•°ã§åˆ¤å®š
            if len(posts) < 100:
                break
        
        page += 1
        
        # Rate Limitå¯¾ç­–: çŸ­ã„å¾…æ©Ÿæ™‚é–“
        time.sleep(0.5)
    
    logger.info(f"\n   ğŸ“Š åˆè¨ˆ {total_posts_count} ä»¶ã®æŠ•ç¨¿ã‚’å–å¾—")
    
    # ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥çµ±è¨ˆ
    platform_stats = {}
    for item in all_analytics_data:
        p = item["platform"]
        if p not in platform_stats:
            platform_stats[p] = {
                "total_posts": 0,
                "impressions": 0,
                "total_engagement": 0,
                "external_posts": 0,
                "late_posts": 0
            }
        platform_stats[p]["total_posts"] += 1
        platform_stats[p]["impressions"] += item.get("impressions", 0)
        platform_stats[p]["total_engagement"] += (
            item.get("likes", 0) +
            item.get("comments", 0) +
            item.get("shares", 0)
        )
        
        # Issue #4 å¯¾å¿œ: External/Late Post ã®åˆ†é¡
        if item.get("is_external"):
            platform_stats[p]["external_posts"] += 1
        else:
            platform_stats[p]["late_posts"] += 1
    
    # çµæœã‚µãƒãƒªãƒ¼
    result = {
        "metadata": {
            "fetched_at": datetime.now().isoformat(),
            "period_start": from_date,
            "period_end": to_date,
            "total_posts": len(all_analytics_data),
            "total_pages": page,
            "total_impressions": sum(item.get("impressions", 0) for item in all_analytics_data),
            "total_engagement": sum(
                item.get("likes", 0) + item.get("comments", 0) + item.get("shares", 0)
                for item in all_analytics_data
            ),
            "platform_stats": platform_stats,
            "optimization_info": {
                "api_calls": page,  # âœ… å¤§å¹…å‰Šæ¸›ï¼ˆå¾“æ¥ã¯ N+1 å›ï¼‰
                "script_version": "optimized_v1.0",
                "issues_fixed": ["#1_param_names", "#2_n+1_query", "#3_pagination", "#4_dual_id"]
            }
        },
        "data": all_analytics_data
    }

    return result


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description="Late API Analytics æœ€é©åŒ–ç‰ˆãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆIssues #1-4 ä¿®æ­£æ¸ˆã¿ï¼‰"
    )
    parser.add_argument(
        "--from-date",
        type=str,
        required=True,
        help="é–‹å§‹æ—¥ (YYYY-MM-DD)"
    )
    parser.add_argument(
        "--to-date",
        type=str,
        required=True,
        help="çµ‚äº†æ—¥ (YYYY-MM-DD)"
    )
    parser.add_argument(
        "--platform",
        type=str,
        choices=["x", "threads", "linkedin", "facebook"],
        help="ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ æŒ‡å®šï¼ˆçœç•¥æ™‚ã¯å…¨ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ï¼‰"
    )
    parser.add_argument(
        "--sort-by",
        type=str,
        choices=["date", "engagement"],
        default="date",
        help="ã‚½ãƒ¼ãƒˆåŸºæº–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: dateï¼‰"
    )
    parser.add_argument(
        "--order",
        type=str,
        choices=["asc", "desc"],
        default="desc",
        help="ã‚½ãƒ¼ãƒˆé †åºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: descï¼‰"
    )
    parser.add_argument(
        "--output",
        type=str,
        help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰"
    )

    args = parser.parse_args()

    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    result = fetch_all_analytics(
        from_date=args.from_date,
        to_date=args.to_date,
        platform=args.platform,
        sort_by=args.sort_by,
        order=args.order
    )

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹æ±ºå®š
    if args.output:
        output_path = Path(args.output)
    else:
        from_date_str = args.from_date.replace("-", "")
        to_date_str = args.to_date.replace("-", "")
        filename = f"late_api_analytics_optimized_{from_date_str}-{to_date_str}.json"
        output_path = Path(__file__).parent.parent / "data" / filename

    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\n" + "="*80)
    print("ğŸ“Š Late API Analytics æœ€é©åŒ–ç‰ˆ - ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†")
    print("="*80)
    print(f"ä¿å­˜å…ˆ: {output_path}")
    print(f"æœŸé–“: {args.from_date} ï½ {args.to_date}")
    print(f"\nâœ… ä¿®æ­£æ¸ˆã¿Issues: #1 (ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å), #2 (N+1å•é¡Œ), #3 (ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³), #4 (Dual ID)")
    print(f"\nç·æŠ•ç¨¿æ•°: {result['metadata']['total_posts']}ä»¶")
    print(f"ç·ãƒšãƒ¼ã‚¸æ•°: {result['metadata']['total_pages']}ãƒšãƒ¼ã‚¸")
    print(f"APIå‘¼ã³å‡ºã—æ•°: {result['metadata']['optimization_info']['api_calls']}å›")
    print(f"ç·ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°: {result['metadata']['total_impressions']:,}")
    print(f"ç·ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæ•°: {result['metadata']['total_engagement']:,}")

    print("\nãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ åˆ¥çµ±è¨ˆ:")
    for platform, stats in result['metadata']['platform_stats'].items():
        platform_name = platform if platform else "ä¸æ˜"
        print(f"  {platform_name:10s}: {stats['total_posts']:3d}ä»¶ | "
              f"Impressions: {stats['impressions']:,} | "
              f"Engagement: {stats['total_engagement']:,} | "
              f"External: {stats['external_posts']} / Late: {stats['late_posts']}")

    print("\nâœ… å®Œäº†")


if __name__ == "__main__":
    main()
