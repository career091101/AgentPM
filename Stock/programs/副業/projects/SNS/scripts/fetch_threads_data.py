#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Threads API ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ç›®çš„: Threads APIã‚’ä½¿ç”¨ã—ã¦éå»90æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
æ©Ÿèƒ½:
1. æŠ•ç¨¿ä¸€è¦§å–å¾—
2. å„æŠ•ç¨¿ã®Insightså–å¾—
3. CSVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
4. ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œï¼ˆæŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ï¼‰
"""

import os
import time
import requests
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
env_path = Path(__file__).parent.parent / '.env'
load_dotenv(dotenv_path=env_path)

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—
THREADS_USER_ID = os.getenv('THREADS_USER_ID')
THREADS_ACCESS_TOKEN = os.getenv('THREADS_ACCESS_TOKEN')
DATA_DIR = os.getenv('DATA_DIR', str(Path(__file__).parent.parent))

# APIè¨­å®š
API_VERSION = 'v1.0'
BASE_URL = f'https://graph.threads.net/{API_VERSION}'

def exponential_backoff(attempt, max_wait=60):
    """æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•è¨ˆç®—"""
    wait_time = min(2 ** attempt, max_wait)
    return wait_time

def api_request(url, params, max_retries=5):
    """
    APIå‘¼ã³å‡ºã—ã¨ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ

    Args:
        url: APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆURL
        params: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°

    Returns:
        JSONãƒ¬ã‚¹ãƒãƒ³ã‚¹
    """
    for attempt in range(max_retries):
        try:
            response = requests.get(url, params=params, timeout=30)

            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ï¼ˆHTTP 429ï¼‰
            if response.status_code == 429:
                wait_time = exponential_backoff(attempt)
                print(f"âš ï¸  ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã€‚{wait_time}ç§’å¾…æ©Ÿä¸­...")
                time.sleep(wait_time)
                continue

            # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼
            if response.status_code != 200:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼: {response.status_code} - {response.text}")
                return None

            return response.json()

        except requests.exceptions.Timeout:
            print(f"âš ï¸  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã€‚ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{max_retries}")
            time.sleep(exponential_backoff(attempt))

        except requests.exceptions.RequestException as e:
            print(f"âŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return None

    print(f"âŒ æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸã€‚")
    return None

def get_threads_list(threads_user_id, access_token, since_timestamp, until_timestamp):
    """
    éå»90æ—¥åˆ†ã®ThreadsæŠ•ç¨¿ä¸€è¦§ã‚’å–å¾—

    Args:
        threads_user_id: Threads User ID
        access_token: ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³
        since_timestamp: é–‹å§‹æ—¥æ™‚ï¼ˆUnixã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰
        until_timestamp: çµ‚äº†æ—¥æ™‚ï¼ˆUnixã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰

    Returns:
        æŠ•ç¨¿ãƒªã‚¹ãƒˆ
    """
    url = f"{BASE_URL}/{threads_user_id}/threads"
    params = {
        'fields': 'id,text,timestamp,permalink,media_type,media_url,username',
        'access_token': access_token,
        'since': since_timestamp,
        'until': until_timestamp,
        'limit': 100  # æœ€å¤§100ä»¶/ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    }

    all_threads = []

    print("ğŸ“¥ ThreadsæŠ•ç¨¿ä¸€è¦§ã‚’å–å¾—ä¸­...")

    while True:
        data = api_request(url, params)

        if not data:
            break

        if 'data' in data:
            all_threads.extend(data['data'])
            print(f"   å–å¾—æ¸ˆã¿: {len(all_threads)}ä»¶")

        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†
        if 'paging' in data and 'next' in data['paging']:
            url = data['paging']['next']
            params = {}  # nextã«ã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å«ã¾ã‚Œã¦ã„ã‚‹ã®ã§ç©ºã«ã™ã‚‹
        else:
            break

    print(f"âœ… ThreadsæŠ•ç¨¿ä¸€è¦§å–å¾—å®Œäº†: {len(all_threads)}ä»¶")
    return all_threads

def get_threads_insights(thread_id, access_token):
    """
    ThreadsæŠ•ç¨¿ã®Insightsã‚’å–å¾—

    Args:
        thread_id: ThreadsæŠ•ç¨¿ID
        access_token: ã‚¢ã‚¯ã‚»ã‚¹ãƒˆãƒ¼ã‚¯ãƒ³

    Returns:
        Insightsè¾æ›¸
    """
    url = f"{BASE_URL}/{thread_id}/insights"
    params = {
        'metric': 'views,likes,replies,reposts,quotes,shares',
        'access_token': access_token
    }

    data = api_request(url, params)

    if not data or 'data' not in data:
        return {}

    # Insightsã‚’è¾æ›¸å½¢å¼ã«å¤‰æ›
    insights = {}
    for item in data['data']:
        metric_name = item['name']
        metric_value = item['values'][0]['value'] if item['values'] else 0
        insights[metric_name] = metric_value

    return insights

def fetch_all_threads_data(days=90):
    """
    éå»90æ—¥åˆ†ã®Threadsãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦CSVã«ä¿å­˜

    Args:
        days: å–å¾—æ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ90æ—¥ï¼‰
    """
    if not THREADS_USER_ID or not THREADS_ACCESS_TOKEN:
        print("âŒ ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    # æ—¥æ™‚ç¯„å›²ã®è¨ˆç®—
    until_date = datetime.now()
    since_date = until_date - timedelta(days=days)

    since_timestamp = int(since_date.timestamp())
    until_timestamp = int(until_date.timestamp())

    print(f"ğŸ“… å–å¾—æœŸé–“: {since_date.strftime('%Y-%m-%d')} ã€œ {until_date.strftime('%Y-%m-%d')}")
    print()

    # æŠ•ç¨¿ä¸€è¦§ã‚’å–å¾—
    threads_list = get_threads_list(
        THREADS_USER_ID,
        THREADS_ACCESS_TOKEN,
        since_timestamp,
        until_timestamp
    )

    if not threads_list:
        print("âš ï¸  ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    print()
    print("ğŸ“Š å„æŠ•ç¨¿ã®Insightsã‚’å–å¾—ä¸­...")

    # å„æŠ•ç¨¿ã®Insightsã‚’å–å¾—
    results = []
    for i, thread in enumerate(threads_list, 1):
        print(f"   å–å¾—ä¸­: {i}/{len(threads_list)}ä»¶ - ID: {thread['id']}")

        # Insightså–å¾—
        insights = get_threads_insights(
            thread['id'],
            THREADS_ACCESS_TOKEN
        )

        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæ•°è¨ˆç®—
        likes = insights.get('likes', 0)
        replies = insights.get('replies', 0)
        reposts = insights.get('reposts', 0)
        quotes = insights.get('quotes', 0)
        shares = insights.get('shares', 0)
        total_engagement = likes + replies + reposts + quotes + shares

        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡è¨ˆç®—ï¼ˆé–²è¦§æ•°ãƒ™ãƒ¼ã‚¹ï¼‰
        views = insights.get('views', 0)
        engagement_rate = (total_engagement / views * 100) if views > 0 else 0

        # ãƒ‡ãƒ¼ã‚¿æ•´å½¢
        result = {
            'æŠ•ç¨¿ID': thread['id'],
            'ãƒ¦ãƒ¼ã‚¶ãƒ¼å': thread.get('username', ''),
            'æŠ•ç¨¿æ—¥æ™‚': thread.get('timestamp', ''),
            'ãƒ†ã‚­ã‚¹ãƒˆ': thread.get('text', '')[:200] if thread.get('text') else '',  # 200æ–‡å­—ã¾ã§
            'ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—': thread.get('media_type', 'TEXT'),
            'ãƒ‘ãƒ¼ãƒãƒªãƒ³ã‚¯': thread.get('permalink', ''),
            'é–²è¦§æ•°': views,
            'ã„ã„ã­æ•°': likes,
            'è¿”ä¿¡æ•°': replies,
            'ãƒªãƒã‚¹ãƒˆæ•°': reposts,
            'å¼•ç”¨æ•°': quotes,
            'ã‚·ã‚§ã‚¢æ•°': shares,
            'ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæ•°': total_engagement,
            'ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡': round(engagement_rate, 2)
        }

        results.append(result)

        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        time.sleep(0.1)

    print(f"âœ… Insightså–å¾—å®Œäº†: {len(results)}ä»¶")
    print()

    # DataFrameã«å¤‰æ›
    df = pd.DataFrame(results)

    # æŠ•ç¨¿æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼ˆé™é †ï¼‰
    df['æŠ•ç¨¿æ—¥æ™‚'] = pd.to_datetime(df['æŠ•ç¨¿æ—¥æ™‚'])
    df = df.sort_values('æŠ•ç¨¿æ—¥æ™‚', ascending=False)
    df['æŠ•ç¨¿æ—¥æ™‚'] = df['æŠ•ç¨¿æ—¥æ™‚'].dt.strftime('%Y-%m-%d %H:%M:%S')

    # CSVå‡ºåŠ›
    output_dir = Path(DATA_DIR) / 'Threads'
    output_dir.mkdir(parents=True, exist_ok=True)

    today_str = datetime.now().strftime('%Y-%m-%d')
    output_path = output_dir / f'threads_{today_str}.csv'

    df.to_csv(output_path, index=False, encoding='utf-8-sig')

    print(f"ğŸ’¾ CSVãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {output_path}")
    print()

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("=" * 80)
    print("Threads ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚µãƒãƒªãƒ¼")
    print("=" * 80)
    print(f"ç·æŠ•ç¨¿æ•°: {len(df)}ä»¶")
    print(f"ç·é–²è¦§æ•°: {df['é–²è¦§æ•°'].sum():,}")
    print(f"å¹³å‡é–²è¦§æ•°: {df['é–²è¦§æ•°'].mean():.0f}")
    print(f"å¹³å‡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡: {df['ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡'].mean():.2f}%")
    print()

    # ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ
    print("ã€ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆã€‘")
    for media_type in df['ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—'].unique():
        type_df = df[df['ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¿ã‚¤ãƒ—'] == media_type]
        print(f"  {media_type}: {len(type_df)}ä»¶ (å¹³å‡é–²è¦§æ•°: {type_df['é–²è¦§æ•°'].mean():.0f})")
    print()

    print("âœ… å‡¦ç†å®Œäº†")

if __name__ == '__main__':
    fetch_all_threads_data()
