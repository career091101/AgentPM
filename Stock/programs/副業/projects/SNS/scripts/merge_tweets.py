#!/usr/bin/env python3
"""
X Timeline Tweets Merger and Filter

è¤‡æ•°ã‚µã‚¤ã‚¯ãƒ«ã§åé›†ã—ãŸãƒ„ã‚¤ãƒ¼ãƒˆJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ¼ã‚¸ã—ã€
é‡è¤‡æ’é™¤ã€ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢è¨ˆç®—ã€ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’è¡Œã„ã¾ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    python3 merge_tweets.py --input /tmp/tweets_cycle_*.json --output data/x_timeline_20260101.json --config config/automation_config.yaml --top-n 10

ä¾‹:
    python3 merge_tweets.py --input "/tmp/tweets_cycle_*.json" --output data/x_timeline_20260101.json --top-n 10
"""

import argparse
import glob
import json
import sys
import yaml
from pathlib import Path
from typing import Dict, List
from datetime import datetime


class TweetMerger:
    """ãƒ„ã‚¤ãƒ¼ãƒˆãƒãƒ¼ã‚¸ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¯ãƒ©ã‚¹"""

    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
    DEFAULT_MIN_IMPRESSIONS = 1000
    DEFAULT_MIN_ENGAGEMENT_RATE = 0.05  # 5%
    DEFAULT_TOP_N = 10
    DEFAULT_ENGAGEMENT_WEIGHTS = {
        'like': 1,
        'retweet': 3,
        'reply': 5
    }

    def __init__(self, config_path: Path = None):
        """
        Args:
            config_path: automation_config.yamlã®ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.config = self._load_config(config_path) if config_path else {}
        self.tweets: List[Dict] = []

    def _load_config(self, config_path: Path) -> Dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€

        Args:
            config_path: YAMLãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            è¨­å®šè¾æ›¸
        """
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            print(f"âš ï¸  è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰: {e}", file=sys.stderr)
            return {}

    def load_tweets_from_files(self, file_pattern: str) -> int:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸€è‡´ã™ã‚‹å…¨JSONãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ„ã‚¤ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚€

        Args:
            file_pattern: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹: "/tmp/tweets_cycle_*.json"ï¼‰

        Returns:
            èª­ã¿è¾¼ã‚“ã ãƒ•ã‚¡ã‚¤ãƒ«æ•°
        """
        files = glob.glob(file_pattern)

        if not files:
            print(f"âš ï¸  ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ä¸€è‡´ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_pattern}", file=sys.stderr)
            return 0

        all_tweets = []
        for file_path in sorted(files):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    tweets = json.load(f)

                if isinstance(tweets, list):
                    all_tweets.extend(tweets)
                else:
                    print(f"âš ï¸  {file_path} ã¯ãƒªã‚¹ãƒˆå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“", file=sys.stderr)

            except Exception as e:
                print(f"âš ï¸  {file_path} èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
                continue

        self.tweets = all_tweets
        print(f"âœ… {len(files)} ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ {len(all_tweets)} ä»¶ã®ãƒ„ã‚¤ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        return len(files)

    def deduplicate(self) -> int:
        """ãƒ„ã‚¤ãƒ¼ãƒˆIDã§é‡è¤‡æ’é™¤

        Returns:
            å‰Šé™¤ã•ã‚ŒãŸé‡è¤‡ä»¶æ•°
        """
        before_count = len(self.tweets)

        seen_ids = set()
        unique_tweets = []

        for tweet in self.tweets:
            tweet_id = tweet.get('tweet_id')
            if tweet_id and tweet_id not in seen_ids:
                seen_ids.add(tweet_id)
                unique_tweets.append(tweet)

        self.tweets = unique_tweets
        removed_count = before_count - len(unique_tweets)

        print(f"âœ… é‡è¤‡æ’é™¤: {removed_count} ä»¶å‰Šé™¤ï¼ˆ{before_count} â†’ {len(unique_tweets)}ï¼‰")
        return removed_count

    def calculate_engagement_metrics(self) -> None:
        """å…¨ãƒ„ã‚¤ãƒ¼ãƒˆã«ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™ã‚’è¨ˆç®—ãƒ»è¿½åŠ """
        weights = self.config.get('engagement_weights', self.DEFAULT_ENGAGEMENT_WEIGHTS)

        for tweet in self.tweets:
            likes = tweet.get('likes', 0)
            retweets = tweet.get('retweets', 0)
            replies = tweet.get('replies', 0)

            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢è¨ˆç®—
            engagement_score = (
                likes * weights.get('like', 1) +
                retweets * weights.get('retweet', 3) +
                replies * weights.get('reply', 5)
            )
            tweet['engagement_score'] = engagement_score

            # ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ¨å®šï¼ˆã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡2%ã¨ä»®å®šï¼‰
            total_engagement = likes + retweets + replies
            impressions_estimated = int(total_engagement / 0.02) if total_engagement > 0 else 0
            tweet['impressions_estimated'] = impressions_estimated

            # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡è¨ˆç®—
            engagement_rate = (
                total_engagement / impressions_estimated
                if impressions_estimated > 0 else 0
            )
            tweet['engagement_rate'] = engagement_rate

        print(f"âœ… ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™è¨ˆç®—å®Œäº†")

    def filter_tweets(self, min_impressions: int = None, min_engagement_rate: float = None) -> int:
        """ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°åŸºæº–ã«åŸºã¥ã„ã¦ãƒ„ã‚¤ãƒ¼ãƒˆã‚’ãƒ•ã‚£ãƒ«ã‚¿

        Args:
            min_impressions: æœ€å°ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°
            min_engagement_rate: æœ€å°ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡

        Returns:
            ãƒ•ã‚£ãƒ«ã‚¿å¾Œã®ä»¶æ•°
        """
        filters_config = self.config.get('filters', {})

        min_imp = min_impressions if min_impressions is not None else filters_config.get('min_impressions', self.DEFAULT_MIN_IMPRESSIONS)
        min_er = min_engagement_rate if min_engagement_rate is not None else filters_config.get('min_engagement_rate', self.DEFAULT_MIN_ENGAGEMENT_RATE)

        before_count = len(self.tweets)

        filtered_tweets = [
            tweet for tweet in self.tweets
            if (tweet.get('impressions_estimated', 0) >= min_imp and
                tweet.get('engagement_rate', 0) >= min_er)
        ]

        self.tweets = filtered_tweets
        print(f"âœ… ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: {before_count - len(filtered_tweets)} ä»¶å‰Šé™¤ï¼ˆ{before_count} â†’ {len(filtered_tweets)}ï¼‰")
        print(f"   åŸºæº–: impressions â‰¥ {min_imp}, engagement_rate â‰¥ {min_er*100:.0f}%")
        return len(filtered_tweets)

    def sort_and_top_n(self, top_n: int = None) -> int:
        """ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆã—ã€ä¸Šä½Nä»¶ã‚’å–å¾—

        Args:
            top_n: ä¸Šä½Nä»¶ã‚’å–å¾—ï¼ˆNoneã®å ´åˆã¯å…¨ä»¶ï¼‰

        Returns:
            å–å¾—å¾Œã®ä»¶æ•°
        """
        n = top_n if top_n is not None else self.config.get('filters', {}).get('top_n', self.DEFAULT_TOP_N)

        # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢é™é †ã§ã‚½ãƒ¼ãƒˆ
        self.tweets.sort(key=lambda t: t.get('engagement_score', 0), reverse=True)

        if n and len(self.tweets) > n:
            self.tweets = self.tweets[:n]
            print(f"âœ… ä¸Šä½ {n} ä»¶ã‚’æŠ½å‡º")

        return len(self.tweets)

    def save_to_json(self, output_path: Path) -> bool:
        """çµæœã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜

        Args:
            output_path: å‡ºåŠ›å…ˆJSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            æˆåŠŸæ™‚Trueã€å¤±æ•—æ™‚False
        """
        try:
            output_path.parent.mkdir(parents=True, exist_ok=True)

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãã§ä¿å­˜
            output_data = {
                'collected_at': datetime.now().isoformat(),
                'total_tweets': len(self.tweets),
                'tweets': self.tweets
            }

            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(output_data, f, ensure_ascii=False, indent=2)

            print(f"âœ… ä¿å­˜å®Œäº†: {output_path}")
            print(f"   æœ€çµ‚ãƒ„ã‚¤ãƒ¼ãƒˆæ•°: {len(self.tweets)}")
            return True

        except Exception as e:
            print(f"âŒ JSONä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}", file=sys.stderr)
            return False

    def print_summary(self) -> None:
        """çµæœã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
        if not self.tweets:
            print("\nãƒ„ã‚¤ãƒ¼ãƒˆãŒã‚ã‚Šã¾ã›ã‚“")
            return

        print("\n" + "="*60)
        print("ğŸ“Š X Timeline Collection Summary")
        print("="*60)

        top_3 = self.tweets[:3]
        for i, tweet in enumerate(top_3, 1):
            print(f"\n{i}. â¤ï¸  {tweet.get('likes', 0)} ğŸ” {tweet.get('retweets', 0)} ğŸ’¬ {tweet.get('replies', 0)}")
            print(f"   Score: {tweet.get('engagement_score', 0)}, ER: {tweet.get('engagement_rate', 0)*100:.1f}%")
            text = tweet.get('text', '')
            preview = text[:60] + '...' if len(text) > 60 else text
            print(f"   {preview}")

        print("\n" + "="*60)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(
        description='è¤‡æ•°ã‚µã‚¤ã‚¯ãƒ«ã®ãƒ„ã‚¤ãƒ¼ãƒˆJSONã‚’ãƒãƒ¼ã‚¸ãƒ»ãƒ•ã‚£ãƒ«ã‚¿'
    )
    parser.add_argument(
        '--input',
        type=str,
        required=True,
        help='å…¥åŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆä¾‹: "/tmp/tweets_cycle_*.json"ï¼‰'
    )
    parser.add_argument(
        '--output',
        type=str,
        required=True,
        help='å‡ºåŠ›JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹'
    )
    parser.add_argument(
        '--config',
        type=str,
        default=None,
        help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆautomation_config.yamlï¼‰'
    )
    parser.add_argument(
        '--top-n',
        type=int,
        default=None,
        help='ä¸Šä½Nä»¶ã‚’æŠ½å‡ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ï¼‰'
    )
    parser.add_argument(
        '--min-impressions',
        type=int,
        default=None,
        help='æœ€å°ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1000ï¼‰'
    )
    parser.add_argument(
        '--min-engagement-rate',
        type=float,
        default=None,
        help='æœ€å°ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.05ï¼‰'
    )

    args = parser.parse_args()

    output_path = Path(args.output)
    config_path = Path(args.config) if args.config else None

    # ãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
    merger = TweetMerger(config_path)

    # å‡¦ç†ãƒ•ãƒ­ãƒ¼
    if merger.load_tweets_from_files(args.input) == 0:
        print("âŒ å‡¦ç†ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“", file=sys.stderr)
        sys.exit(1)

    merger.deduplicate()
    merger.calculate_engagement_metrics()
    merger.filter_tweets(args.min_impressions, args.min_engagement_rate)
    merger.sort_and_top_n(args.top_n)

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    merger.print_summary()

    # ä¿å­˜
    if merger.save_to_json(output_path):
        sys.exit(0)
    else:
        sys.exit(1)


if __name__ == "__main__":
    main()
