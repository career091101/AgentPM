#!/usr/bin/env python3
"""
Phase 3: 36å€‹ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°çµæœJSONã‚’çµ±åˆã—ã¦æœ€çµ‚CSVå‡ºåŠ›

ä½¿ç”¨æ–¹æ³•:
    python integrate_scoring_results.py
"""

import json
import csv
from pathlib import Path
from datetime import datetime
from collections import defaultdict

# ãƒãƒƒãƒãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆbatch_completion_status.txtã‹ã‚‰ç”Ÿæˆï¼‰
BATCH_FILES = {
    1: "./scoring_results_batch_001_20260104_125755.json",
    2: "./scoring_batches/scoring_results_batch_002_20260104_125843.json",
    3: "./scoring_results_batch_003.json",
    4: "./scoring_results_batch_004.json",
    5: "./scoring_results_batch_005.json",
    6: "./scoring_results_batch_006.json",
    7: "./scoring_results_batch_007.json",
    8: "./scoring_results_batch_008.json",
    9: "./scoring_results_batch_009.json",
    10: "./scoring_results/scoring_results_batch_010.json",
    11: "./scoring_results_batch_011.json",
    12: "./scoring_results_batch_012.json",
    13: "./scoring_results_batch_013.json",
    14: "./scoring_results_batch_014.json",
    15: "./scoring_batches/scoring_results_batch_015.json",
    16: "./scoring_results_batch_016.json",
    17: "./scoring_results_batch_017.json",
    18: "./scoring_results_batch_018.json",
    19: "./scoring_results_batch_019.json",
    20: "./scoring_results_batch_020.json",
    21: "./scoring_results_batch_021.json",
    22: "./scoring_results_batch_022.json",
    23: "./scoring_results_batch_023.json",
    24: "./scoring_results_batch_024.json",
    25: "./scoring_results_batch_025.json",
    26: "./scoring_results/scoring_results_batch_026.json",
    27: "./scoring_batches/scoring_results_batch_027.json",
    28: "./scoring_batches/scoring_results_batch_028.json",
    29: "./scoring_batches/scoring_results_batch_029.json",
    30: "./scoring_batches/scoring_results_batch_030.json",
    31: "./scoring_results_batch_031.json",
    32: "./scoring_batches/scoring_results_batch_032.json",
    33: "./scoring_results_batch_033.json",
    34: "./scoring_results_batch_034.json",
    35: "./scoring_results_batch_035.json",
    36: "./scoring_batches/scoring_results_batch_036_20260104_125856.json",
}


def load_json_file(file_path):
    """JSONãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"âš ï¸  JSONèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
        return None


def extract_clinic_data(batch_num, json_data):
    """JSONã‹ã‚‰ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
    clinics = []

    # resultsã‚­ãƒ¼ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
    if 'results' in json_data:
        results = json_data['results']

        # resultsãŒé…åˆ—ã®å ´åˆ
        if isinstance(results, list):
            for clinic in results:
                clinics.append({
                    'batch_num': batch_num,
                    'data': clinic
                })

        # resultsãŒã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆï¼ˆåŒ»é™¢åãŒã‚­ãƒ¼ï¼‰ã®å ´åˆ
        elif isinstance(results, dict):
            for clinic_name, clinic_data in results.items():
                # clinic_dataã«åŒ»é™¢åã‚’è¿½åŠ 
                clinic_record = clinic_data.copy() if isinstance(clinic_data, dict) else {}
                clinic_record['clinic_name'] = clinic_name
                clinics.append({
                    'batch_num': batch_num,
                    'data': clinic_record
                })

    # clinicsã‚­ãƒ¼ãŒå­˜åœ¨ã™ã‚‹å ´åˆï¼ˆåˆ¥ã®å‡ºåŠ›å½¢å¼ï¼‰
    elif 'clinics' in json_data and isinstance(json_data['clinics'], list):
        for clinic in json_data['clinics']:
            clinics.append({
                'batch_num': batch_num,
                'data': clinic
            })

    # dataã‚­ãƒ¼ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
    elif 'data' in json_data and isinstance(json_data['data'], list):
        for clinic in json_data['data']:
            clinics.append({
                'batch_num': batch_num,
                'data': clinic
            })

    # ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ãŒé…åˆ—ã®å ´åˆ
    elif isinstance(json_data, list):
        for clinic in json_data:
            clinics.append({
                'batch_num': batch_num,
                'data': clinic
            })

    else:
        print(f"âš ï¸  ãƒãƒƒãƒ {batch_num:03d}: ä¸æ˜ãªJSONæ§‹é€ ")

    return clinics


def normalize_clinic_record(batch_num, clinic_data):
    """ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’çµ±ä¸€ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¤‰æ›"""

    # ã‚¹ã‚³ã‚¢æƒ…å ±æŠ½å‡º
    total_score = clinic_data.get('total_score', 0)

    # scoresã‚­ãƒ¼ã‹ã‚‰å„ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º
    scores = clinic_data.get('scores', {})
    if isinstance(scores, dict):
        score_åŸºç¤è©•ä¾¡ = scores.get('åŸºç¤è©•ä¾¡', 0)
        score_æ¥é™¢æ‚£è€…æ•° = scores.get('æ¥é™¢æ‚£è€…æ•°', 0)
        score_å­ã©ã‚‚å¯¾å¿œåŠ› = scores.get('å­ã©ã‚‚å¯¾å¿œåŠ›', 0)
        score_Webç©æ¥µæ€§ = scores.get('Webç©æ¥µæ€§', 0)
        score_åŒ»é™¢è¦æ¨¡ = scores.get('åŒ»é™¢è¦æ¨¡', 0)
        score_ãƒ–ãƒ­ã‚°æ´»å‹• = scores.get('ãƒ–ãƒ­ã‚°æ´»å‹•', 0)
    else:
        score_åŸºç¤è©•ä¾¡ = 0
        score_æ¥é™¢æ‚£è€…æ•° = 0
        score_å­ã©ã‚‚å¯¾å¿œåŠ› = 0
        score_Webç©æ¥µæ€§ = 0
        score_åŒ»é™¢è¦æ¨¡ = 0
        score_ãƒ–ãƒ­ã‚°æ´»å‹• = 0

    # Website analysisæƒ…å ±ï¼ˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå½¢å¼ã®å ´åˆã¯'analysis'ã‚­ãƒ¼ï¼‰
    web_analysis = clinic_data.get('website_analysis', clinic_data.get('analysis', {}))

    # Raw dataæƒ…å ±ï¼ˆã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå½¢å¼ã®å ´åˆã¯ç›´æ¥clinic_dataï¼‰
    raw_data = clinic_data.get('raw_data', clinic_data)

    # åŒ»é™¢é•·åæŠ½å‡ºï¼ˆè¤‡æ•°ã®ã‚­ãƒ¼ã‚’è©¦è¡Œï¼‰
    director_name = web_analysis.get('director_name', '')
    if not director_name and 'director_name_extracted' in web_analysis:
        director_name = web_analysis.get('director_name_extracted', '')
    if not director_name and 'csv_director_name' in clinic_data:
        director_name = clinic_data.get('csv_director_name', '')

    # åŒ»é™¢åæŠ½å‡ºï¼ˆè¤‡æ•°ã®ã‚­ãƒ¼ã‚’è©¦è¡Œï¼‰
    clinic_name = clinic_data.get('clinic_name', '')
    if not clinic_name:
        clinic_name = raw_data.get('name', '')

    # ä½æ‰€æŠ½å‡ºï¼ˆè¤‡æ•°ã®ã‚­ãƒ¼ã‚’è©¦è¡Œï¼‰
    address = raw_data.get('formatted_address', clinic_data.get('address', ''))

    # é›»è©±ç•ªå·æŠ½å‡º
    phone = raw_data.get('formatted_phone_number', clinic_data.get('phone', ''))

    # Webã‚µã‚¤ãƒˆURLæŠ½å‡º
    website_url = raw_data.get('website', clinic_data.get('website_url', ''))

    # Google Maps URLæŠ½å‡º
    google_maps_url = raw_data.get('url', clinic_data.get('google_maps_url', ''))

    # éƒµä¾¿ç•ªå·æŠ½å‡º
    postal_code = raw_data.get('postal_code', clinic_data.get('postal_code', ''))

    # çµ±ä¸€ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆ
    return {
        'ãƒãƒƒãƒç•ªå·': batch_num,
        'ç·åˆã‚¹ã‚³ã‚¢': total_score,
        'åŒ»é™¢å': clinic_name,
        'åŒ»é™¢é•·å': director_name,
        'éƒµä¾¿ç•ªå·': postal_code,
        'ä½æ‰€': address,
        'åŸºç¤è©•ä¾¡': score_åŸºç¤è©•ä¾¡,
        'æ¥é™¢æ‚£è€…æ•°': score_æ¥é™¢æ‚£è€…æ•°,
        'å­ã©ã‚‚å¯¾å¿œåŠ›': score_å­ã©ã‚‚å¯¾å¿œåŠ›,
        'Webç©æ¥µæ€§': score_Webç©æ¥µæ€§,
        'åŒ»é™¢è¦æ¨¡': score_åŒ»é™¢è¦æ¨¡,
        'ãƒ–ãƒ­ã‚°æ´»å‹•': score_ãƒ–ãƒ­ã‚°æ´»å‹•,
        'å–¶æ¥­æ™‚é–“': web_analysis.get('operating_hours', ''),
        'ãƒ–ãƒ­ã‚°æ›´æ–°æ—¥': web_analysis.get('blog_updated', ''),
        'é›»è©±ç•ªå·': phone,
        'Webã‚µã‚¤ãƒˆURL': website_url,
        'Googleè©•ä¾¡': raw_data.get('rating', ''),
        'ãƒ¬ãƒ“ãƒ¥ãƒ¼ä»¶æ•°': raw_data.get('user_ratings_total', ''),
        'è¨ºç™‚ç§‘ç›®ã‚¿ã‚°': ','.join(raw_data.get('types', [])) if isinstance(raw_data.get('types'), list) else '',
        'å†™çœŸæšæ•°': len(raw_data.get('photos', [])) if isinstance(raw_data.get('photos'), list) else 0,
        'SNS Instagram': web_analysis.get('sns_instagram', False),
        'SNS Facebook': web_analysis.get('sns_facebook', False),
        'SNS LINE': web_analysis.get('sns_line', False),
        'SNS Twitter': web_analysis.get('sns_twitter', False),
        'SNSé€£æºæ•°': sum([
            1 if web_analysis.get('sns_instagram') else 0,
            1 if web_analysis.get('sns_facebook') else 0,
            1 if web_analysis.get('sns_line') else 0,
            1 if web_analysis.get('sns_twitter') else 0
        ]),
        'å­ã©ã‚‚å‘ã‘ã‚³ãƒ³ãƒ†ãƒ³ãƒ„': web_analysis.get('kids_content', False),
        'å¾…åˆå®¤å†™çœŸ': web_analysis.get('waiting_room_photo', False),
        'Google Maps URL': google_maps_url
    }


def main():
    print("=" * 60)
    print("Phase 3: ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°çµæœçµ±åˆ")
    print("=" * 60)

    all_clinics = []
    batch_stats = defaultdict(int)

    # 36ãƒãƒƒãƒã‚’é †ç•ªã«èª­ã¿è¾¼ã¿
    for batch_num in range(1, 37):
        file_path = BATCH_FILES.get(batch_num)

        if not file_path or not Path(file_path).exists():
            print(f"âš ï¸  ãƒãƒƒãƒ {batch_num:03d}: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            continue

        print(f"\nğŸ“¦ ãƒãƒƒãƒ {batch_num:03d}: {file_path}")

        # JSONèª­ã¿è¾¼ã¿
        json_data = load_json_file(file_path)
        if not json_data:
            continue

        # ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
        clinics = extract_clinic_data(batch_num, json_data)
        print(f"   â†’ {len(clinics)}ä»¶ã®ã‚¯ãƒªãƒ‹ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º")

        # æ­£è¦åŒ–ã—ã¦è¿½åŠ 
        for clinic_info in clinics:
            normalized = normalize_clinic_record(batch_num, clinic_info['data'])
            all_clinics.append(normalized)

        batch_stats[batch_num] = len(clinics)

    # çµ±è¨ˆè¡¨ç¤º
    print("\n" + "=" * 60)
    print("çµ±è¨ˆæƒ…å ±")
    print("=" * 60)
    print(f"å‡¦ç†ãƒãƒƒãƒæ•°: {len(batch_stats)}/36")
    print(f"ç·ã‚¯ãƒªãƒ‹ãƒƒã‚¯æ•°: {len(all_clinics)}ä»¶")

    # ã‚¹ã‚³ã‚¢åˆ†å¸ƒ
    score_distribution = defaultdict(int)
    for clinic in all_clinics:
        score = clinic['ç·åˆã‚¹ã‚³ã‚¢']
        if score >= 70:
            score_distribution['é«˜ã‚¹ã‚³ã‚¢ï¼ˆ70ç‚¹ä»¥ä¸Šï¼‰'] += 1
        elif score >= 40:
            score_distribution['ä¸­ã‚¹ã‚³ã‚¢ï¼ˆ40-69ç‚¹ï¼‰'] += 1
        else:
            score_distribution['ä½ã‚¹ã‚³ã‚¢ï¼ˆ39ç‚¹ä»¥ä¸‹ï¼‰'] += 1

    print("\nã‚¹ã‚³ã‚¢åˆ†å¸ƒ:")
    for category, count in score_distribution.items():
        percentage = count / len(all_clinics) * 100 if all_clinics else 0
        print(f"  {category}: {count}ä»¶ ({percentage:.1f}%)")

    # åŒ»é™¢é•·åæŠ½å‡ºç‡
    director_names_found = sum(1 for c in all_clinics if c['åŒ»é™¢é•·å'])
    director_extraction_rate = director_names_found / len(all_clinics) * 100 if all_clinics else 0
    print(f"\nåŒ»é™¢é•·åæŠ½å‡ºç‡: {director_names_found}/{len(all_clinics)}ä»¶ ({director_extraction_rate:.1f}%)")

    # CSVå‡ºåŠ›
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_csv = f'tanabe_dental_leads_scored_{timestamp}.csv'

    fieldnames = [
        'ãƒãƒƒãƒç•ªå·', 'ç·åˆã‚¹ã‚³ã‚¢', 'åŒ»é™¢å', 'åŒ»é™¢é•·å', 'éƒµä¾¿ç•ªå·', 'ä½æ‰€',
        'åŸºç¤è©•ä¾¡', 'æ¥é™¢æ‚£è€…æ•°', 'å­ã©ã‚‚å¯¾å¿œåŠ›', 'Webç©æ¥µæ€§', 'åŒ»é™¢è¦æ¨¡', 'ãƒ–ãƒ­ã‚°æ´»å‹•',
        'å–¶æ¥­æ™‚é–“', 'ãƒ–ãƒ­ã‚°æ›´æ–°æ—¥', 'é›»è©±ç•ªå·', 'Webã‚µã‚¤ãƒˆURL',
        'Googleè©•ä¾¡', 'ãƒ¬ãƒ“ãƒ¥ãƒ¼ä»¶æ•°', 'è¨ºç™‚ç§‘ç›®ã‚¿ã‚°', 'å†™çœŸæšæ•°',
        'SNS Instagram', 'SNS Facebook', 'SNS LINE', 'SNS Twitter', 'SNSé€£æºæ•°',
        'å­ã©ã‚‚å‘ã‘ã‚³ãƒ³ãƒ†ãƒ³ãƒ„', 'å¾…åˆå®¤å†™çœŸ', 'Google Maps URL'
    ]

    with open(output_csv, 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(all_clinics)

    print(f"\nâœ… CSVå‡ºåŠ›å®Œäº†: {output_csv}")
    print(f"âœ… ç·ä»¶æ•°: {len(all_clinics)}ä»¶")
    print("=" * 60)


if __name__ == '__main__':
    main()
