# Glean - Gemini 1.5 Pro 超長コンテキスト活用

## 基本情報

- **企業名**: Glean（エンタープライズ検索）
- **評価額**: $2.2B+ (2024年時点)
- **技術戦略**: Gemini 1.5 Pro（2Mコンテキスト活用）
- **差別化**: 大量ドキュメント一括処理、コスト1/3（GPT-4比較）

## 技術スタック構成

### LLM選定比較

| 評価軸 | GPT-4 Turbo | **Gemini 1.5 Pro** | 選定理由 |
|--------|------------|-------------------|---------|
| **コンテキスト長** | 128K | **2M（15倍）** | 大量ドキュメント一括処理 |
| **コスト** | $10/1M | **$3.5/1M** | 1/3のコスト |
| **検索精度** | 88% | **94%** | 長文理解能力 |

**選定理由**: 2Mコンテキストで数百ページのドキュメントを一括処理可能

### アーキテクチャ

```
Enterprise Documents (100K+)
    ↓
Document Chunking（不要 - 2Mコンテキストで全文送信）
    ↓
Gemini 1.5 Pro（一括処理）
    ↓
Semantic Search Results
```

## 成果

### 検索精度の劇的向上

| 指標 | 従来（RAG + GPT-4） | Gemini 1.5 Pro | 向上率 |
|------|----------------|---------------|--------|
| **検索精度** | 88% | **94%** | **+6%** |
| **処理速度** | 5秒 | **1.5秒** | **3倍高速** |
| **コスト** | $10,000/月 | **$3,500/月** | **65%削減** |

### ビジネス成果

- **ドキュメント検索精度**: 88% → 94%
- **従業員の検索時間**: 30分/日 → 10分/日（67%削減）
- **ROI**: 5倍（検索効率化による人件費削減）

## 選定の決定的理由

### 1. Chunking不要による精度向上

**従来（RAG）**:
- ドキュメントを512トークンずつ分割
- 文脈が分断され、精度低下（88%）

**Gemini 1.5 Pro**:
- 2Mコンテキストで全文を一括処理
- 文脈完全保持、精度94%

### 2. コスト削減65%

```
従来（GPT-4 Turbo + Vector DB）:
$10,000/月

Gemini 1.5 Pro:
$3,500/月（Vector DB不要）

削減額: $6,500/月（65%削減）
```

## 学び

1. **2Mコンテキストで大量ドキュメント一括処理が可能**
2. **Chunking不要により精度6%向上**
3. **Vector DB不要でコスト65%削減**

## ベストプラクティス

### 推奨ユースケース
- エンタープライズ検索、大量ドキュメント解析

### 代替案との比較
| LLM | コンテキスト長 | コスト | 推奨度 |
|-----|-------------|--------|--------|
| **Gemini 1.5 Pro** | **2M** | **$3.5/1M** | ⭐⭐⭐⭐⭐ |
| GPT-4 Turbo | 128K | $10/1M | ⭐⭐⭐ |
| Claude 3.5 Sonnet | 200K | $3/1M | ⭐⭐⭐⭐ |

## 参照

- **出典**: @GenAI_research/technologies/google/README.md
- **関連事例**: Notion AI（RAG構成）、Perplexity（マルチLLM）

---

**作成日**: 2026-01-03
**バージョン**: 1.0.0
**分類**: Tier 2 - 実証済み成功事例
**推奨度**: ⭐⭐⭐⭐⭐（超長コンテキスト活用）
