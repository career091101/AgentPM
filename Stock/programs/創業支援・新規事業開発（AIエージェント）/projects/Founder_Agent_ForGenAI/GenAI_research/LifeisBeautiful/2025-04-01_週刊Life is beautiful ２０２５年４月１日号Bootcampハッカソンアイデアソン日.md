---
title: "週刊Life is beautiful ２０２５年４月１日号：Bootcamp、ハッカソン、アイデアソン、日本初ベンチャーとグローバル市場、なぜ日本ではDXやAIXが起こらないのか、日本の半導体戦略とラピダス"
author: "中島聡"
date: "2025-04-01"
source: "週刊Life is beautiful Newsletter"
newsletter_number: "2025-04-01号"
tags: ["GraphAI", "ハッカソン", "ブートキャンプ", "日本ベンチャー", "グローバル市場", "mixi", "Facebook", "Elon Musk", "VC戦略", "DX", "AIX", "リファクタリング", "解雇規制", "半導体", "ラピダス", "TSMC", "護送船団方式"]
summary: |
  シンギュラリティ・ソサエティBootcamp発表会とGraphAIハッカソン開催。
  日本ベンチャーとグローバル市場の違い（mixi vs Facebook、小さな成功vs壮大なビジョン）。
  VCパネルディスカッションでの本質的議論：ホームラン狙い vs 着実な成長。
  なぜ日本でDX/AIXが起こらないか（レガシー負債、リファクタリング困難、解雇規制）。
  日本半導体戦略の歴史と現在（垂直統合の失敗、TSMC優位、ラピダスの課題）。
key_points:
  - "GraphAIハッカソン: 15チーム参加、Mac Mini 64GB 4台進呈、コミュニティ貢献度で評価"
  - "日本ベンチャーの限界: 目標が上場・六本木ヒルズ・港区ギャル（小さな成功）に留まる"
  - "mixi失敗例: 世界最先端だったが早期上場・黒字化優先、Facebookは赤字で世界制覇"
  - "Elon Musk型ビジョン: 電気自動車で地球維持可能化、火星移住（次元が違う目標）"
  - "VCの期待: 満塁ホームラン狙い、10社中1社が100倍利益なら成功、送りバント不要"
  - "DX/AIX不可能性: 既存企業はレガシー負債で身動き取れず、解雇規制でリファクタリング困難"
  - "日本半導体衰退史: 1990年世界シェア51%→護送船団崩壊、垂直統合がTSMC水平分業に敗北"
  - "ラピダス問題: 政府主導1兆円、顧客不在、カリスマ不在、国家プロジェクト失敗パターン"
  - "TSMC優位性: ファウンドリ専業でスケールメリット、収益→設備投資の好循環確立"
  - "護送船団の終焉: 電電公社・IBM互換から脱却できず、オープン市場競争で敗北"
related_topics:
  - "ベンチャー成功の定義：日本型 vs シリコンバレー型"
  - "企業リファクタリングと解雇規制の関係"
  - "半導体産業の垂直統合vs水平分業戦略"
  - "国家主導プロジェクトの成功条件"
  - "パソコン市場コモディティ化と日本メーカー衰退"
confidence_level: "high"
---

# 週刊Life is beautiful ２０２５年４月１日号：Bootcamp、ハッカソン、アイデアソン、日本初ベンチャーとグローバル市場、なぜ日本ではDXやAIXが起こらないのか、日本の半導体戦略とラピダス

**From:** "中島聡 mag2 0001323030" <mailmag@mag2premium.com>  
**Date:** Tue, 1 Apr 2025 07:10:00 +0900 (JST)

---

<h1>今週のざっくばらん</h1>
<h2>メルマガの不具合</h2>
<p>X、および、２６日臨時発行号でお知らせをしましたが、３月２５日号のメルマガに対して、「誤字脱字が多い」というご指摘が多数寄せられ、対処に追われました。結論から言えば、Gmailの誤動作（必要もないのに、日本語訳をしてしまう）でしたが、最初は何が起こっているか分からず、焦りました。</p>
<p>読者の中に、具体的にどんな誤字・脱字があったかを報告してくれた方がいたため、私の書いた文章と異なることが分かり、原因の究明に至りました。後から分かりましたが、同様の現象は、堀江貴文さんのメルマガでも起こっていたそうです。</p>
<p>状況から察するに、</p>
<ol>
<li>Googleが、Gmailに自動翻訳機能を追加。</li>
<li>Gmailの言語判定機能が誤動作し、私のメルマガを英語だと判定</li>
<li>（一部のユーザーで）自動翻訳機能が働き、メルマガを日本語へ翻訳</li>
<li>日本語から日本語への翻訳の過程で、誤字・脱字が発生</li>
</ol>
<p>ということが起こったようです。「日本語から日本語への翻訳」で誤字・脱字が発生する理由は、LLM（大規模言語モデル）の中で、実際には、「日本語からトークンへ、トークンから日本語へ」と２段階の変換が行われており、その過程で、意味が変わってしまったり、文字が落ちたりしたのだと思います。</p>
<p>今後、世の中で行われているさまざまな業務がAIによって行われるようになると思いますが、この手の問題が頻発するだろうことは容易に想像できます。その意味では、良い勉強になりました。</p>
<p>ちなみに、２６日臨時発行号に対して、「３月２５日号のメルマガが届いていない」という質問も沢山いただきました。再送も行っていますが、ほとんどのケースは、迷惑メールに分類されてしまったためと考えられるので、そちらを確認していただけると良いと思います。</p>
<h2>Bootcamp、ハッカソン、アイデアソン</h2>
<p>3月22日23日の週末に、シンギュラリティ・ソサエティ主催で、ブートキャンプの発表会と、<a href="https://github.com/receptron/graphai">GraphAI</a>のハッカソンを行いました。</p>
<p>ブートキャンプは、シンギュラリティ・ソサエティで数ヶ月に渡ってアプリやサービスを作るイベントで、今年で二期目になります。普段はスラック上で仲間を集めたり、議論しながら開発をしてもらい、今回のような発表会で成果を披露してもらいます。</p>
<p>個人でアプリを作っている方から、ベンチャー企業でサービスを本気で立ち上げている人まで様々で、進捗状況は様々ですが、やはり「継続は力」で、発表される製品やサービスは、発表のたびに良くなっています。</p>
<p>私としては、ブートキャンプがそんな「やる気のある人たち」にとってのインキュベーター（孵卵器）のような役割を果たすことが出来れば、と開催しています。</p>
<p>ハッカソンの方は、オープンソースで開発しているGraphAIをより多くのエンジニアに理解していただくためのイベントで、1月から続いている「コントビューション・フェス」の締めくくりのイベントとして開催しました。GraphAIを使ったアプリケーションや、GraphAIそのものへのコントリビューション（＝オープンソース・プロジェクトに何らかの形で寄与すること）を行っていただき、貢献度の高い人を表彰する、というイベントです。</p>
<p>この手のイベントを開催する時は、毎回、ドキドキします。参加型のイベントなので、どんな人たちが集まるか、どんなプレゼンが行われるかがイベントの成功の鍵を握るからです。</p>
<p>幸いなことに、素晴らしいイベントになりました。優秀な人たちがたくさん集まってくれたし、誰もが一生懸命に物作りをしている姿勢が伝わって来ました。寸前になって、VC(ベンチャー投資家)の方たちと私のパネル・ディスカッションをすることが決まりましたが、そこでも有意義なディスカッションが出来ました。</p>
<p>１５チームほどの参加者があり、その中から４人にMac Mini (64GB)、３人に私の書物（メタトレンド投資）を進呈しました。他にも素晴らしい発表もありましたが、GraphAIをちゃんと理解しているかどうか、GraphAIのコミュニティを盛り上げる意味での貢献度で、入賞者を決めさせていただきました。</p>
<p>また、少し前に開催していたアイデアソンの方も、入賞作品が以下の二つに決まりました。</p>
<ul>
<li><a href="https://github.com/snakajima/life-is-beautiful/issues/482">#482 「Honest Filter」プレリリースのお知らせ ～本当の自分を取り戻す、未来型ウェアラブルデバイスが登場</a></li>
<li><a href="https://github.com/snakajima/life-is-beautiful/issues/469">#469 AIと海中ドローンで切り拓く未来の水産物流：生きた魚の効率的輸送システム</a></li>
</ul>
<h2>日本初ベンチャーとグローバル市場</h2>
<p>上にも書きましたが、VC(ベンチャー投資家)の方たちとのパネル・ディスカッション（最近は、ファイヤーサイド・チャットと呼ぶのが流行っているようです）で、色々と有意義な議論を展開することが出来ました。</p>
<p>トピックは、「日本初ベンチャーはどうやったらグローバル市場で活躍できるか」というものでした。</p>
<p>結局のところは「何を目指して起業したのか」に尽きると思います。日本のベンチャー企業は、たとえ成功したところで、こじんまりと日本市場で上場する程度で、満足してしまいます。</p>
<p>分かりやすい例が、mixiで、世界でも最も先を走るサービスだったにも関わらず、早々に日本で上場し、黒字化を目指す道を選びました。Facebookは、莫大な資金をVCから調達し、赤字を垂れ流しながら急成長して世界制覇を果たしました。どちらが正しいという話ではありませんが、mixiのようなやり方では、グローバル市場で活躍することは出来ません。</p>
<p>日本のベンチャー企業と、シリコンバレーのメガ・ベンチャーとでは目指しているものが大きく違うように私には見えます。</p>
<p>極端な言い方をすれば、日本のベンチャー企業の成功モデルが、「会社を上場させ、六本木ヒルズにオフィスを構え、港区ギャルと遊んで、美人アナウンサーと結婚する」ぐらいの「小さな成功」でしかないように私には見えるのです。</p>
<p>Elon Muskは、「電気自動車で地球を維持可能にする」ことを目的にTeslaを立ち上げ、「人が火星に暮らす未来を作る」ことをビジョンとして掲げてSpaceXを立ち上げました。目指しているところの次元が全く異なるのです。</p>
<p>日本のITベンチャーの多くが、ソシャゲで稼いで大きくなりましたが、彼らは、ソシャゲの、特にガチャのビジネスモデルが、一部の情報弱者に大きなお金を使わせる「搾取ビジネス」であることを十分に知った上でビジネスを運営して来ました。目的はお金儲けであり、そこにはビジョンのかけらもありません。彼らが、暗号通貨の交換所やFXのビジネスに手を出すのも、全く同じ理由です。</p>
<p>シリコンバレーの投資家が求めているのは、Elon Muskが掲げるような壮大なビジョンを抱えた起業家なのです。投資家たちは、彼らの広げる大風呂敷に賭け、莫大な資金を提供してくれますが、その見返りとして期待されているのは、満塁ホームランであり、一塁打、二塁打ではないのです。</p>
<p>Facebookが莫大な赤字を垂れ流しながら成長できたのは、そんな投資家から資金を集めることが出来たからですが、投資家から見れば、Facebookは投資先のベンチャー企業の一つであり、１０個投資した企業のうち、一つでも１００倍の利益をもたらしてくれるのであれば、それで十分なのです。</p>
<p>創業者から見れば、自分の会社が潰れてしまえば、それで終わりなので、あまりに多くのリスクは取り難いところですが、投資家から見れば、リスクを取ってこそのベンチャーであり、「着実に塁を進める送りバント」などは見たくないのです。</p>
<p>グローバル市場で活躍するためには、シリコンバレーのVCからの莫大な資金が必須ですが、彼らからお金を調達するということは、ホームラン狙いのハイリスク・ハイリターンな戦い方をすること半ば強いられることを覚悟する必要があります。調子が良い時には、イケイケで積極的に攻めることを期待されますが、一旦ダメだと見放されてしまうと、救済のための追加投資など全く期待できないのが、シリコンバレーのVCなのです。</p>
<p>グローバルな戦い方とは、そんな戦い方だということを知った上で、どこで勝負すべきかを決めるべきだと思います。目指すところが、上場であったり、お金儲けであるならば、グローバル市場で戦う必要はありません。しかし、人々のライフスタイルを変えるほどの大きな目標を持つのであれば、米国のVCから資金調達をしてグローバル市場でハイリスク・ハイリターンな戦いをしてみるのも悪くないと思います。</p>
<h2>なぜ日本ではDXやAIXが起こらないのか</h2>
<p>私は以前から、DX（デジタル・トランスフォーメーション）は、既存の会社が事業のデジタル化を行うような小さな変化ではなく、デジタル技術を中心に置いた新しいビジネスモデルを前提に作られたベンチャー企業が既存のビジネスを破壊することにより起こると主張してきました。</p>
<p>これは、AIX（AI・トランスフォーメーション）においても同じで、「既存の企業がAIを活用する」程度の生やさしい話ではなく、「人間以上に賢いAI」の存在を前提に置いたAI-nativeなベンチャービジネスが、既存のビジネスを破壊することによってしか起こらないと私は見ています。</p>
<p>先日、なぜ既存の企業がDXやAIXを起こせないかについて、分かりやすい説明がしてある記事を見つけたので紹介します。</p>
<ul>
<li><a href="https://note.com/singsoc/n/ne58ace56cfef">法律や税制にもリファクタリングを──シンプルな仕組みが社会を強くする</a></li>
</ul>
<p>ソフトウェアは、少しずつ変更や改良を加えていくと、徐々に複雑化が進んで、コードが読みにくく、非効率になってしまいます。そんな時には、「リファクタリング」と呼ばれる大規模な変更により、場合によっては土台から作り直す必要がありますが、それには手間もかかるし、大きなリスクも伴います。</p>
<p>会社も同じで、時代の変化と共に、いろいろな変更を加えていくと、それが負の資産となって歪みだらけになってしまい、身動きが取れなくなってしまいます。そんな時には、思い切ったリファクタリングにより、ビジネスモデルそのものから見直す必要がありますが、それには大きなリスクと痛みが伴うため、既存の企業には簡単には出来ないのです。</p>
<p>特に日本の場合、正社員を会社の都合だけで解雇できない「解雇規制」があるため、新しいビジネス・モデルにフィットしない社員を多く抱えた企業にとって、「トランスフォーメーション」と呼ばれるほどのリファクタリングを行うことは、ほぼ不可能なのです。</p>
<h2>日本の半導体戦略とラピダス</h2>
<p>以前にも触れたことがありますが、シアトルに<a href="https://www.nbr.org/">NBR(The National Bureau of Asian Research)</a>というシンクタンクがあり、（シアトルにいる間は）時々、会合に参加しています。テーマは、米国とアジアの国々との経済・安全保障面での連携・対立などです。当然ですが、最近は米国と中国の間の緊張関係が中心で、その観点から、AIや半導体の話をすることが増えています。</p>
<p>今回、東京大学で国際政治経済学・科学技術政策論を専門に研究されている鈴木一人教授がNBRに向けて、日本の半導体政策についてまとめた小論文（<a href="https://www.nbr.org/publication/the-japanese-semiconductor-renaissance-will-it-be-successful/">The Japanese Semiconductor Renaissance
Will It Be Successful?</a>）が発表されたので、それに沿って、私なりの解釈・解説を加えたいと思います。</p>
<p>この論文では、まず最初に、日本の半導体ビジネスが衰退した経緯について分かりやすく解説しています。</p>
<p>ひとことで言えば、TSMCによる（水平型の）ファウンドリ・ビジネスに垂直統合型の日本のビジネスが負けた、となります。しかし、Teslaのように、垂直統合で成功している会社もあるので、必ずしも垂直統合が悪いわけではありません。</p>
<p>日本の半導体産業がピークを迎えたのは、1980年代後半から1990年代初頭にかけてで、1990年には、日本は世界の半導体生産の51.1%を占めていました。</p>
<p>その頃活躍していたのは、NEC、東芝、日立製作所、三菱電機、松下電器、富士通、沖の７社です。電電公社（今のNTT）向けに通信機器を提供していた「電電ファミリー」と言われる会社群であり、IBMのメインフレームを真似した「IBMクローン」を作っていた会社群とも大きくオーバーラップしています。</p>
<p>日本の半導体メーカーは、80年代前半に、電電公社のデジタル交換機、および、メインフレームやミニコンピュータ向けのDRAMでシェアを伸ばしましたが、その背景には、通商産業省（今の経産省）を頂点に置いた「護送船団方式」があったことは否定できません。日本政府主導により作られた、さまざまな非関税障壁に守られて、日本の交換機・コンピュータ・半導体ビジネスが戦後の高度成長期に作られたのです。</p>
<p>IBM PCが発売されたのは1981年ですが、その後パソコン市場が徐々に広がり、80年代後半になると、パソコン向けのDRAM市場が大きく成長し始めました。</p>
<p>日本の半導体メーカーは、当初、その「パソコン特需」で大きく売り上げを伸ばしましたが、半導体技術が急速に進歩し続け、大量生産によるスケールメリットが重要になってくると、「複数の半導体メーカーが存在している」「垂直統合であること」がデメリットになって来てしまいました。</p>
<p>スケールメリットを享受するためには、思い切った設備・研究開発投資が必要になりましたが、大きな企業の一部である半導体部門には、そんなリスクを負うことが出来なかったのです。</p>
<p>TSMC（Taiwan Semiconductor Manufacturing Company）は、半導体の製造のみを請け負うファンダリとして1987年に台湾の国策で作られた企業で、半導体の製造技術一本にフォーカスすることにより、スケールメリットを享受して大きな売り上げを計上し、そこからさらなる積極的な設備投資という好循環を作り出すことが出来ました。</p>
<p>この論文によると、日本政府もこの問題に気付き、各社から半導体部門を切り離して統合しようと試みましたが、なかなかうまく行かなかったそうです。最終的には、かろうじて、日立製作所、三菱電機、NECの半導体部門を統合したルネサスだけが生き残った形になりましたが、ルネサスは、半導体の設計と製造の両方を行う企業である点で、TSMCとは大きく異なります。</p>
<p>この論文には書かれていませんが、パソコン市場が成熟・コモディティ化して、競争が激化したことも日本の半導体ビジネスを衰退させた原因の一つだと私は解釈しています。各社がパソコンには自社製のDRAMを採用するなど、悠長なことは言ってられなくなった上に、日本のパソコンのシェアそのものが大きく下がり始めたのです。</p>
<p>電電公社向けの電子交換機、日本の銀行向けのメインフレーム、のような護送船団方式が通用しないオープンな市場での戦いに負けてしまったのです。</p>
<p>少し話はずれますが、似たようなことは、日本の携帯電話市場でも起こりました。日本の携帯電話機メーカーは、NTTドコモを頂点にした護送船団方式でビジネスを立ち上げましたが、世界の通信方式が共通化が進み、AppleがiPhoneをリリースすると、日本のメーカーは、この市場から、ほぼ駆逐されてしまいました。</p>
<p>この論文では、現在、日本で進行しているの三つの半導体事業について紹介しています。</p>
<ol>
<li>TSMCの熊本工場、JAMS（TSMC、トヨタ、デンソー、ソニーの合弁会社）</li>
<li>北海道千歳市のラピダス</li>
<li>横浜のTSMCジャパン3DIC研究開発センター</li>
</ol>
<p>この中で、もっともリスクが大きいのが、ラピダスで、現時点での主戦場である3～4nmの一歩先を行く、2nm半導体を製造する、ファウンドリとして日本政府の肝煎りで作られた会社です。</p>
<p>この論文は、（複数の会社がリスクを負っている）JAMSと違って、ラピダスの設立資金の大半を日本政府が提供していること（約１兆円）、量産体制を作るまでには、さらなる投資が必要なことを指摘した上で、既存のビジネスからの収益を次世代技術への先行投資に使うことが出来るTSMCと戦うことの難しさを指摘しています。</p>
<p>リスクの大きさを考えると、民間からの大きな投資は期待できず、日本政府として、さらなる兆円単位の投資を続けることが出来るかどうかには大いに疑問があると私は見ています。</p>
<p>日本では、AIチップベンチャーのTenstorrentがラピダスを製造パートナーとして選んだかのように報道されましたが（<a href="https://xtech.nikkei.com/atcl/nxt/column/18/02258/111700015/">ラピダスが“伝説の”技術者とタッグ、「初期顧客として期待」と小池社長</a>）、実際のところは、LSTC（Leading-edge Semiconductor Technology Center）がTensorrentからAIチップのIPをライセンスし、それをラピダスに製造委託する、という話でした（参照：<a href="https://www.anandtech.com/show/21281/tenstorrent-licenses-risc-vcpu-ip-to-build-2nm-edge-ai-accelerator">Tenstorrent Licenses RISC-V CPU IP to Build 2nm AI Accelerator for Edge</a>）。</p>
<p>LSTCは、ラピダス会長を務める東氏が理事長として22年12月に設立された、東京都小金井市の国立研究開発法人産業技術総合研究所（産総研）内に作られたラピダスのパートナー企業で、このケースでは、Tenstorrentがラピダスをチップの製造委託先として選んだわけではないのです。</p>
<p>ラピダスが本当に必要なのは、顧客です。最先端の2nmプロセスを目指すのであれば、Apple、NVIDIA、Qualcommクラスの上客が必要で、そのためには、彼らの信頼を勝ち取る必要があり、簡単ではありません。しかし、一旦信頼を勝ち取って仕舞えば、新たな製造ラインを構築するための資金を社債の形で提供してくれることすらある、特上の顧客です。</p>
<p>そのためには、ラピダスは１日でも早く実績を作る必要があり、仲間であるLSTCからの注文でも構わないので、品質の高いチップを製造・提供し、それが市場で価値のあるものであることを証明することが求められており、簡単ではないと思います。</p>
<p>最近、国が主導する「国家プロジェクト」はことごとく失敗しています。グローバル化により、上に書いたように、高度成長期に日本経済を牽引して来た「護送船団形式」が通用しなくなっていることが大きな理由ですが、それと同時に、ホンダやソニーのような野心にあふれたベンチャー企業が活躍しにくい土壌になっている面もあるように見えます。「雇用の維持」を理由に、日本政府が既存のゾンビ化した大企業をさまざまな方法で守るからです。</p>
<p>ラピダスは、熱いビジョンを語るカリスマ性を持つ人が立ち上げたベンチャー企業とは違い、国家主導で人工的に作られた企業である点が一番の懸念です。莫大な資金が政府により提供され、人生を賭けて死に物狂いでラピダスのビジネスを立ち上げようとしている人がいない状況で、このプロジェクトがうまく行くとは、私にはどうしても思えないのです。</p>
<p>ラピダスに関しては、東洋経済オンラインに複数の解説記事が掲載されているので、下にリンクを貼り付けておきます。</p>
<p>【参考資料】</p>
<ul>
<li><a href="https://toyokeizai.net/articles/-/840502">半導体のラピダスはこのままでは99.7％失敗する</a></li>
<li><a href="https://toyokeizai.net/articles/-/750194">日本の｢半導体業界復活｣に絶対的に必要な3つ</a></li>
<li><a href="https://toyokeizai.net/articles/-/716877">常識破り｢国策半導体ラピダス｣成功に必要なこと</a></li>
<li><a href="https://toyokeizai.net/articles/-/669396">｢国策半導体｣ラピダス､2ナノ量産までの道筋</a></li>
<li><a href="https://toyokeizai.net/articles/-/747635">ラピダスの前途が手放しには｢楽観｣できない事情</a></li>
<li><a href="https://toyokeizai.net/articles/-/750421">国策ラピダスとTSMC&quot;2つの戦略&quot;で決定的な差</a></li>
</ul>
<h1>私の目に止まった記事</h1>
<p><a href="https://finance.yahoo.com/news/openais-viral-studio-ghibli-moment-232309102.html">OpenAI's viral Studio Ghibli moment highlights AI copyright concerns</a></p>
<p>OpenAIがDalle.3に置き換える、新しいイメージ生成モデルをChatGPTに追加しましたが、それに既存の写真を与え、「ジブリのアニメ風に変換して」と指示を与えると、とても上手に変換してくれることを発見した人がおり、それがミーム（ネット上の瞬発的な流行）となって、瞬く間にインターネット上に広まりました。</p>
<p>下の画像は、トランプ大統領とバンス副大統領の写真をジブリ風に変更したものです。</p>
<p><img style="width:380px" src="https://satoshi.blogs.com/mag2/April2025/trump_vp.png" alt=""></p>
<p>私の息子もこのミームに乗り、彼の運営するVCファンドの<a href="https://untapped.vc">ウェブサイト</a>をジブリ化してしまいました。</p>
<p><img style="width:380px" src="https://satoshi.blogs.com/mag2/April2025/untapped.jpeg" alt=""></p>
<p>ちなみに、OpenAIは、プロンプトとしてアーティストの名前を明示的に入力すると、それを弾くように作っていますが、なぜ「ジブリ風」だと通ってしまうのかは不明です。ニーズがあることは明らかなので、会社名ならば良いと判断したとも考えられます。</p>
<p>ジブリは、最近、著作権違反に厳しく対応すると発表しているので（参照：<a href="https://en.as.com/meristation/news/studio-ghibli-declares-war-on-piracy-with-a-triple-warning-n/">Studio Ghibli declares war on piracy with a triple warning</a>）、何らかの動きに出る可能性もあります。</p>
<p>【追記】</p>
<p>トランプ氏らの写真のドラゴンボール風アニメへの変更も成功しました（Prompt: Turn it into Dragon Ball style image.）。バンス副大統領の目が、ベジータのようになっている点が素晴らしいと思います。</p>
<p><img style="width:380px" src="https://satoshi.blogs.com/mag2/April2025/trump_dg.png" alt=""></p>
<p>「君の名は」風に新宿副都心の夕焼けを描かせることも出来ました。かなり許容度は上がっているようです。</p>
<p><img style="width:380px" src="https://satoshi.blogs.com/mag2/April2025/shinjuku_sunset.png" alt=""></p>
<p><a href="https://www.theinformation.com/articles/openais-agents-pose-risks-doordash-consumer-apps?rc=rvvbkr">OpenAI’s ‘Agents’ Pose Risks to DoorDash, Other Consumer Apps</a></p>
<p>OpenAIが人の代わりにウェブサイトからサービスを注文できる、&quot;Operator&quot;と呼ばれるAIエージェントを発表した際に、DoorDashなどの企業にパートナー企業として参加するようにコンタクトしたそうですが、その際に、そんな世界が本格的に広まってしまうと、DoorDashなどのサービスを提供する企業にとってはマイナスの要素が増える懸念があると、DoorDash側が指摘した話を紹介しています。</p>
<p>分かりやすい例が、関連するビジネスの広告です。（Uberイーツと同様のビジネスを行っている）DoorDashの場合は、特定のレストランの広告を出すことにより、そこで副収入を得ていますが、ウェブサイトに来るのがAIエージェントばかりになってしまうと、その収入がなくなってしまいます。</p>
<p>この手のサービスにとって、ウェブサイトはサービスの顔であり、そことユーザーとの間にAIエージェントが入ってしまうことは、大きな力をAIエージェント側に与えることになってしまい、中長期的にはサービスのコモディティ化などのリスクがあるのです。2000年代にGoogleの検索エンジンの力が絶大なものに成長したシナリオに似ています。</p>
<p>今後、AIエージェントの活用はますます増えて行くことは明らかで、そんな世界において、どこが力を持ち、どこがコモディティ化されるのかには、注目しておきたいと思います。</p>
<p><a href="https://joisino.hatenablog.com/entry/physics">言語モデルの物理学</a></p>
<p>言語モデルが動く仕組みを、物理現象を観察するかのようにシステマチックに調べた一連の論文（英文）を紹介する、日本語の解説記事です。とても分かりやすく書かれており、お勧めです。</p>
<p>トランスフォーマーは、Googleが2017年に&quot;<a href="https://arxiv.org/abs/1706.03762">Attention is all you need</a>&quot;という論文を発表して以来、言語モデルのデファクト・スタンダードになり、さまざまなところで使われてていますが、なぜ、さまざまな能力が発現するのかなどは、ちゃんと理解されていませんでした。</p>
<p>「言語モデルの物理学」とは、言語モデルが動く仕組みを理解するために、ノイズのない学習データを与えるなどして、システマティックに解析する学問で、最近になって、いくつかの論文が発表されています。</p>
<p>この記事は、それらの論文を一つつづ解説する形で、「言語モデルの物理学」とは何であるか、そして、それによって、私たちは何を学んだかが、丁寧に解説されている、素晴らしい記事です。</p>
<p>この記事からの一番の学びは、インターネットにある雑多な文章ではなく、人工的に作り出したノイズのない文章だけを使ってLLMに学習させることにより、学習データと、そこから作られる言語モデルの関係を、観測することが出来るという点です。筆者は、「真空状態で物理現象を観察するようなもの」と表現していますが、まさにその通りです。あえて与える学習データを絞り込むことにより、言語モデルが何にどう学んでいるかを可視化することが可能なのです。</p>
<p>パラメータ一つあたりに蓄積できるデータが２ビットだというデータも非常に興味深い数字です。言語モデルは、与えられた教育データをベースにパラメータの値を定めますが、それはある意味のデータ圧縮であり、パラメータ数と蓄積できるデータ数との関係が明らかになったことは、（学習データ量とパラメータ数のバランスが重要だと主張する）「<a href="https://arxiv.org/abs/2203.15556">Chinchillaペーパー</a>」の主張を裏付ける、貴重なデータです。</p>
<p><a href="https://x.com/karpathy/status/1902046003567718810">Digital Hygiene by Andrej Karpathy</a></p>
<p>最近、急増しているフィッシング詐欺などに引っかからないためには何をすべきかが書かれた、Andrej Karpathyによる文章です。素人には実行することが難しいことが書かれていますが、私のお勧めは以下のものです。</p>
<ol>
<li>パスワードは自分で作らず、ブラウザーやパスワード管理アプリに自動的に作らせ、覚えさせる。</li>
<li>パスワードは自分で打ち込まず、ブラウザーやパスワード管理アプリに任せる。</li>
<li>メールで送られてきたURLは原則としてクリックせず、自分でURLを打ち込む癖をつける。</li>
<li>ググってウェブサイトに行く場合には、広告ではないことを確認してからリンクをクリックする。</li>
<li>ウェブサイトのログイン画面で、ブラウザーやパスワード管理アプリがパスワードを提供してくれない場合には、フィッシングサイトである可能性が高いので、そこからログインしようとしない。</li>
<li>パスワードを紙に書いて保管することはとても危険。特に、アカウント番号も同時に分かる形で保管してはいけない。</li>
</ol>
<p><a href="https://x.com/janrosenow/status/1903072627184353620">Wind and solar now produce more than coal in the US</a></p>
<p>米国において、風力と太陽光からの発電量の合計が、石炭火力による発電量を超えたことを伝える記事です。</p>
<p>トランプ大統領は、石炭火力への回帰を選挙活動時には訴えていましたが、これは、石炭産業の衰退によって職を失った人たちからの票を集めるためのものでしかなく、今さら、石炭火力を増やすことは現実的ではありません。</p>
<p>しかし、パリ協定からの脱退を見ても分かる通り、トランプ氏は、地球温暖化対策に懐疑的なことは事実で、再生化エネルギーへの補助金を減らしたり、シェールガスの採掘を増やしたりした結果、再生可能エネルギーの比率が伸び悩むことになる可能性は高いと思います。</p>
<p><a href="https://www.hiroshima-u.ac.jp/news/89290">膵臓の細胞からアルツハイマー病を抑制する因子が放出されることを発見しました</a></p>
<p>広島大学大学院の研究者（小澤孝一郎 教授）による、画期的な発見を報告するプレスリリースです。この記事によると、小澤孝一郎教授は、膵臓β細胞死を起こしている糖尿病の患者はアルツハイマー病の発症リスクが上昇する点に着目し、「膵臓β細胞から神経保護因子が分泌されているのではないか」との仮説を立てて、研究してきたそうです。</p>
<p>その結果、膵臓β細胞が分泌するFGF23という物質が、神経細胞の細胞死抑制効果を持ち、アルツハイマー病の進行を抑制する可能性があることが分かったそうです。</p>
<p>この手の研究結果が、実際の治療に役立つまでには時間もかかるし、失敗する可能性もありますが、多くの高齢者がアルツハイマー病になることを考えると、とても重要な発見のように思えます。</p>
<p><img style="width:380px" src="https://satoshi.blogs.com/mag2/April2025/saibou1.png" alt=""></p>
<p><a href="https://devblogs.microsoft.com/foundry/integrating-azure-ai-agents-mcp/">Introducing Model Context Protocol (MCP) in Azure AI Foundry: Create an MCP Server with Azure AI Agent Service</a></p>
<p>Anthropicが提唱している、MCP(Model Context Protocol)を、Microsoft Azure上でどう活用するかを説明する、Microsoftによる記事です。</p>
<p>以前にも指摘しましたが、MCPは、LLMのfunction callingを拡張し、リモートサーバーにあるサービスをLLMからダイナミックに呼び出すなどする際には、とても便利な仕組みで、業界のデファクト・スタンダードになる可能性があります。</p>
<p>Microsoftは、AnthropicのライバルであるOpenAIの大株主ではありますが、それにも関わらずMCPについての解説を作ってくるあたりが、今時のオープンなイノベーションの形を良く表していると思います。</p>
<p><a href="https://x.com/TheHumanoidHub/status/1903173205155815431">robotic-assisted cinematography and virtual ad production</a></p>
<p>ここ１年ほど、人型ロボット（ヒューマノイド）の開発競争が激化しており、その応用範囲も広がっていますが、このTweetは、人型ロボットにカメラを持たせて映像を撮影する様子を紹介しています。通常、カメラをスムーズに大きく動かすには、大型の特殊な機械を必要としますが、スムーズに動くことが可能な人型ロボットを使えば、はるかに手軽に、安価に行えます。</p>
<p><img style="width:380px" src="https://satoshi.blogs.com/mag2/April2025/robot_cinema.png" alt=""></p>
<p>人型ロボットというと、人間の仕事を置き換える点ばかり注目されていますが、こんな風に「ロボットにしか出来ないこと」も沢山あることを考えると、まさにこれこそが、「メガトレンド」の一つだと思います。</p>
<p><a href="https://x.com/elonmusk/status/1902899450487455809">Tesla all-hands live presentation</a></p>
<p>Elon Muskによる、Teslaの社員総会でのプレゼンです。特に新しいことを言っているわけではありませんが、冒頭のビデオは社員のモチベーションを上げるために作られた良いビデオだし、ブレのないElon Muskの発言は、Tesla株を保有している私にとっては、頼もしい限りです。</p>
<p><a href="https://x.com/MistralAI/status/1901668499832918151">Introducing Mistral Small 3.1. </a></p>
<p>フランスのAIベンチャー、Mistralによる、24BパラメータのSLM（小規模言語モデル）の発表です。</p>
<p>先日、MicrosoftのPhi-4(9.1GB)、GoogleのGemma3(17GB)、Alibabaのqwq(32b)の話を書いたばかりですが、それらと同様のサイズのSLMです。</p>
<p>「ある満月の夜、空を見上げると、月のすぐそばに火星が見えた。その時、地球と火星の距離は遠いのか近いのか？」の問いにはまともに答えられませんでした。それ以外にも、いくつか試しましたが、私が試した範囲では、あまり優秀には思えませんでした。</p>
<p><a href="https://x.com/the_ai_investor/status/1902594941140004929?s=46">Jensen just ended the Nvidia vs. ASIC debate for good.</a></p>
<p>DeepSeekが「考えるモデル」をライバルよりも安く（＝少ない数のGPUで）作ることに成功したことに関し、それにより、逆にGPUの需要が増えることを説得力を持って語る、NVIDIA CEO、Jensen Huangです。私は、NVIDIAの株も持っているので、この手のCEOの発言には常に注意を払うようにしています。</p>
<p>この件に関しては、Bloombergにも「<a href="https://www.bloomberg.com/news/articles/2025-03-19/nvidia-ceo-says-deepseek-impact-analysis-wrong-more-gear-needed">Nvidia CEO Says Fears About DeepSeek’s Impact Are Misplaced</a>」という記事で紹介されていましたが、この記事をベースに、「Jensen氏が日本語で５分間のスピーチを行うので、原稿を書いて」とChatGPTにリクエストしたところ、以下のようなスピーチ原稿を書いてくれました。</p>
<p>【スピーチの原稿】</p>
<p>最近、一部の報道や市場の声の中で、「DeepSeekのR1モデルによって、今後はAIに必要な計算量が減少し、Nvidiaのような高性能チップは必要なくなるのではないか」という懸念が聞こえてきました。私はこの場で、はっきりと申し上げたいと思います――その懸念は、根本的に誤解に基づいています。</p>
<p>まず、R1モデルのように高度で洗練されたAIを動かすには、より多くの計算能力が必要なのです。AIが生成する回答が複雑になり、理解力が深まり、推論が可能になればなるほど、その裏側には膨大な演算処理が走っています。それは、ただチップの数を減らせば済む話ではありません。</p>
<p>DeepSeekが「低コストで高性能」とアピールしているのは事実です。しかし、それはコスト構造の一部に過ぎません。実際に我々の最大手顧客たちは、その後もAIインフラへの投資を拡大しています。Bloombergの最新の調査でも、データセンター事業者の支出は予想を超えるスピードで増加しているという結果が出ています。</p>
<p>よく「お客様が自社でチップを開発することで、Nvidiaの地位が脅かされるのではないか」という声もあります。たしかにGoogleなどは自社用のASICをBroadcomとともに設計しています。しかし、重要なのは設計されたからといって、それが本当に現場で使われるとは限らないということです。多くのケースで、試作段階にとどまっています。</p>
<p>そして、私たちNvidiaのHopper、そして最新のBlackwellアーキテクチャは、それらの競合チップの何十倍もの性能を持っています。BlackwellはHopperの40倍の処理能力を持ち、すでにHopperを超えるペースで注文が入っています。これはクラウド事業者からの注文だけにとどまらず、今後はあらゆる企業が自社でAIデータセンターを持つ時代になります。</p>
<p>さらに、仮に景気が後退したとしても、企業は逆にAI投資を加速させます。なぜなら、AIこそが新たな収益の源泉であり、効率を飛躍的に高める手段だからです。</p>
<p>また、米国政府が提案している一部の輸入品への関税についても、我々への影響は最小限です。重要な部品については、台湾TSMCのアリゾナ工場など、国内生産へと切り替えを進めており、供給体制の強靭化も着々と進んでいます。</p>
<p>結論として申し上げたいのは、DeepSeekは革新的な存在であり、それは歓迎すべきことです。しかし、それがNvidiaのビジネスモデルや成長を脅かすことはありません。むしろ、より高性能なインフラへのニーズを加速させているのです。</p>
<p>AIの未来は、より深く、より広く、そしてより多くの計算を必要とします。私たちは、その未来に向けて、すでに走り始めています。</p>
<p><a href="https://x.com/TradexWhisperer/status/1903487062491152459">$PLTR @Heineken Partnership is Blossoming</a></p>
<p>世界中にビールを販売しているHeinekenにとっては、需要を見越した生産と流通は、非常に重要です。（コストがかかる）在庫を減らし、（売り上げにとってマイナスになる）売り切れ状態を極力なくすことが、利益率に大きな影響を与えます。</p>
<p>このプレゼンは、HeinekenのCOOによる発表で、Palantirの技術を使って、この問題を解決していることを紹介しています。</p>
<p>前にも指摘しましたが、Palantirのことは上場時から気になっていましたが、どうも理解出来ずに、当初は株の所有をためらっていましたが、順調に売り上げを伸ばし、利益を上げていることを見て、株を少し購入しました。</p>
<p><a href="https://blog.palantir.com/palantir-joins-forces-with-u-s-army-for-project-convergence-capstone-19c79f3c748a">Palantir Joins Forces with U.S. Army for Project Convergence Capstone</a></p>
<p>アメリカ陸軍は、最新技術を導入して作戦の迅速化と精度向上を図る「Project Convergence（プロジェクト・コンバージェンス）」という演習シリーズを実施しています。PCC5はその最新の実験イベントです。この記事は、Palantir社は、この演習で中心的な役割を果たしたことを報告しています。</p>
<p>この記事によると、Palantirのソフトウェアは、</p>
<ul>
<li>作戦資産のリアルタイム追跡</li>
<li>多領域（陸・空・海・宇宙・サイバー）にわたる認識と管理</li>
<li>インタラクティブなマップによる状況把握、戦略立案、リソース配分</li>
</ul>
<p>し、これにより、前線から司令部までがリアルタイムで同じ戦況情報（COP）を共有出来るようになるそうです。</p>
<p>分かりやすく言えば、軍事戦略のDX（デジタル・トランスフォーメーション）化であり、そのニーズに、Palantirが上手に答えた、という話だと理解しています。</p>
<p><a href="https://x.com/JonathanRoss321/status/1903072876137533902">What can AI researchers learn from TPU and LPU chip design?</a></p>
<p>TPU (GoogleのAIチップ)とLPU（GroqのAIチップ）の両方の設計に関わった、GroqのCEO、Jonathan Rossによる、AIチップ・デザインに関するコメントですが、とても鋭いことを語っています。</p>
<p>過去に成功した（計算用の）チップを見ると、一つの共通点があり、それは「Programmable(プログラムが可能)」であることだそうです。直感的には、Transformer専用のASICを作った方が、効率が良く、それを持って(NVIDIAの)GPUが勝つことが可能なように思えますが、それでは市場でニッチな役割しか果たせず、最終的にはさまざまな計算に使える汎用チップが市場では受け入れられる、という話です。</p>
<p>ちなみに、GroqのLPUは、GPUと同様にプログラム可能な汎用チップですが、大きな違いが一つあります。CPUやGPUが、計算リソースやキャッシュメモリをかなりダイナミックに活用しているのに対して、LPUはコンパイル時に全ての割り当てを決めてしまうため、計算時間がコンパイル時に決まっている上に、(GPUやGPUに必要な)制御回路が不要な分だけ、計算機能そのものにより多くのトランジスタを活用出来るのです（参照：<a href="https://blog.codingconfessions.com/p/groq-lpu-design">The Architecture of Groq's LPU</a>）。</p>
<p>ちなみに、世界市場ではほとんど知られていませんが、プリファードネットワークのAIチップ、MN-Coreも、同様の設計思想で作られています。</p>
<p><a href="https://news.tv-asahi.co.jp/news_society/articles/900021062.html">「歴史上AIはいなかった」歴史学者ハラリ氏が語るAIの危険性　人類のための“処方箋”</a></p>
<p>ベストセラー『サピエンス全史』などで知られる歴史学者　ユヴァル・ノア・ハラリ氏による、AIが社会や民主主義に与える悪影響を警告するインタビュー記事です。</p>
<p>ハラリ氏は、AIによりコントロールされるSNSのアルゴリズムが、世論をコントロールする時代になったことを警告した上で、Elon Muskが行っている官僚組織の解体が、より多くの権限をAIに与えることに繋がり、それが社会を不安定にし、民主主義を脅かすと警告しています。</p>
<p>ハラリ氏らしい発言だとは思いますが、「欲」を持つ人間が権限を持つからこそ共産主義が失敗し、民主主義も欠陥だらけであることを考えれば、データ・ドリブンに行える部分に関しては、AIに任せてしまうのもありだと私は考えています。</p>
<p>もちろん、そうなると、今度はAIシステムの設計者（欲を持つ人間）が大きな力を持ってしまうことになりますが、そこは、オープンソースの力を使えば回避することが可能ではないかと私は期待しています。</p>
<p><a href="https://www.theinformation.com/articles/deepseek-national-treasure-china-now-closely-guarded">DeepSeek, a National Treasure in China, is Now Being Closely Guarded</a></p>
<p>OpenAIに匹敵する推論AIモデルをより低コストで開発し、1月に世界的な注目を浴びた中国にAIベンチャー、DeepSeekが、中国国内では「国宝級」の扱いをされる存在になったことを報告する記事です。</p>
<p>中国政府は、DeepSeekの成功を対米技術封鎖への勝利と見なし、同社は習近平国家主席や李強首相との会合にも招かれているそうです。しかし同時に、DeepSeekの一部社員は、中国政府からパスポートの提出を求められ、自由に海外渡航できなくなっているそうです。</p>
<h1>質問コーナー</h1>
<h3>【質問】</h3>
<p>私は現在新卒2年目で不動産業界で働いております。主に賃貸マンション開発に携わることが多く、現在日本の賃貸マンション市況(首都圏)は好調で前向きに仕事に取り組めております。今後も利上げや工事費の高騰等から分譲マンションに手を出しづらく、賃貸市況は引き続き好調と思っております。</p>
<p>是非とも今後の仕事でも活かしていくべく、中島さんから今後の賃貸マンション市況について見解等ございましたらご教示いただきたいです。</p>
<h3>《回答》</h3>
<p>市況のことは、専門家でもない私には分かりませんが、基本的には不動産投資は好きです。家賃収入で数％のリターンが得られ、かつ、キャピタルゲインの可能性もある点が気に入っています。一時期は、日本に３つ、シアトルに５つほど賃貸用の不動産を持っていたことがあります。</p>
<p>もし、日本でマンション投資をするのだとしたら、都心のそれも交通の便の良い場所を選ぶだろうと思います。日本全体では、人口が減少しているとは言え、東京一極集中はさらに進むと予想できるからです。</p>
<p>ちなみに、新築マンションであっても値切ることは十分に可能なので覚えておくと良いと思います。特に、完成間近、もしくは、完成しているにも関わらずまだ売れていない物件は、かなり強気に値切ることが可能です。値切らずに買うのは損、と言えるぐらいです。</p>
<h3>【質問】</h3>
<p>「自分にとっての根源的な好きを見つけるのは、人生を豊かにする上で大切なこと」的、考え方があると思います。なんとなく正しい気がしますが、実際、中島さんのように好きなことで身を立てている方もいるので、説得力があります。</p>
<p>ところが、最近読んだ本で</p>
<p>「人間は圧倒的にやったことを好きになるように出来ている」（数学者・岡澄）という考えを知りました。個人的には、これはこれで、実感として正しいような気がしています。</p>
<p>中島さん自身は「好きは先天的なものである」派だと思いますが、この「好きは後天的に作られる」的な考え方について、ご意見をお願いします。</p>
<h3>《回答》</h3>
<p>それなりに正しいとは思いますが、好きでなければ「圧倒的にやる」ことは不可能なので、結局は好きなことを見つけることが重要だと思います。もちろん、最初は好きでもなかったけれども、始めて見たら好きになる、ケースもあるので、色々と試すことが大切だと思います。</p>
<h3>【質問】</h3>
<p>The Informationの記事の内容の濃さに驚かされました。独自の視点で書かれた記事ばかりです。</p>
<p>私は新聞社の記者なのですが、紙面は「発表モノ」がほとんどで、独自性の高い記事に遭遇する頻度は年々低下しています。</p>
<p>今後、企業や行政の発表モノはAIに代替され、キュレーションもAIがやるでしょう。ストレートニュースを加工するコストは限りなくゼロに近づいていくと思います。発表報道に未来がないのは明白です。</p>
<p>中島さんが感じる日本メディアの問題点は何ですか。どう変わるべきですか。</p>
<h3>《回答》</h3>
<p>日本のメディア、特に新聞やニュースは、インターネット以前の「誰でもが知っておくべき情報を届ける」という役割から脱却できていないように私には見えます。</p>
<p>「通信社とか記者クラブ経由で流れてくる情報」には価値がない、という事実を強く意識した上で、「どこで勝負する（＝ユニークな価値を提供する）メディアなのか」を考えて戦略を立てるべきです。</p>
<p>日本の場合、既存の大手メディアが「通信社とか記者クラブ経由で流れてくる情報」を流すだけの「価値のないメディア」に成り下がり、一方で、文春のようなところがスキャンダラスな暴露記事報道ばかりしていますが、その間が欠けているように私には感じられます。マスコミの役割の一つが、政府や大企業を監視することであることを考え、もっとそちらに時間と労力を割くべきだと思います。</p>
<h3>【質問】</h3>
<p>千葉工業大学古田さんとの対談動画拝見しました。</p>
<p>そこでボストン・ダイナミクスのロボ動画は怪しいみたいな話を古田さんがされていましたが、動画は偽物とお考えでしょうか。
最近もXでボストンのロボの動画が沢山流れてきて、みんな感動していました。</p>
<p>実際、どこまで本当なのか気になります。</p>
<h3>《回答》</h3>
<p>完全な偽物とは思いませんが、都合の良いもの（たまたまうまく動いたものだけ）だけを編集で組み合わせて発表する、などは良くある話です。あの手のビデオを１００％信じる必要はありませんが、ボストン・ダイナミクスが何を目指してもの作りをしているのか、どんなものが今後発売されることになるのかを知るにはとても有効だと思います。</p>
<h3>【質問】</h3>
<p>楽天証券の件、非常に怖いです。</p>
<p>証券会社選びのコツ及び今回の件のような被害に遭わないための対策(中島さんが普段行われている資産のリスク管理)などを教えていただきたいです。</p>
<h3>《回答》</h3>
<p>上に、私なりのフィッシング詐欺対策を書いたので参考にしてください。</p>
<h3>【質問】</h3>
<p>私は大学4年生で、これから芸人になりたいと考えています。芸人がネタ作成やパフォーマンスにおいてAIを効果的に活用するためのアイデアはありますでしょうか？私が現在試しているのは動画生成AIを使って面白い動画を大量に作ってYouTubeにあげることです。</p>
<h3>《回答》</h3>
<p>お笑いに関しても、AIにネタを作らせる、動画を作らせる、などは起こることは明らかで、今後Youtubeに自動生成された動画が溢れることは必然だと考えています。AIの能力が上がり、かつ、同時にコストが下がっていくので、そこはレッド・オーシャンになると考えて良いでしょう。</p>
<p>企業として技術を駆使して本気の勝負をするならいざ知らず、個人の芸人として、そこで勝負するのはとても難しいと私は思います。</p>
<p>芸人として食べて行くのであれば、まずはあなた自身が芸人として「面白いネタを作る」「人の心を掴む」などのテクニックをマスターした上で、AIを使って、それを拡張することを考えた方が良いと思います。</p>
<h3>【質問】</h3>
<p>3月4日号のメルマガでも取り上げられていたMicrosoftの量子チップやGoogleの最新量子コンピューティングチップ ウィローの登場によりビットコインなどの仮想通貨の暗号が破られるのではないか？という懸念が今まで以上に浮上しているように思えます。</p>
<p>中島さんはこの問題についてどのような見解をお持ちでしょうか？</p>
<h3>《回答》</h3>
<p>この問題に関しては、私も同様の疑問を持ち、調べたところ、ビットコインの設計者は、それを見越して、暗号化の部分はアップデートが可能な設計になっているそうです。なので、量子コンピュータの進化により、今の暗号が破られるようになったとしても、アップデートで対応できると私は理解しています。ただし、アップデートの際には、コミュニティの同意が必要であり、場合によっては、ハードフォーク（別のブロックチェーンをスタートすること）も起こりかねないので、混乱はするだろうと思います。</p>
<h3>【質問】</h3>
<p>中島さんが開発されているGraphAIは、Open AIなどのAPIを使ってアプリを開発できるものの、ユーザや開発者が使用するデータは、Open AIなどの会社に渡さずに済むと理解しています。</p>
<p>Grapysでは、AIとの会話中にデータを貼り付けても、そのウェブサイト上で、データを留めておけると思います。(ここの理解が間違っていたらすみません)</p>
<p>なぜこんなことが出来るのか分からないので、解説していただけませんでしょうか？</p>
<h3>《回答》</h3>
<p>少し誤解があるようですが、GraphAIからは、OpenAIのようなウェブ・サービス型のAIを使うことも出来るし、ローカルで動くオープンソースなAIを使うことも出来ます。</p>
<p>なので、与えるデータをOpenAIなどの会社に渡したくないのであれば、ローカルで動くオープンソースなAI（Meta Llama3.2, Microsoft Phi-4、Google Gemma3など）を使う必要があります。ローカルで動くAIを使う限りは、サードパーティにはデータは渡りません。Grapysも同様です。</p>
<h3>【質問】</h3>
<p>Deep researchを使用して調査を行う上で、情報の精度や質をより高めるならば、英語のコンテキストで指示を出してまとめさせるのが良いかと考えています。中島さんのメルマガの内容を拝読すると、中島さんもおそらくそうしていると思いますが、指示を出す際の英語のコンテキストはDeepLを使用して日本語から英語に変換して指示出しするなど、一手間かけていらっしゃいますか？
また、Deep research から返ってきた英語のレポートですが、日本語に変換した方が理解が深まると思いますので、例えば英語→日本語に翻訳するようにDeep research に指示を出したりしていますでしようか？</p>
<p>(というのも当方、英検準1級に合格できた英語読解力はあるものの、英語よりも日本語で文章を読んだ方が理解が深まる感覚があるためご質問させていただきました)</p>
<h3>《回答》</h3>
<p>私の場合は、質問は英語で直接書きます。私が主に使っているPerplexityのDeep Researchは、プロンプトで入力した単語をそのままウェブ検索で使うので、日本語でプロンプトを書くと、日本語の記事ばかり探してしまうので、注意が必要です。</p>
<p>英語でプロンプトを書いたり、英語で出力されたレポートを読むのが面倒であれば、間に翻訳を挟んでも良いと思います。</p>
<p>試しに、Perplexityに&quot;Find out if the advancement of quantum computing is a threat to bitcoin. レポートは日本語で書いて。&quot;と入力したところ、英語で記事を検索した上で、レポートは英語で書いてくれました。</p>
<p>【ディープ・リサーチ】<a href="https://www.perplexity.ai/page/liang-zi-konhiyuteinkunojin-bu-BE4Fhj5vT6OqmfSHdsZCwA">量子コンピューティングの進歩はビットコインにとって脅威となるか</a></p>
<h3>【質問】</h3>
<p>数学が大の苦手です。学生時代は数学を避けるために、私立大学の文系学部の道を選んだほどです。</p>
<p>メルマガに掲載されている頭の体操や、よくある「ノートと鉛筆合わせて100円。鉛筆はノートより40円安い。鉛筆は1本いくら？」というような問題が苦手です。答えが分かってからも理解に時間がかかってしまいます。</p>
<p>「高校数学を学び直したい」とまではいかないものの、このような問題に引っかからない程度には、数学的な思考力を身につけたいという気持ちがあります。特に、中島さんのメルマガを読んでいると、知的好奇心が刺激され、数学に対して前向きな気持ちが芽生えてきました。</p>
<p>私のような、数学に苦手意識がある人間の場合、まずどのような教材から始めるのがおすすめでしょうか。何かアドバイスをいただけると幸いです。</p>
<h3>《回答》</h3>
<p>たくさん問題を解くことが一番だと思います。私の場合、小学校の頃から多湖輝氏の「頭の体操」を読んでいたし、算数の応用問題集（中学受験）を手に入れて、片っ端から解いていました。</p>
<h3>【質問】</h3>
<p>中島様のお話の中でNVIDIAの優位性が変わらないに少し疑問を感じています。</p>
<p>私の展望では学習用と推論用が分かれて、エッジAIが進むと思います。特に、学習用では一時的な利用が多いことや企業でサーバーを保有するにはリスクが高いためPaaSのクラウド提供になるかと思っています。</p>
<p>学習用ではcerebrasが本命かと思いますが普及していない理由にNVIDIAの優位性の一つがcudaが広く普及していることだと思っています。</p>
<p>しかしながらCerebrasといった新興のGPUもcudaを使わずともPytorchなどが使えるほか、仮に新しい機構が生まれてcerebrasのcsoftなどを書かないといけないとしてもcsoftを人間が読まないでもそれ自身をAIに書かせられると思うので皮肉なことにNVIDIAによるAIの発展によってGPUがNVIDIAである必要性がなくなったような気がしています。</p>
<p>そのため「特定のアーキテクチャに特化したASICへの投資には大きなリスクがあり(例：Transformer専用のEdged)、汎用GPUの上に強力なソフトウェアスタックを持ったNVIDIAにとって有利な状況が今後も続くと考えて良いように思えます。」（3/11のメルマガ）とありますが、cerebrasもDiffusionモデルが使えるらしいことや上記の理由から、今後のGPU設計会社としてのNVIDIAは終焉していくかと思っていますがもしご意見を頂けましたら幸いです。（ちなみにNVIDIAはほかの優位性があると思っているので今後NVIDIAそのものが没落するとは考えていません）</p>
<h3>《回答》</h3>
<p>確かに、NVIDIAの優位性は絶対的なものではないし、CerebrasやGroqのような強力なライバルも現れています。また、エンタープライズが、サービス型のAIを嫌い、オープンソースなAIによる推論をオンプレのマシンで動かすようになった際に、NVIDIA以外の選択肢があるのも事実です。実際、私自身も、SLMをMacBook Pro(M3チップ)上で動かし始めています。</p>
<p>ただし、学習プロセスにおいてNVIDIAを置き換えるのはとても難しいと思います。AIの研究者たちが、NVIDIAが提供する開発環境に慣れており、ライブラリも充実しているため、切り替えには大きなリスクが伴うためです。</p>
<p>先のことを予想するのはとても困難ですが、少なくともここ２～３年に関して言えば、学習プロセスにおけるNVIDIAの優位性は持続し、推論プロセスに関しては、市場の拡大と共に選択肢も増え、サーバー側では、GoogleのTPUに加えて、CerebrasやGroqなどの「NVIDIA以外」のチップがそれなりのシェアを確保し、ローカル環境では、Apple、Qualcomm、AMDなどが活躍するだろうと私は見ています。</p>
<p>最近、NVIDIAが発表した、DGX Spark（旧 Project Digits）は、今後のNVIDIAの活躍を決める、とても重要なデバイスだと私は見ています。開発者・研究者の多くがDGX Sparkを購入し、かつ、エンタープライズがDGX SparkをオンプレでオープンソースなAIを動かすマシンとして採用することになれば、NVIDIAの優位性が、推論プロセスにおいても持続することになります。</p>
<p>次世代Windowsパソコンである、Copilot+ PCと同様に、注目して行きたいと思います。</p>
<h3>【質問】</h3>
<p>生成AIを活用してシステム開発をしてみたいのですがコードがほとんど読めません。開発フローのみ簡単に勉強した程度です。</p>
<p>コードが読めるように勉強すればいいのですが、AIの使い方次第で、読めなくても弱点を補う方法があるのかどうか教えて頂きたいです。</p>
<h3>《回答》</h3>
<p>現時点では、AIにコードを生成させても、それを使いこなすのは簡単ではありません。しかし、今は過渡期であり、近い将来（たぶん、1年以内）には、コードが読めない人でも、AIにコードを生成させて仕事をさせることが可能になると私は見ています。</p>
<h3>【質問】</h3>
<p>ブロックチェーンを使って納税者が何に税金が使われるかを選んで納税できる仕組みがあれば透明性も確保できていいかな？と思うのですがどうでしょうか？</p>
<h3>《回答》</h3>
<p>私も思います。絶対的な力を持つ管理者がいないブロックチェーンは、国民が政治家や官僚を監視する仕組みとしては最適だと思います。問題は、こんなシステムの導入を、当事者である政治家・官僚たちが嫌がってしまう点です。そこを乗り越えるのが難しいのがネックです。</p>
<h3>【質問】</h3>
<p>“福岡を舞台に世界が注目する映画を作る”という自己実現を目指しています。地域を軸にグローバルに届けるために、中島さんならどのような切り口やテーマを狙いますか？地域とテックの融合に可能性を感じています</p>
<h3>《回答》</h3>
<p>最初に頭に浮かんだのは、福岡に古代文明の遺跡が見つかり、それを舞台に何らかの事件が起こるという映画です。実在する神社や山などを舞台として使い、映画を観た人たちが、そこに訪れたくなるように誘導します。</p>
<p>テックを絡めたいのであれば、遺跡から見つかった物質が、実は宇宙から来た先進的な文明を持つ宇宙人が残したデバイスであり、それを解析した結果が、画期的な半導体の開発に繋がる、というストーリーにしても良いと思います。最初はSF小説のように始まりますが、その秘密を巡って、米国・中国・台湾・日本が争う、産業スパイ小説に発展します。</p>
<p>上のアイデアをベースに、AIに小説の冒頭の部分を書かせてみました。</p>
<p><a href="https://note.com/lifeisbeautiful/n/nfc0d6eb2197d">宙（そら）の記憶</a></p>
<h3>【質問】</h3>
<p>以前安野さんとの対談で、「IQの高いAGIを作ろうとしているビックテックに対して、日本ではドラえもんのような&quot;EQ&quot;が高いAIを作ることが重要ではないか。」とおっしゃっておりました。</p>
<p>一方で、最近 GPT-4o を使っているとすごく人間味のある回答が生成されるように感じます。（特別、プロンプトを工夫しているわけでもありません。）</p>
<p>これらは&quot;EQ&quot;も高くなるよう設計されていると考えられるのでしょうか？それとも&quot;EQ&quot;が高いAIの出力は、また別なんでしょうか？</p>
<h3>《回答》</h3>
<p>私も最近のGPT-4oには変化を感じますが、EQが高いフリをしているだけにも思えます。明らかに、聞き手が喜ぶような話し方をしているように感じることがあります。</p>
<p>実際にEQが高いのか、EQが高いフリをしているだけなのかを見極めるのは難しく、見極めることが出来ないならば、フリで十分とも言えるので、これで良いのかも知れません。</p>
<h3>【質問】</h3>
<p>エンタープライズ、あるいはうちのような中小企業であっても、数十万円からローカルのAIを育ていていける、特に守秘義務と弊社業務への特化という意味で必要と思います　わからないのは、新しいバージョンの優れたモデルがどんどん出てくるので、乗り換える必要があると思いますが繰り返すのも大変です</p>
<p>せっかく育てたものは移行できるのでしょうか　自社内蒸留のようなことが必要になるのでしょうか　うまく訓練を引き継げるといいのですが</p>
<h3>《回答》</h3>
<p>ローカルLLM(言語モデル)のファイン・チューニングをお考えだと思いますが、ご指摘の通り、ファイン・チューニングは「（別のLLMへの）乗り換え」を難しくするし、そもそも手間とコストがかかるので、よほどのことがなければ、避けた方が良いと私は思います。</p>
<p>エンタープライズの場合、まずはRAG(Retrieval Augmented Generation、検索拡張生成)を試し、どうしてもそれでは不十分な場合にファイン・チューニングを行うべきと一般的に言われていますが、私もその通りだと思います。</p>
<h3>【質問】</h3>
<p>以下、質問ではないので恐縮ですが、シェアさせていただきたいと思いご連絡しました。</p>
<p>以前の記事で紹介されていた「AI-nativeな医療サービス」の内容を参考にして、スポーツ選手へのトレーニングとして実際に行ってみました。</p>
<p>その選手が抱える問題や課題について事前に話してもらうとともに、実際のトレーニング中の会話やインストラクション、エクササイズの説明を全て録音し、AIで自動文字起こししました。</p>
<p>それをChat GPTに入れて、次回のセッションの計画・指導におけるポイント・長期的に重視すべき内容などがアウトプットされました。まだまだ試行が足りないので継続する必要がありますが、非常に興味深い方法だと感じております。</p>
<h3>《回答》</h3>
<p>ありがとうございます。このコーナーでは、質問に限らず、この手のコメントも大歓迎です。ChatGPTに限った話ではありませんが、LLMは使い方次第では、とても大きな価値を発揮してくれるので、是非とも色々と試してみて下さい。</p>
<p>◇　◇　◇</p>
<p>私の過去のメルマガを活用して、私の代わりに質問に答えてくれるAIボットを知り合いのエンジニアが作ってくれたので、このメルマガの公式Lineとして採用させていただくことにしました。下のリンクから友達登録をすると、質問をすることが出来ます。</p>
<p><a href="https://lin.ee/TMY64Ih">https://lin.ee/TMY64Ih</a></p>
<p>◇　◇　◇</p>
<p>★ このメルマガの一部をブログなどに引用の形で利用することは、出典を明確にしていただく限り、個別に許可を取らなくても結構です。ただし、「メルマガ限定」と書いてある部分は例外（引用不可）とさせていただきます。</p>
<p>★『週刊 Life is beautiful』のバックナンバーはこちらから購入できます。</p>
<p>https://www.mag2.com/archives/0001323030/</p>
<p>これまでの号はこちらで確認してください。</p>
<p>================================================</p>
<p>・有料メルマガの購読、課金に関するお問い合わせは、 reader_yuryo@mag2.com までお願いします。</p>
<p>・私へのご質問やご要望などのお問い合わせは、そのままご返信いただくか、 mag2.nakajima@gmail.com までお願いします。 すべての質問に答えられるとは限りませんが、読者の方から送られて来たメールにはすべて目を通していますし、可能なかぎり回答したいと考えています。</p>
<p>・質問の内容や回数に特に制限はもうけていませんので、気軽にお願いします。ちなみに、回答は原則としてメルマガ紙面上で行いますので、公開されては困るような質問の場合は、そこを明確にしていただけると助かります。</p>
<p>・メルマガ内に掲載されている画像は記事リンク先からの引用です。記事のリンクがないものはクリエイティブ・コモンズ・ライセンスにより許可されたもの、もしくは著者所有の画像です。</p>

<hr>
<table id="mag2-pay-magazine-footer" border="0" cellspacing="0" cellpadding="0" width="100%">
<tr>
<td style="padding: 10px">
◎週刊 Life is beautiful<br>
購読アドレスの変更等の手続きはまぐまぐ！マイページから<br>
⇒ <a href="https://mypage.mag2.com/" target="_blank">https://mypage.mag2.com/</a></td>
</tr>
</table>


