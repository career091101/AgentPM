---
title: "- URL: https://www.youtube.com/watch?v=m_dNwtoxqd8"
video_id: "m_dNwtoxqd8"
video_url: "https://www.youtube.com/watch?v=m_dNwtoxqd8"
speaker: ""
channel: ""
date: ""
duration: ""
tags: ["PMF", "AI", "machine_learning", "product_development"]
topics: ["プロダクト開発", "AI技術"]
summary: |
  - URL: https://www.youtube.com/watch?v=m_dNwtoxqd8
  - Retrieved at: 2025-12-30T16:09:54+09:00
  - [00:00] I'm thrilled to introduce semantic
key_points:
  - "- URL: https://www.youtube.com/watch?v=m_dNwtoxqd8"
  - "- Retrieved at: 2025-12-30T16:09:54+09:00"
  - "- [00:00] I'm thrilled to introduce semantic"
  - "- [00:03] partnership with Reddis and taught by"
  - "- [00:05] Tyler Hutchinson and IA Zasha. In this"
category: "AI技術"
confidence_level: "high"
---


# Transcript: m_dNwtoxqd8

- URL: https://www.youtube.com/watch?v=m_dNwtoxqd8
- Retrieved at: 2025-12-30T16:09:54+09:00

## Text

- [00:00] I'm thrilled to introduce semantic
- [00:01] caching for AI agents built in
- [00:03] partnership with Reddis and taught by
- [00:05] Tyler Hutchinson and IA Zasha. In this
- [00:09] course, you learn how to make your AI
- [00:10] agents faster and more cost effective by
- [00:13] adding a semantic cache. Traditional
- [00:15] input output caching reuses old results
- [00:17] only when the user asks exactly the same
- [00:20] question. Semantic caching on the other
- [00:22] hand looks at meaning. So if someone
- [00:24] asks, "How do I get a refund?" and
- [00:26] another person asked, "I want my money
- [00:28] back." We can reuse the model's response
- [00:30] to the first question. This can make
- [00:33] your app faster and also save on token
- [00:35] cost. But there are many details to
- [00:37] building a fast and accurate semantic
- [00:40] cache for your AI app. And in this
- [00:42] course, you learn about them. Thanks,
- [00:43] Andrew. You'll start by building a
- [00:46] semantic cache from scratch to
- [00:48] understand how it works under the hood.
- [00:50] Then you'll reimplement your cache using
- [00:52] Reddus's open- source SDK with features
- [00:54] that are needed for a production system.
- [00:57] For example, you will set time to live
- [00:59] policies to keep the cache fresh. You'll
- [01:01] also use our open weight embedding model
- [01:03] fine-tuned for cache accuracy.
- [01:06] Once you have a working cache, we'll
- [01:08] measure its performance using hit rate,
- [01:10] precision, and recall. You'll see how
- [01:11] changing the similarity thresholds fits
- [01:14] all metrics. We'll also measure latency
- [01:16] and you'll see all this come together to
- [01:18] speed up a complex AI agent.
- [01:20] >> For many applications, semantic caching
- [01:22] will improve speed and cost efficiency.
- [01:24] I hope you enjoy the course.
- [01:31] [Music]
