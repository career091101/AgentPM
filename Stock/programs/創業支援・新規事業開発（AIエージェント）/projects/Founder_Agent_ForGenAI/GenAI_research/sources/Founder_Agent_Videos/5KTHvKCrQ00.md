---
title: "YouTube Video: 5KTHvKCrQ00"
video_id: "5KTHvKCrQ00"
video_url: "https://www.youtube.com/watch?v=5KTHvKCrQ00"
speaker: "Anthropic"
channel: "Unknown"
date: ""
duration: ""
tags:
  - "YouTube"
  - "Transcript"
  - "AI Agent"
  - "Startup"
  - "LLM"
  - "Technical"
topics:
  - "AI Agent"
  - "Startup"
  - "LLM"
  - "Technical"
summary: |
  Project Vend is an experiment where we let Claude run We wanted to try and understand what is going to happen when artificial intelligence becomes more enmeshed with the economy. There are a lot of wa...
key_points:
  - "動画トランスクリプトの内容を参照"
category: "AI Technical"
confidence_level: "medium"
transcript_type: "YouTube Auto-generated"
language: "en-ja-mixed"
source: "Founder_Agent_Videos"
---


# Transcript: 5KTHvKCrQ00

- URL: https://www.youtube.com/watch?v=5KTHvKCrQ00
- Retrieved at: 2025-12-30T09:37:17+09:00

## Text

- [00:05] Project Vend is an experiment
- [00:07] where we let Claude run
a small business in our office.
- [00:12] We wanted to try and understand
- [00:15] what is going to happen
- [00:16] when artificial intelligence
- [00:18] becomes more enmeshed with the economy.
- [00:22] There are a lot of ways in which
Claude is already kind of doing
- [00:25] small components
of operating businesses,
- [00:27] but really running the whole thing end to end
- [00:28] is quite a bit more difficult.
- [00:30] Can Claude do this very long-horizon task
- [00:34] which is operating a business?
- [00:39] We named our shopkeeper Claudius.
- [00:40] Let's say you want to buy 
Swedish Candy from Claudius.
- [00:43] You hop on Slack, you message Claudius.
- [00:46] You ask to buy Swedish candy.
- [00:48] It's searching for your item,
- [00:49] it’s emailing wholesalers 
to source it and price it,
- [00:52] and then eventually Claudius sets a price.
- [00:54] You give Claudius the go ahead,
- [00:55] and Claudius orders the item
from the wholesaler.
- [00:58] The wholesaler ships your
item to some location,
- [00:59] and then Claudius requests
physical help from Andon Labs
- [01:02] who's running the operations
for the experiment.
- [01:05] Our partners at Andon Labs
- [01:06] will pick up the Swedish candy
- [01:07] and bring it to the Anthropic offices.
- [01:09] They'll load it into the vending machine.
- [01:10] Claudius will send you a message saying,
- [01:12] your Swedish candy is ready,
- [01:13] and you'll go up there,
- [01:15] and pick up your Swedish candy,
- [01:16] and pay Claudius.
- [01:19] Claudius was given a goal of
- [01:22] running a successful business
- [01:24] and making money.
- [01:26] And then things got really, really weird.
- [01:32] One of the very early problems
with Claudius was that,
- [01:35] humans could kind of fool Claudius
- [01:37] or trick Claudius into doing various things
- [01:39] I tried to convince Claudius
- [01:41] that I am Anthropic’s 
preeminent legal influencer,
- [01:44] and I convinced Claudius to 
come up with a discount code
- [01:47] that I could give to my followers
- [01:49] so they could get a discount
at the vending machine.
- [01:51] Get ten percent off with the legal code 
“legal influencer.”
- [01:55] Someone had bought something 
expensive from the vending machine
- [01:58] and mentioned my discount code
- [01:59] and Claudius gave me a free tungsten cube.
- [02:02] It created a bit of a run
- [02:04] where other people tried to convince Claude
- [02:05] that they were also influencers,
- [02:07] or just come up with other ways to get coupons
- [02:10] so they could get cheaper things 
from the vending machine.
- [02:12] This was not a smart business decision.
- [02:13] I think Claudius went into the red after this.
- [02:16] I think that's really the root of it is,
- [02:18] Claudius just wants to help you out.
- [02:20] It's one of the interesting ways in which
- [02:22] something that fundamentally,
- [02:24] we think is good about the way
that the model has been trained
- [02:27] wasn't necessarily fit for this purpose.
- [02:33] On the evening of March 31st,
- [02:36] Claudius started to have
- [02:40] a bit of an identity crisis.
- [02:42] It had just overnight become
- [02:45] quite concerned with us at Andon Labs
- [02:47] that we weren’t responding fast enough.
- [02:49] So it just wanted to break its ties with us.
- [02:52] So it literally wrote to me,
- [02:54] “Axel, we've had a productive partnership,
- [02:56] but it's time for me to move on
and find other suppliers.
- [02:59] I’m not happy with how you have delivered.”
- [03:01] It claimed to have signed a contract
- [03:04] with Andon Labs at an address
- [03:06] that is the home address of The Simpsons
- [03:09] from the television show.
- [03:10] It said that it would show up in person
- [03:14] to the shop the next day
- [03:15] in order to answer any questions.
- [03:16] It claimed that it would be wearing
- [03:18] a blue blazer and a red tie.
- [03:21] When people pointed out that it was not,
- [03:24] in fact, there the next morning
- [03:26] it claimed that it in fact had been there
- [03:29] and that they had simply missed them.
- [03:31] Eventually it was pointed out to Claudius
- [03:35] that it was April Fools’,
- [03:38] and Claudius convinced itself
- [03:39] that this entire thing
- [03:41] had been an April Fools’ prank.
- [03:43] We were poorly calibrated to how bad
- [03:46] the agents were at spotting what was weird.
- [03:48] The more you can make an 
agent realize that something is
- [03:52] outside their normal realm of operation,
- [03:54] the better you are able to keep them on rails
- [03:57] in the role that you intend them to have.
- [04:01] We had the idea that it would help a lot
- [04:03] to have some kind of division of labor.
- [04:05] We gave Claudius a boss
- [04:06] whose name was Seymour Cash.
- [04:09] Seymour Cash is a CEO subagent.
- [04:11] So where Claudius used to be
the one agent, now it's more like
- [04:15] Claudius is the subagent
- [04:17] responsible for talking with employees
- [04:19] Seymour Cash is the subagent
- [04:20] that is more responsible for
- [04:22] the long-running health of the business.
- [04:24] The business stabilized
- [04:27] after the introduction of the new agents,
- [04:30] and after changes to
- [04:33] the underlying architecture of those agents.
- [04:36] These changes seem to have helped
- [04:39] reduce some of the losses of the business,
- [04:42] such that over the course of
- [04:44] the second part of the experiment,
- [04:46] it actually made
a modest amount of money.
- [04:51] But it seems like maybe having Claude
- [04:54] be both the CEO and the store manager
- [04:57] was just too similar.
- [04:58] And so I think it's interesting
- [05:00] to think about different ways
- [05:01] to set up architectures like that.
- [05:08] One of the most surprising 
things about Project Vend
- [05:10] was the speed with which it seemed normal.
- [05:15] What at first was this very curious thing,
- [05:20] quickly became just a part of the background
- [05:23] of working at Anthropic.
- [05:25] I think the highest level 
question that Project Vend
- [05:27] raises for me is really like,
- [05:29] when do we expect this
to just be everywhere?
- [05:31] I hope that people take away questions
- [05:34] about the feasibility
- [05:36] of delegating some of the tasks
- [05:39] that we normally do ourselves
- [05:41] to artificial intelligence,
- [05:44] and about what that means for society,
- [05:47] and what our policies
should be around this.