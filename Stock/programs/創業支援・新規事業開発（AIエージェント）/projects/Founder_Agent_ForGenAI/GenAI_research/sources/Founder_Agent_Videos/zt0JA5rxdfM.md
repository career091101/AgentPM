---
title: "- URL: https://www.youtube.com/watch?v=zt0JA5rxdfM"
video_id: "zt0JA5rxdfM"
video_url: "https://www.youtube.com/watch?v=zt0JA5rxdfM"
speaker: ""
channel: ""
date: ""
duration: ""
tags: ["hiring", "machine_learning", "marketing", "PMF", "AI", "team_building", "product_development", "growth"]
topics: ["成長戦略", "プロダクト開発", "組織構築", "AI技術"]
summary: |
  - URL: https://www.youtube.com/watch?v=zt0JA5rxdfM
  - Retrieved at: 2025-12-30T16:48:11+09:00
  - [00:00] What will be the most important trends in AI in
key_points:
  - "- [00:00] What will be the most important trends in AI in"
  - "So if you see an obstacle, you should turn left,"
category: "AI技術"
confidence_level: "high"
---


# Transcript: zt0JA5rxdfM

- URL: https://www.youtube.com/watch?v=zt0JA5rxdfM
- Retrieved at: 2025-12-30T16:48:11+09:00

## Text

- [00:00] What will be the most important trends in AI in 
2026? Well, we take a stab at this every year
- [00:06] with with some success, I would say. And this 
time out, I have the knowledgeable assistance
- [00:11] of my colleague, Aaron Baughman, to help us out. 
Well, yeah. You know, after your prediction
- [00:16] of infinite memory last year, I thought maybe 
you could use just a little bit of help. Yeah,
- [00:20] that's that's fair. Well, how about we each take 
four trends each? That sounds good. How about you
- [00:26] first? All right. Okay. So my number one trend 
of 2026 is multi-agent orchestration. Now last
- [00:36] year we said 2025 was the year of the agent. 
AI agents that can reason and plan and take
- [00:42] action on a task and agents I think it's fair 
to say really delivered. There are new numerous
- [00:47] agentic platforms for tasks like coding and basic 
computer use but no single agent really excels at
- [00:55] everything. So, what if you had a whole team of 
agents working together? So, maybe we've got an
- [01:01] agent here that kind of acts as a planner agent 
that decomposes goals into steps. Maybe we have
- [01:08] some worker agents here that do different 
steps like one specializes in writing code,
- [01:15] others call APIs and so forth. And then perhaps 
we have a critic agent that evaluates outputs and
- [01:22] flags issues. And these agents collaborate under 
a coordinating layer that is the orchestrator.
- [01:33] And multi-agent setups like this help introduce 
cross-checking where one agent checks the other
- [01:38] agents work and it can break problems into more 
discrete verifiable steps. Well, great. So,
- [01:45] how could I really follow that trend? 
Well, I think I might just have one. So,
- [01:49] the second one is going to be the digital labor 
workforce. So now these are digital workers that
- [01:56] are autonomous agents that can do a couple 
of items. So the first one is they can parse
- [02:01] a task by interpreting multimodal input. So after 
preparation the worker then executes what's called
- [02:08] a workflow. Now this is where at the end of an 
action plan you know it would follow a sequence of
- [02:15] steps but then it has to be integrated into some 
sort of system that then in turn can take action.
- [02:22] And these could be downstream components. Now 
these systems are then further enhanced by what we
- [02:27] call human-in-the-loop AI, which then provides a 
couple of items. The first one would be oversight.
- [02:33] The next one would be correction and then we're 
looking at these strategic guidance or these rails
- [02:38] um to ensure that all of these agents are doing 
what they're supposed to be doing. Now this
- [02:43] overall trend will create a force multiplying 
effect to extend human capability. Now trend
- [02:49] number three is physical AI. Now we all know that 
large language models they generate text like ABC.
- [03:00] And then there are other models as well. So for 
example there are plenty of diffusion image models
- [03:06] and they generate pixels. They generate images. 
These are all operating in digital space. Now,
- [03:14] physical AI is about models that understand and 
interact with the world that we live in, the the
- [03:21] real 3D world. And this is about models that can 
perceive their environment, reason about physics,
- [03:29] and that can take physical action like robotics. 
So, previously getting a robot like this to do
- [03:37] something useful meant programming explicit rules. 
So if you see an obstacle, you should turn left,
- [03:44] for example. And it was all done by humans. It 
was up to yeah, smart guys like this to code these
- [03:53] rules. Now, physical AI kind of flips that around. 
So you train models in simulation that simulate
- [04:03] the real world and it learns to understand 
how objects behave in the physical world,
- [04:08] how gravity works, how to grasp something without 
crushing it. Now these models are sometimes called
- [04:16] world foundation models. They're generative models 
that can create and understand 3D environments.
- [04:23] They can predict what happens next in a physical 
scene. And in 2026, many of these world models are
- [04:30] taking things like those humanoid robots that you 
found there, Aaron, and they're taking them from
- [04:36] research to commercial production. Physical AI 
is scaling. Well, Martin, you just took my trend,
- [04:43] but let's just go ahead and say number four is 
about social computing. Now, this is a world
- [04:49] where many agents and humans operate within the 
shared AI fabric. So say if I have an agent here
- [04:55] and then a human here. So they're going to be 
connected through this fabric and here if I
- [05:02] have information that flows between the two, they 
begin to understand each other and then they can
- [05:08] gather what the intent is going to be. And then 
once they have the intent and information, they
- [05:13] have actions. They can affect each other or maybe 
even the environment of which they're in. But all
- [05:19] of this flows seamlessly across this system. It's 
this shared space that enables collaboration,
- [05:25] context exchange as well as event effective 
understanding. Now the outcome is really an
- [05:30] empathetic emergent network of these interactions. 
It's what we call this collective intelligence
- [05:35] or this real world swarm computing. So teams of 
agents, digital labor, humanoid robots, and tech
- [05:43] that can understand me with effective computing. 
2026 could be uh quite the year and we're only
- [05:50] halfway through the trends. So trend number five 
that is verifiable AI. Now the EU AI act is coming
- [06:03] and by mid 2026 it becomes fully applicable. 
And think of this a little bit like GDPR but for
- [06:10] artificial intelligence. Now, the core idea here 
is that AI systems, especially high-risk ones,
- [06:17] need to be auditable and they also need to 
be traceable. Now, what does that mean? Well,
- [06:22] it means a few things. It means documentation. 
So, if you're building high-risk AI, you need
- [06:29] technical docs that demonstrate compliance to 
how you tested the models and the risks that you
- [06:34] identified. It means transparency. So, users need 
to know when they're interacting with the machine.
- [06:41] So things like synthetic text, they need to be 
clearly labeled and it means data lineage. You
- [06:48] need to be able to summarize where your training 
data came from and prove you respected copyright
- [06:53] optouts. And just like how GDPR has shaped global 
privacy, not just folks in the EU, the EU AI act
- [07:01] will probably set the template for AI governance 
worldwide. Wow, that's great. And you know, trend
- [07:07] number six, right? It really changes everything, 
but it also changes nothing at the same time.
- [07:13] And now this is where we put in quantum utility 
everywhere. So 2026 is where we start to see this
- [07:20] quantum computing to reliably start solving 
real world problems better, faster, or more
- [07:26] efficiently than classical computing methods. Now, 
at this point, we have this quantum utility scale.
- [07:32] is these systems that begin working alongside and 
together with classical infrastructure to deliver
- [07:37] these practical value in everyday workflows. Now, 
this is going to help with optimization and then
- [07:44] we'll also look at simulation and decision-making. 
Now, all three of these tasks were previously
- [07:50] out of reach within the classical realm. But this 
hybrid quantum classical error, it will begin to
- [07:56] transform quantum computing into this mainstream 
paradigm as it's going to be woven into our
- [08:01] everyday business operations. Now my trend number 
seven is reasoning at the edge. Now last year, we
- [08:10] talked about very small models, models with just 
a few billion parameters that don't need huge
- [08:14] data centers to run. They work on your laptop 
or well maybe even your phone. Well, in 2026,
- [08:21] those small models are learning to think. So, if 
we think about the best models that we have today,
- [08:27] the frontier models, well, pretty much all of them 
now use something called inference time compute.
- [08:36] They spend extra time thinking before giving you 
an answer, working through problems step by step.
- [08:42] Now, the trade-off for that is they need more 
compute. But here's what's changing. Essentially,
- [08:49] teams have figured out how they can distill all 
of this reasoning information into smaller models.
- [08:59] So now these smaller models can perform thinking 
as well. You're taking massive reasoning models
- [09:05] that generate tons of step-by-step solutions and 
we're using that data to train the smaller models
- [09:12] to reason the same way. And that's resulting 
in reasoning models with only a few billion
- [09:17] parameters. They work offline. Your data never 
leaves your device. And there's no roundtrip
- [09:22] latency to a data center. So for anything that's 
real time or mission critical, having a model that
- [09:28] can actually reason through a problem locally is 
a pretty big deal. Yeah. So that's all very true,
- [09:35] Martin. But now our last and final trend is number 
eight. So this is what we're calling amorphous
- [09:42] hybrid computing. So this is a future where both 
AI model topologies and the cloud infrastructure,
- [09:48] they blend into what's called a fluid computing 
backbone. So AI models, they're shifting beyond
- [09:53] just this pure transformer design, right? They're 
beginning to evolve into these other architectures
- [09:59] that integrate transformers and we call them 
these state space models. And then in 2026,
- [10:06] you're also going to see different emerging 
algorithms that are combine both the state space
- [10:11] and transformers and other elements together, 
right? And that's going to be really fun to watch,
- [10:17] very artful. And then at the same time, we have 
this cloud computing piece that's becoming fully
- [10:23] differentiated by combining many different 
chip types. So we're going to have CPUs,
- [10:29] GPUs, TPUs as well. And finally, what we just 
talked about in trend six, quantum, we're going
- [10:37] to have QPUs. I did also want to mention and 
note that you'll see these neuromorphic chips
- [10:42] that are coming out and those emulate the brain. 
But all of these are going to be put together
- [10:48] right into this unified compute environment 
where parts of each of these types of models,
- [10:53] they're going to be automatically mapped to 
the optimal compute substrate. And this is
- [10:57] really going to help to deliver this maximum 
performance and efficiency. And you know what?
- [11:02] Who knows? But at this pace, probably 
not in 2026, but I think further out,
- [11:07] you might see DNA computing entering into the 
mix. Well, those are some lofty goals. And look,
- [11:13] these are what we think are some of the biggest 
AI trends in 2026. But what are we missing?
- [11:21] Which AI trend do you expect to be a big deal in 
2026? Yeah, let us know in the comments below.
