---
title: "結局 AIて過去のデータから見つけ出してきて未来を予測してるだけでしょみたいなことを言ってていやそうじゃなくなったんだけどみたいな思って一般の人っていうか多くの人それに気づいてないんだなと AI 研究..."
video_id: "aPXJLb6-uxM"
video_url: "https://www.youtube.com/watch?v=aPXJLb6-uxM"
speaker: "Unknown"
channel: "Unknown"
date: ""
duration: ""
tags:
  - "AI"
  - "LLM"
topics:
  - "LLM Development"
summary: |
  AIて過去のデータから見つけ出してきて未来を予測してるだけでしょみたいなことを言ってていやそうじゃなくなったんだけどみたいな思って一般の人っていうか多くの人それに気づいてないんだなと
  研究コミュニティはデスト自用デスタイムアダプテーションという新しいパラダイムに入ったということでこれオープン
  のロードマップですけど僕エージェントとイノベーターの違いってよくわかんなかったんだけど多分こういうことなのかなと
key_points:
  - "See transcript for details"
category: "AI & Technology"
confidence_level: "high"
---

# Transcript: aPXJLb6-uxM

- URL: https://www.youtube.com/watch?v=aPXJLb6-uxM
- Retrieved at: 2025-12-30T11:32:39+09:00

## Text

- [00:00] 結局
- [00:00] AIて過去のデータから見つけ出してきて未来を予測してるだけでしょみたいなことを言ってていやそうじゃなくなったんだけどみたいな思って一般の人っていうか多くの人それに気づいてないんだなと
- [00:12] AI
- [00:13] 研究コミュニティはデスト自用デスタイムアダプテーションという新しいパラダイムに入ったということでこれオープン
- [00:19] A
- [00:19] のロードマップですけど僕エージェントとイノベーターの違いってよくわかんなかったんだけど多分こういうことなのかなと
- [00:26] そうなんな感じしますねというの
- [00:29] から言ってるんですけども、再利用できる小傷を発掘して即興で組み替え続ける力を知能という風に彼は提しています。
- [00:39] このタスクの情報のデータを言いてきて解決するようなホログラムなのか
- [00:40] [音楽]
- [00:45] AIなのかをノーバで作るタイプ
- [00:48] 1
- [00:48] の直感でどれを使うかみたいなを持ってきてやるわけです。あ
- [00:54] あ、なるほどね。
- [00:55] これが効率よ、解決できるようになればエージェント時代からイノベーターの時代へ行する。うん。
- [01:00] [音楽]
- [01:05] こんにちは。
- [01:06] こんにちは。なんかね、あのエドさんからうえっとなかなか暑いスライドですねとお褒めいいただいたんですけど
- [01:12] はい。はい。はい。
- [01:13] あのもうこれAI様さですよね。なんか
- [01:17] あのリサーチアシスタントが
- [01:18] Tイter見たもんですよね。
- [01:20] だ、ちょ、ちょっとでも自分があの、どうなってるんだろうと思ったことはガンガンリサーチできちゃうので
- [01:26] うん。うん。うん。うん。
- [01:27] 自分1
- [01:28] 人でやってたらこれどれぐらい情報取っとくのどれぐらい時間かかるだろうと思うようなことが
- [01:32] うん。
- [01:32] 本当にね、あの、何十秒かでリサーチしてくれるので、だから
- [01:37] いくらでもネタありますみたいな感じですよね。いくらでも僕の、僕の好奇心の続く限りネタ作れますという
- [01:44] 感じなんで、あ、これがやっぱり
- [01:46] AIなんだなていう
- [01:48] うん。気はしますね。で、最近その
- [01:52] AI
- [01:52] で仕事がどうなのかってのちょうど今なんか調べてて次回そういう話もしてみたいんですけど楽しみですね。うん。
- [01:58] はい。そこであのやっぱりなんだろうな自分の強みがどこにあるのかはっきりわか分かってくるみたいな。
- [02:06] うん。
- [02:06] ディープリーサーチが出てできた出た時にはね、あ、俺自分の仕事なくなるわと思いましたですけど、ディープリサーチのそのリサーチしてくる力は本当すごいんですよ。
- [02:15] リサーチしてくる強いんですけど、すごいんですけど、そうとめるところとか
- [02:19] うん。うん。
- [02:20] あの、ま、当たり触りのないまとめ方してくるので
- [02:23] うん。
- [02:24] その僕の思いとかなんかそういうの
- [02:28] うん。
- [02:29] の文章の文章やあのスライドの方が僕自身は面白いなと思ってあの本当にねリサージやってもらうと当たり触りなくてラックはないですけどあのなんかなんかその
- [02:42] 感情を揺さぶらないようなものになってくるのでね。
- [02:45] うん。
- [02:45] あ、だからあ、自分のあの強みっていうのはそこに残るんだなっていうことなんで必も
- [02:51] AIで僕の仕事がなくなるというよりも
- [02:53] AI
- [02:53] のおかげで僕の仕事がなんかより強くなるみたいな。
- [02:58] ああ。はいはいはい。
- [02:59] そんなそんなの本当今実感してるとこなんでだからスライドすごいですねと言われるといやうん。うん。
- [03:06] やっぱりなんか自分の力が倍増されたみたいなそんな気はしますよね。
- [03:12] はい。
- [03:12] はい。ま、そういう話次回してみたいんですけど、今日はアークワツ
- [03:17] 3
- [03:17] の話ですかね。え、リーズモデルのベンチマークの話で、これを見ると何か、えっと、今
- [03:25] AI
- [03:25] ってどっちの方向住んでんのかなてのがわかるのでうん。
- [03:28] うん。てましたということなんで、ちょっとまた共有させていただきます。
- [03:32] はい。見えてますでしょうか?
- [03:34] はい。タイトル煽ってますね。
- [03:36] [笑い]
- [03:37] これね、エ藤さんと一緒にいたあるイベントでね。
- [03:41] はい。
- [03:41] あの、イベントでこんなこと言ってる人が何人かいらっしゃったんで、結局いて過去のデータから見つけ出してきて未来を予測してるだけでしょみたいなことを言ってて、いや、そうじゃなくなったんだけどみたいに思って、あ、多くの人って、ま、
- [03:56] おそらくこれ1
- [03:57] 年前だったらそうだったと思うんですけど、あの、リーズモテル出てきたことでね、なんかこういう状況ではなくなってきたんだけども、一般の人っていうか、多くの人それに気づいてないんだなと思ったんですよね。
- [04:09] ああ、確かに。うん。
- [04:10] ちょっとやっぱり今どこまで行ってんのかっていうのを理解してもらった上で議論しないと
- [04:17] 他の人がその1年前のAI
- [04:19] の状態で議論されていやえねそんなことできないですよとか言われてもいいやいやもうできるんですけどみたいなことになってきて議論が噛み合わないのでやっぱり今やがどこまで住んでんのかっていうのを知った上で社会がどう変わるのか仕事がどう変わるのかっていうの議論した方がいいのかなと思うんでこれやっぱり抑えておく必要があるのかなと思ってたらちょうどあのフランスワョレさんのインタビューが出てたんで
- [04:40] これをベースに今のどこまで来てるのかというのをもう
- [04:43] 1
- [04:43] 度再確認したいなと思ったということなんですね。
- [04:46] うん。はい。
- [04:47] で、これに気づいてる人がいるの?どれがいるのか最近の
- [04:51] Aの進化のフェーズですけども目を持った
- [04:53] AIっていうのは、ま、Dランニングで
- [04:55] 2012年で言語を持ったAI
- [04:57] というのがトランスフォーマーチャット
- [04:58] ATGPTで、え、論風が2017
- [05:00] 年だけども、え、チャット
- [05:02] GPTデータの方が2023年ですよね。
- [05:05] うん。
- [05:05] あの、多くの人がここの状況の
- [05:08] AI
- [05:08] のことを話しておられるのかなと思うんですけど、今は去年の
- [05:12] 9月にオープンAIのオ1
- [05:13] が出て理的思考リーズモデル時代に入ったんで、ちょっとやっぱり違うの
- [05:18] AI
- [05:18] のフェーズに入ったのかなと思いますね。でも
- [05:20] うん。ちょっと終わって入ってあれですけれども、これ目をもったい合い、言語をもったい、思考もったい、これ全部イリアさんですからね。
- [05:27] イリアさんがやったんだ。ああ、そうか。そう。
- [05:30] 2012
- [05:30] 年のディープランニングのやつで多分アレックスネットのことを言ってると思うんですけどあれさん中段に入ってますし
- [05:38] はいはいはい
- [05:38] この言語もったいチャット
- [05:40] GPT
- [05:41] はイリアさんのスケーリング速で作ったやつですし
- [05:44] 思考もったい合いはイリアさんがあのベースを考えたリーズですからね。
- [05:49] そうですね。これでびっくりしてさき場がさるとマを首にしようとしたって話ですもんね。
- [05:54] ね。はい。今みちゃん全部リアさんちゃんと。
- [05:57] そうですよね。やっぱりすごいすごい研究者なんですよね。
- [06:00] うん。
- [06:00] はい。で、えっと、あんまりね、今生成の時代だと言われていて、だから生
- [06:05] AIっていうのは、まあ2
- [06:06] 番目の言語を持ったAI
- [06:07] というところのフェーズなんで、多くの人がまだやっぱり
- [06:10] 2番目だと思ってるんですけど、実は
- [06:12] 3
- [06:12] 番目があったんですよっていうのがあまり認識されてないということで、ちょっと遠藤さんにすればちょっと簡単すぎて、
- [06:19] そんなんじゃないと僕ね、昔ほら、遠藤さんとあの
- [06:22] AI
- [06:23] の勉強会やってた時に僕はいやこんな風になってんですよって言った後、僕が最初に話してその後エさんがう
- [06:29] するというパターンでいや、ゆ川さんはあいましたけど、そんな簡単なもんじゃないですって。毎回僕の言うことをね、否定されるのがね、なんか面白いなと思います。面白いなというか。はい。ということで、ま、否定されるかもしれないですけど、目を持ったってどういうことかというと、このね、この耳の分を拡大するとこんな風になって、で、白と黒で表すと、え、で、白を
- [06:48] 0で、0にするとこれが0010010
- [06:51] というこの0と1
- [06:52] の数字になりますということで、写真を
- [06:55] 0と1の数字にした上でですね。
- [06:58] それでのデータ、
- [06:59] ここはなんか言った方がいいんですかね?さすがに
- [07:02] そんな方なもんじゃないでしょうね。はい。
- [07:04] ま、も、もうちょっと、もうちょっとね。
- [07:06] はい。
- [07:07] ですけれど、
- [07:07] ごめ、ごめんなさい。はい。そこはもうもうちょっとということにしておいて、えっと、後でめちゃめちゃ詳しい話してもらわないといけないとこあるんで、そこに、そこに置いておいて、ここはちょっと流していただければと思うんですけど。はい。
- [07:17] 1つのデータセットがこの数字で、もう1
- [07:19] つが猫だったら1、猫じゃなかったら0と
- [07:22] いうことで、で、え、猫の数字の並び方の
- [07:25] 特徴を我々は見てもわかんないけど、AI
- [07:28] が判断してパターンを見つけ出すという
- [07:30] ことで、写真何が映ってるのかというのを
- [07:32] AIが分かるようになりましたということ
- [07:34] ですよね。で、言語を持ったAIというの
- [07:36] は、ま、我々受験勉強のとこにしました
- [07:38] この穴開け問題ですね。
- [07:40] 文章ってこの穴開いた子に何が入りますでしょうかということでいっぱい文章を読んでたらあけの次におめでとうございます。ま、入るだろうなということ予測できますということ。で、毎度の場合は毎度大きにもあるし毎度ありがとうございます。
- [07:54] 毎度ありもあるしあるんでそれはその前後の文章を見て推測するしかないということで、ま、インターネット上の文章を片端しから穴埋めに変えて自分に問題を出して自分で答えて答え合わせすることで学習していったというのが生成言語を持った
- [08:09] AIの仕組みなんですね。で、え、思考
- [08:12] AIの仕組みというのは、えっと、AIと
- [08:14] いうのは学習するのと、これ受験勉強する
- [08:17] ようなもんで、それからテストを受けるの
- [08:19] と、テスト受けるの方を水論って言うん
- [08:21] ですけどね、以前は受験勉強法にこれ反動
- [08:24] 体なんですけど、計算資源いっぱい使い
- [08:26] ましたと。ね、テスト受けてる時は1
- [08:28] 個ぐらいしか使えませんと言うんだけども、今は、ま、受験便の時もいっぱい使うんですけど、テスト受ける時もいっぱい反対すかって考えますということで、考えること考える絵なったんですけど、どうやって考えるんですかと言うと、ま、こういう風にこれは
- [08:41] 3探索というやつですか?
- [08:43] そうですね。多分1個1個がCOT
- [08:46] の分岐みたいなやつじゃないかなと思うんですけど
- [08:49] ね。これがAだったらB、BだったらC
- [08:51] とかいう風にこうやって段階に分けていって、それぞれの段階で可能性のある回答思考錯。
- [08:56] を通じて選択して最終的な答えにたどり着くというにこんな風になってるんじゃないのかなという風に大ワが出た時に遠藤さんと議論したんですよね。
- [09:06] そうですね。
- [09:07] なんかこんな風になってるんじゃないかというなんか推測
- [09:09] までも実際こんな風になってるみたいな話その出ませんでしたっけ?
- [09:13] そう出たんですよね。だからあ、まあ遠藤さんの言ってこと間違いなくていいやみんなまあまこうだと思ってんですけど実は今日この後にもっと詳しい何が行われてるかっていうのが出てきます。
- [09:23] それちょっとエ藤さん見てもらって、あ、実はま、これ考え方これに近いんですけどね、もっとなんか同的というか、それをちょっと後で見てもらいたいなと思うんですけど、
- [09:31] ていうとこなんですけど、そこでこのフランスは小霊さんちょっと見てみると、フランス人ですね。
- [09:45] うん。
- [09:45] で、この人のどんなこと言ってんのかというと、計算能力の進歩とスケリングへの過信ということ言ってるんですけど、
- [09:52] 1940年以来コストは10年ごとに2
- [09:55] 桁ずつ低下していたと。要なボトルネクだった計算能力とデータが豊富になったことで、
- [10:01] 2010年代にはGPU
- [10:02] ベースの計算能力と大量のデータを用いた進層
- [10:06] 学習が迫的に進歩という、ま、ディープライニングとこですよね。目を持った
- [10:10] Aのところが2010
- [10:11] 年代に大きく進化したということなですね。
- [10:14] で、その後自己教りテキストモデリング。これがさっき言ったあの穴埋めですね。自分で穴を開けて自分で答えていくという。それの成功によって大規模言語モデルの訓練をスケーブルアップすることが主流になったという。これが
- [10:28] 2
- [10:29] 番目までのフェーズだったんですけど、ただもっと規模を大きくすれば全てが解決し
- [10:34] AGI
- [10:34] 到達できるという考え方が広まったということでね。だからみんなスケーリング則全盛紀なんですけど最近スケーリングいやもう終わったんじゃないかと話も出てきてるんですけど。
- [10:43] うん。に言わとしていたということなんですけども
- [10:46] うん。
- [10:47] で、何が足らなかったかというと、古いと流動的な一般的なインテリジェンス流動的汎用知能の決通常ということですかね。
- [10:55] で、記憶されたスキル、性的ですこういう、ま、丸暗記してたようなもんなんで、それと初めて見るもんだけど即座に理解する能力とか全然違うもんなんだよと。
- [11:05] これが当たらなかったと思うでなんか丸暗記してポンと答えてたけれどもそれと知能とは違うんだよみたいなことでその違いを明確にするために
- [11:14] 2019
- [11:14] 年にベンジマーク作りました。アウトラクションコーパスというアーク
- [11:19] 1
- [11:19] というのを設計しましたということですね。
- [11:21] うん。うん。
- [11:22] で、これを使ってGPT4.5ま2019
- [11:25] 年頃のモデルよりも5
- [11:26] 番倍にスケールアップしてるんです。
- [11:28] 反動体の数もそれから学習データの数もそれからモデルの大きさも全部めちゃめちゃ確してるんですけどもそれでもアーク
- [11:37] 1での制度は10%程度と
- [11:39] で人間は95%
- [11:41] 以上答えられるのにということでこれは流的知能は事電学習のスケールアップからは生まれない。
- [11:46] え、今までのやり方で学習のところでどんだけ反動体を突き込んで勉強さしてもこの流動的な汎用性つまり初めて見るものを即大にする理解する能力というのは生まれないんだという風なこれ決定的な結論だという風に回は言ってます。
- [12:02] うん。はい。
- [12:02] で、そこで出てきたのがテスト自王というさっきなんかツリーコードになってるんじゃないかといろんな人が続していたことなんですけどそれを今はなんかテストタイムアダプステーションと呼ぶみたいですね。
- [12:15] TTAということで、これね、次のページ
- [12:18] でこんな形でワークロでやってますっての
- [12:20] 後で言うんですけども、それが2024年
- [12:22] に入り全てが変わった。これはま、
- [12:25] オープンA1のリズニングモデルの登場
- [12:27] ですよね。AI研究コミュニティはテスト
- [12:30] 自用デスタイムアダプテーションという
- [12:32] 新しいパラダイム入ったということで
- [12:34] やっぱりもうこれ多分O1の言いと思い
- [12:38] ます。言ってると思います。
- [12:39] これちょっと少し調べたんですけど、
- [12:42] 多分この24年にMIT
- [12:45] からヘストタイムトレーニングみたいな
- [12:47] はいはいはいはい。うん。
- [12:49] 論文が出て多分それのこと言ってんじゃないかな。なるほど。
- [12:53] そ、それはなんかテストっていうか水論時に普通に重みを変える学習をするみたいなカリファインチューニングをなんかセルフでやるみたいなやつでなんかそれがアークの一時的にそう太っていうかすごい高戦出してたみたいな感じなんで多分これはオープン
- [13:12] AI
- [13:12] 系の話じゃなくてそっちの話かなと思います。
- [13:17] で、逆にそのオープンってテスト時に再学習はしてないんで多分あのオープンエア系はどっちかって言うとさっきの釣みたいな感じでテストタイムコンピューティングって言ってすごいテスト時に大量に水論させるなんなな釣りみたいな感じでなんこうあった時になんか色々解放
- [13:32] [音楽]
- [13:38] ABBCdE
- [13:39] みたいな候補出してそっからちょっとずつ釣りみたいにいいやつ探してくみたいなで大量に計算するみたいなんでなんかこ
- [13:47] テストタイム適用をやってないんだ。オープン
- [13:49] A相て。
- [13:49] あ、そのTTA
- [13:51] テストタイム適用の中にその再学習させるやつと計算資源に継い込むっていうのがパターンがあるみたいで
- [13:58] はいはいはい。
- [13:58] で、TTAはTTAなんですけど、この
- [14:01] TTT
- [14:02] っていうテストタイムトレーニング系と
- [14:04] ETC
- [14:04] っていうテストタイムコンピューティング系で超分かれる。
- [14:07] なるほど。これはね、ここはあの
- [14:09] TTAの中にテストタイムトレーニングと
- [14:12] ああ、こうですね。TTTですね。うん。
- [14:14] シンボリックプログラム新シスとチェインオブソ
- [14:18] 3
- [14:18] つが組まれるコンセプトですよという風に言ってるんですよね。あ、はい。はい。ああ、じゃあちょ自分が見てたはまた違うかもしれないですけど、多分このテスタイトレーニングっていうのは本当にテストの時にセルフでファインチューニングするやつだと思います。で、多分シンドブソト寝出て何かな?
- [14:36] ちょっとじゃあそのどういうプロセスで、え、テスタイム
- [14:38] TTA
- [14:39] のワークフローとこんならしいんです。
- [14:40] これはOPAIO3
- [14:42] に聞いたんですけども、まず新井仮説を考えるというんですね。これがチェインオブソートシンセスというやつで、え、どういう順番でやるかっていうのを言語モデルが考えるんですよね。
- [14:52] それでDSL
- [14:53] 編を提示、これはよくわかんないですけど、なんかこういうのやっていきましょうという大体のことを決めるのが
- [14:59] LMM
- [15:00] でチェインオブトンセスということでやるんですけども。で、次はプログラム候法具体化検証というのがシンボリックプログラムシンセシスということでチェインオブソ思う。
- [15:02] [音楽]
- [15:10] の連鎖がLMが考えてきたのを元に
- [15:13] DSL
- [15:14] を優先して、え、わかんないですね。この辺納得か探索をしますということでね。束縛ってこれはあれですか?モンテカルリー検索のこというんですかね?
- [15:23] な、なんですか?これはちょっと違うんじゃないか。なんか条件を絞って探索するの。
- [15:28] あ、なるほど。そういうやつじゃないですかね。うん。
- [15:30] はい。で、各方法を霊入力に実行して
- [15:33] マッチ度をスコアリングしてミスマッチ業
- [15:36] があれば判例としてCOTSに戻し、次は
- [15:39] 左右反転を試そうとか指示を更新する
- [15:42] らしいんです。それからモデル自体も微
- [15:44] 調整もするということ。テストタイム
- [15:46] トレーニング、え、例データと、え、現
- [15:48] 時点での最流のプログラム出力を基地
- [15:51] ラベルにしてLMMの内部表現を5から
- [15:54] 10ステップだけチューニングするという
- [15:56] 。これで次のCOT
- [15:58] 生成が廊下に最適化されて探索効率が上がると
- [16:01] うん。
- [16:02] で、最終プログラムでテスト入力を変換するということで制限時間やステップ数式を超える前にマッチ
- [16:10] 100%
- [16:10] のプログラムが見つかればクリア。見つからない場合でも
- [16:14] TTTで強化されたLMA
- [16:16] が直接力推測を試みるオフもあると僕には何のことかわかんないですけど大体こんな流れだそうです。ピンときました。
- [16:24] 多分ですけど、一般的な手法というよりはこれテスタイムアダプテーションって結構いろんな論文出てるんでなんかの手法のことを言ってるんじゃないかなと。
- [16:34] なるほど。一般的じゃない話かもしれないってことですね。
- [16:37] ああ、そうですね。
- [16:39] はい。で、多分オープンAI
- [16:40] 系はテストタイムトレーニングはやってないと思うんでうん。ああ、少なくとも製品版はですね、もしかしたらボで研究室内というか、一般リースされてないやつはやってるのかもしれないですけど。
- [16:54] 少なくとも製品版として出てるやつはトレーニングはしてないと思うんで
- [16:58] 3
- [16:58] 番はやってないとこですね、この
- [16:59] ああ、そうですね。はい。
- [17:00] なるほど。はい、
- [17:01] 了解です。元に戻ると、え、
- [17:03] TTA
- [17:04] はモデルが水論時に遭遇する特定のデータに基づいて地震の振る舞えを同的に変更する能力に焦点を当てているということですね。
- [17:13] これは事前に読み込まれた知識を問い合わせるのではなく、今までこれですよね、今までのモデルタの事前に読み込まれた知識を持ってくんですけども、え、水論時に学習して適用する能力を意味するそうです。で、
- [17:25] TTAの登場によりアーク
- [17:27] 1で目覚ましい進法が見られ、
- [17:29] 2020年12月にはオープンAIのO3
- [17:32] モデルがアークに特化してフラインチューニングされたバージョンで人間レベルの性能を達成したということですね。
- [17:38] うん。これ多分イメージ的にはこれ
- [17:41] 2
- [17:42] 段落目とか何言ってるかって言うとアークってなんか図形の問題みたいなですか?
- [17:46] 3つぐらい3
- [17:48] つか4
- [17:48] つぐらい例出ると思うんですけどそのうちの
- [17:51] 2つなんか2
- [17:52] 個ぐらいをなんかこう回転させたりとかして水増しするんですよ。で、水増ししてデータを増やしてでその少ないデータでファインチューニングするみたいなんですよね。
- [18:03] で、ファインチューニングしてできた結果でこの
- [18:06] 3
- [18:06] つ目のやつをなんか溶けるかみたいなことを試してで解ければオッケーですよね。
- [18:12] はい。あ、ちょっとどんなテストがあった?こ、あ、これこれですか?
- [18:15] こうやつですね。はい。はい。
- [18:16] こういうやつで。
- [18:17] そう。これだったら入力がこれだったがこれです。入力がこれだったら収力はこれです。入力がこれだったがこれです。じゃあこういう風なものが出たらここはどんな風になるでしょうかという問題ですよね。
- [18:28] あ、そうです。で、これでその1番とか2
- [18:31] 番をなん回転させたりとかして水増しするみたいなんですよね。
- [18:35] そう、そう。
- [18:35] この1番と今2
- [18:37] 問だけだと問題少ないんでちょっとパターンを変えたり、変えるっていうかなんかパターンを水増ししてで水ましたファインチューニングするかそれを解けるように追加で学習してで学習後のモデルでこの
- [18:51] 3
- [18:52] つ目のやつが溶けるかっていうやつをテストしてなんか溶解けるようになるまで多分学習いろんな学習してで
- [18:59] 3つ目が解けたらそのモデルを使ってこの
- [19:02] 4つ目の答えがないやつをもう
- [19:04] 1回とはいそれが
- [19:06] テストタイムテスタイムチューニング
- [19:08] テースですかね、それが。あ、これが多分
- [19:10] TTTですね。テスト
- [19:11] テスタイムトレーニングレ
- [19:13] ですね。はい。これがオープンAI
- [19:16] のモデルには最初入ってなかったという話
- [19:18] ですかね。あ、そう。今も入るか
- [19:19] わかんないですけど。はい。これが出たの
- [19:21] が多分2024年ぐらいでこっから派生系
- [19:24] のそこでなんか多分初めてあのアーク1が
- [19:28] 結構精度良くなってきた。なるほどね。
- [19:31] えっと、ア1
- [19:33] でもやっぱりなかなか精度上がんなかったんだけども、あの、オープン
- [19:36] AIのO3
- [19:37] モデルがアークに特化したファインチューニングされたバージョンで人間レベルの性能を達成した。
- [19:42] あ、これはなんか特別なモデルです。
- [19:44] 特別なモデルですね。そうですね。
- [19:46] ファイン入してないやつで、ま、なかなか制度が上がんなかったけども、ファインチューニング入したらになりましたということですね。で、ポイントは現在、現在は完全にテスト自適用の時代に入っているということですね。
- [19:57] だから新しいフに入ってるんだということで、もうスケーリング速で、え、モデルをどんどん大きくしたら性能上がるという時代は終わって今はテストって企用ですから水論時にコンピューティングするというところの時代に入ってるんだといてアークで優れた性能を発揮する全ての
- [20:14] AIアプローチがTTA
- [20:15] 技術を使用してるということですね。だ、今成績いいのは全部この
- [20:20] TTA
- [20:21] テストタイムアダプテーションという、え、この
- [20:23] 3
- [20:23] つの要素を持ってるんだということを言ってると思います。
- [20:26] すごい記憶が怪しくて間違ってらないんですけど、昔
- [20:30] O3が出た頃に、あの、このアーク
- [20:33] 1
- [20:34] の成績が結構いいみたいなんか話を聞う、ま、この話だと、この話だと思うんですけど、ここでね、
- [20:41] そ、その時に
- [20:42] か、このファインチューニング、テスト時のファインチューニングなしでこんなに生徒が良くなったみたいな、なんかそんな話があったような。
- [20:50] ああ、そうなんですか。
- [20:51] 気もするんですよね。
- [20:52] ああ、そうなんです。
- [20:53] それをだ、ファインチューニング、これまではファインチューニングが主流だったけれどもそれをせずにこの水論水論を大量にすることでけたみたいな話をしたような記憶はうっすら
- [21:05] あるんですけど、ちょっとスライドが見つからず
- [21:08] はい、これもはい、これもさっき話した通りで今ホットなテーマとしてはなぜ事前学習のスケーリングでは壁にぶち合ったと思うのかテスト自適用はで
- [21:19] Agまで行くのか
- [21:20] うん。
- [21:20] え、テスト自表の次ってなんだみたいな、そんなんが今ホットですということを
- [21:24] うん。
- [21:25] え、例さんは言ってます。で、
- [21:27] 2
- [21:27] 年前は誰もがスケーリングでもうモデルをどんどん大きくしていったらエージャイン行くよみんな思ってたということなんですけども、今はそんなことはないと。で、そ適用で
- [21:36] AIが達成できるのなら、今すでに
- [21:39] AI
- [21:39] を達成できてるはずなんで、テスト字用でもないんだと、もっと別の次の方が必要なんだということですね。で、エジに到達するには今後どのような技術が必要なのかというのがこの公演のテーマなんです。
- [21:50] はい。
- [21:50] で、知には2
- [21:51] つの定義がありますよというマービンミンスキーさんの言ってる義とジョンバッカーシさんの言ってる定義がありますと。マービンミスキーさんの定義というのは人間が行うタスクを機械で実行できたようにするということですね。
- [22:04] うん。
- [22:04] で、さんの言ってのはあらかじめ用意されていない
- [22:08] 新しい問題を機械が解決できるようになるとそれが知能なんだというのがマシさの考え方なんですね。
- [22:14] うん。うん。
- [22:15] え、このさんは自分はマッカさん的な考え方ですというで、
- [22:21] え、多くの人がまだこの水さん的なタスクをね、人間がるタスクをできたら、ま、知能だという考え方の人が多いんですけど、例えば経済的価値のある仕事のほとんどができるというのを、え、
- [22:32] Agの定義にこれオープンAI
- [22:34] とかがね、この定義ですけども、それっていうのはミスキーさん派なんで
- [22:38] うん。
- [22:38] で、この彼は詳さん的に今までやったことない問題でも解けるというのが知能なんだということを言ってます。で、彼の考え方に言うと知能はプロセスであってスキルはそのプロセスの結果だという言い方してますんですけど、知能は学びのプロセスのことであって、その学びのプロセスの結果身についたことがタスクなんです。
- [22:57] うん。
- [22:57] で、特定のタスクができるということは知能を示してることにはならないということなんですけど、
- [23:03] これどういうこと?なんか丸でやり方教わってもそれを自分で考えて編み出したんじゃない。ただ教わったことそのままやってるだけだみたいな。
- [23:11] それだから知能じゃないんだみたいなこと
- [23:13] なんですかね。え、知能だったら自分でどうやってこれできるか考え作り出すというのが知能なんでやり方を座ってそれができますというのは知能じゃないんだみたいな。そういう考え方ですかね。
- [23:23] うん。うん。で知能はシステムが持つ情報
- [23:25] 、過去の経験や開発によって与えられた
- [23:28] 事前知識を高い新規性と不確実性を持つ将
- [23:32] の状況に対処するために効率的に活用する
- [23:36] 変換比率ま、だからどれだけで学習できる
- [23:40] かというそれが知能なんだと。
- [23:43] だから当たいい人っていうのはいろんなデータ持ってなくてもそっから色々推測してあこういうことねみたいなことが言えちゃうっていうのが頭のいい人で頭の悪い人は教えてもらったことはできちゃいますけどそれを応用したことてあんまり上手にできないっていうのが頭の悪い人頭の人は働情報よりもっとそれを応用してるができるようになるっていうのが頭のいい人知能が高いということなんだというそういう知能の定義ですね
- [24:07] 1を聞いて授を知るん
- [24:09] そうそうそういうことですよねということです
- [24:13] 昔のAIは普通に1個のことにもう
- [24:16] 1000も万もデータが必要でした。
- [24:18] そうですよね。ま、今でもそうですよね。なんか例えば犬とか猫の判別するのは小さい子供っていうのは何匹ぐらい見れば判別できるんだろう?数匹。数匹じゃない
- [24:28] 10
- [24:28] 匹ぐらい見れば判別できるかもしんないですけど、今のやって何百万
- [24:32] 枚も写真を見ないとね、学習できなかったということなんで、少ないデータでモ事を学べるていうのは人間の知能の高さだという風なことでしょうね。
- [24:40] え、試験のようなベンチマークはスク有のスキルや知識を測ることができるんだけれども事態を図ることはできないというですね。だから今のベンチマークだったらどんだけもの知ってるかっていうのを知ってるか分かるんだけどもそのそれを生み出す知能があるかどうかっていうのは図測れなかったんだというのが例さんの考え方ですね。
- [24:59] で、血のレベルを示す未知の特徴があると
- [25:01] いうことですけども、1つは性的スキルと
- [25:04] 流動的知能の区別基地の問題を解決する
- [25:07] ための性的プログラム集アすることと見た
- [25:10] ことない問題に直面してその場で新しい
- [25:13] プログラムを合成できる能力との違いと
- [25:16] いうことで、これはねなんかこれなん
- [25:18] だろうな、これ決晶かな?
- [25:19] クリスタルっぽいですね。なんか
- [25:20] クリスタルっぽいですね。これは水っぽい
- [25:22] 。
- [25:22] こっちは流動的で柔軟でこっちはカチこちということなんですけども、あの、ことを、いろんなスキルを丸暗記した今までのモデルだったら同じような問題が出たら答えられるけれども、ちょっとでもひねったったら答えられないという。だからなんか数学が苦手だとかよく言われましたよね。
- [25:41] LM
- [25:41] はね、教科書に乗ってるような数式をそのままきてたらそれは答えられるけども、ちょっとひねた数式だったら学習してなかったら嘘つくというハルシネシを起こすとか言われてたのがそういうことだと思うんですけども。
- [25:52] も、あの、やり方を自分で工夫できるというのが知能が高いということなんで、え、それが
- [25:58] 1
- [25:58] つのその教わったことしかできないのか、教わったことをベースにことができるのかというの違いかな。あ、そういうことかな。ちょ、わかんない。
- [26:05] 2
- [26:05] 番目が捜査領域。経験したことのない非常に広い範囲の状況に対応できるスキルがあること。以前に見た状況に非常に近い状況でのみスキルがあることとの違い。この図なんですけどね。
- [26:18] うん。うん。うん。
- [26:18] これがわったことでその周辺のことはできちゃいますみたいなことなんですけど、えっと、知能が高いと教わったことよりももっと大きなことができるようになりますということで、例えばあの全然関係ない
- [26:30] 2
- [26:30] つの知識を元にもっともっと大きなことできますということなんですかね。だから何かできることがどんどん広がるというのが知能の高さだという義ですかね。特徴ですかね。で、
- [26:40] 3
- [26:40] 番目の情報効率というのはっきの野さんが言った位置を知れば
- [26:44] 10を知るというね、そういう話ですね。
- [26:46] 少ないデータでも学習できちゃうというの
- [26:48] が知能の高さだということですね。この3
- [26:51] つが知能レベルを示す特徴だということ
- [26:54] ですね。教わったことしかできないのか、
- [26:56] 自分で工夫できのか、それからえっと
- [26:58] 教わった領域のことしかわかないのか、
- [27:00] その周辺のことも推測できるのか、少ない
- [27:02] データでできるようになんのかと、それが
- [27:04] 頭がいいかどうか、知能が高いかを示す
- [27:07] 特徴だという風に言ってますね。で、なん
- [27:09] でこういう風に特徴ごとに考えないといけ
- [27:12] ないかと言うと、あの、エンジニアって
- [27:13] いうのは測定できるものしか作んないので
- [27:15] 、やっぱり知能の定義とか測定方法が非常
- [27:19] に重要だということで、ベンチマークが
- [27:21] できちゃうとそのベンチマークでいい点が
- [27:23] 取れるように、え、モデルをどんどん
- [27:24] みんな改良するので、だからこういう考え
- [27:27] 方と測定方法を示すということがこれから
- [27:30] のAIを進化させる上で必要なんだという
- [27:32] ことですね。で、AI
- [27:33] コミュニティは長年多すぐ固有のスキルを追求してきた、え、科学の問題解けます。法律の問題解けますとかいうことですよね。で、これは、ま、自動化には繋がりますということですね。自動化には繋がりますけれども、自的に発明を可能にして科学的進法を加速することはできないということですね。やっぱり
- [27:51] 1
- [27:51] からことを考えて色々工夫できるというのが今求められてる知能だということで
- [27:57] うん。
- [27:57] という話ですね。
- [27:59] そう考えると今までのモデルっていうのは自動化に向いているんだけれどもこれから自分で考える
- [28:06] AIになってくると発めに向くと
- [28:08] うん。
- [28:08] そう考えると今はエージェントてこれ自動化の話ですよね。
- [28:12] 今の今のエージェントっていうのはそれでイノベーターというのは自分よ考えるということなるので次のフェーズという風にこれオープのロードマップですけど僕エージェントとイノベーターの違いってよくわかんなかったんだけど多分こういうことなのかなとそうな感じしますね。うん。
- [28:29] 自動自動化全児自童を目指すのがエージェントの時代で自分で考え出すという力を目指すのがイノベーターの時代だということで明らかにやっぱりここは違いますよと。
- [28:39] うん。
- [28:39] えっとAIのシステムとしては全然違う。
- [28:42] ものになりますよということなんで違うレベルになってるんだろうなというのがなんかこれの話を聞いてなんとなく分かりましたとそれまではなんかエージェントもイノベーターも同じじゃないのみたいな感じに思ったんだけどなんかやっぱり全然違う
- [28:54] うんそうすね
- [28:55] ものだという感じですかね
- [28:57] うん
- [28:57] で知能タスクと定義すれば全動システムを目指すわけなんですね今で知能タスクとしてやってたんでみんなエージェントで全自動のシステム目指してるわけなんですけど能をマナーからと提すれば科学の発
- [29:11] 発見につがるということで、
- [29:13] これがロードバップのエージェントの時代からイノベーターの時代へのパラダイムシュートなのかなという感じはなんこの話を聞いて思いましたと。
- [29:14] [音楽]
- [29:21] そういう意味ではサムアルドマンさんはエージェントができれば多くの人はと感じるだろうって発言してたと思うんですけど、
- [29:30] これがまさにミンスキーさんの定義の
- [29:33] AGIでこのレベル4が
- [29:35] マッカーシーさんかな。
- [29:36] マッカーシーさん的な
- [29:37] aのかもしれないですね。
- [29:39] そうですよね。
- [29:40] なんかそんな感じがしますね。だ、ちょっとなんか
- [29:42] AI
- [29:42] の定義が変わってきて、ま、新しいパラに入ろうとしているという感じはしますね。
- [29:48] うん。
- [29:48] そういう意味でなんかこの人の講演って面白かったなと思うんですけど。
- [29:51] うん。
- [29:52] はい。え、さっき出た話ですけど、エンジニアはベンチマークで高得点を取るように
- [29:56] AI
- [29:56] モデル改良するので、ベンチマークの世界が非常に重要だということですね。
- [30:00] うん。
- [30:01] で、え、書が次にどのようなベンチマークを返してるのかが分かれば、
- [30:06] A
- [30:06] が次にどのように進化するのかも分かるんじゃないのかなと思って、次はどんなベンチマークを改良してるのですかという話に行くんですけれども、
- [30:13] ま、アークがどんな風に進化してきましたかということなんですけど、
- [30:17] 2019
- [30:17] 年にリースされたんですね。アーク1
- [30:19] 機械と人間向けのIQ
- [30:20] テストとして設計されたと各タスクはユニークであり、記憶によって解決することはできない。これどんだけ丸期しててもこんなの全部丸期できないですからね。
- [30:30] え、汎用知能を使ってその場で回を
- [30:33] 解き出す必要があるということで、ま、今
- [30:35] までのベンチマークとは違って丸期した
- [30:37] からと知っても答えられないとですね。
- [30:39] ところが人間には簡単だと。4歳児が習得
- [30:42] してるようなオブジェクト性、消歩的な
- [30:44] 物理学基本的な学、トポロジー数え方と
- [30:48] いった基本的な知識のみに基づいてこれが
- [30:51] 解けちゃうということですね。
- [30:53] で、人間にとっては簡単だけど、データは暗記しただけのとっては非常に困難な
- [30:57] うん。
- [30:58] だということで、で、O3
- [31:00] がアークに特化してファインチューニングされたバージョンで人間レベルの性能を去年ですね、達成しましたという。ただ全くできないかほとんどできないかの
- [31:09] 2
- [31:10] 局化してしまうのでもっと進化具合が分かるようなテストが必要だということでアーク
- [31:14] 2を作ったということなんですね。
- [31:16] これ、あのO3がこれで人間ったから、
- [31:19] いや、O3ってじゃあもう人間と同ぐらい
- [31:21] 賢いのか、AGIなのか。いや、そんな
- [31:23] ことはないでしょうということで、もっと
- [31:25] やっぱり
- [31:27] AIが進化してるのを見るためにもっと
- [31:29] ベンチマークを工夫しないといけないよと
- [31:31] 思って工夫して作ったのがアーク2だそう
- [31:33] 。あ、そうですね。アーク2はなんか
- [31:35] もっと難しいんじゃ、もう細かく見れる
- [31:38] ような細かく見れるようにということです
- [31:40] ね。ああ、そうですね。はい。で、アーク
- [31:42] 1
- [31:42] はディープランニング時代のテスト巨大固定なパターン認識回路でどこまで解けるのかを計測したということなんですね。
- [31:49] うん。
- [31:50] だから今までのパターン認識で解けるのかどうかというのを計測するためにアーク
- [31:54] 1
- [31:54] を作ったということなんですけども、アーク
- [31:56] 2
- [31:56] というのはリーズモデル時代のテストと同的に水論しプログラムを合成するシステムでなければ解けない課題を投げ考える能力そのものを継続するということな。
- [32:06] これはO3が言ってるんですけども、昭和
- [32:08] さんちょっと難しい言い方してるんで
- [32:10] 分かんなかったんで、O3に聞いたんです
- [32:11] けど、え、しさんはベンチマークの形式、
- [32:14] 入出力グリッドを数個だけ見せて終水終了
- [32:17] させる方式はアーク1と同じなんだけども
- [32:19] 、マーク2は構成的ハごっぽなる
- [32:23] ジェネレーションをどれだけかにより重点
- [32:26] を置いたということですね。人間でも
- [32:28] アーク1はすぐに解けるけれどもアーク2
- [32:30] は少し考えないと解けない。
- [32:31] 先に構成的反価って何かっていうのもちょっと調べたんですが、その前にじゃあアーク
- [32:35] 2
- [32:35] がどんな問題かと言うとこれが入力でこれが出力です。これが入力でこれが出力です。これが入力だったらどんな答えになりますかというまだからパターンはこのえ、アーク
- [32:45] 2
- [32:45] と似てるんですけどちょっと複雑ですよね。アーク
- [32:48] アークハ結構簡単だったじゃないですか。これね、
- [32:51] え、赤だったら黄色やつきます。青だったら十字につきますみたいな感じでこれだったら赤はこんなありますわっちゃうんだけどもっと服だ。
- [33:02] すよね。これエドさん分かります。
- [33:04] これは多分回転縮小して回転してはめ込んでるんですよね。
- [33:06] [音楽]
- [33:09] そうですね。多分ね、この赤のところが答えなんですよね。
- [33:13] で、これは緑のところが答えなんですよね。で、これ黄色のとこが答えになるんだろうと思います。で、赤のところにこの穴があるんで、これに埋める。で、ただこれ持ってきたら埋められないんで、これは回転だけじゃなくて反転させてますよね。反転させたらここに入ります。
- [33:15] [音楽]
- [33:28] ああ、そうですね。反転もしてます。
- [33:30] これは回転で入りますね。
- [33:32] うん。
- [33:32] で、これはそのまま入りますね。ということですかね?これは
- [33:36] あ、青、
- [33:37] 青はここに入るんですかね?
- [33:38] あ、違うわ。これ赤を、あ、縮小じゃなくて赤を拡大してるんですね、場合に
- [33:42] 赤を拡大して。そう、そう。
- [33:44] 赤を拡大してで、それで他のこの反転させたり、回転させたりして埋めてるということで、黄色は無視ということですね。
- [33:52] うん。
- [33:53] で、これもそうですね。これも緑を拡大してこれは反転しないと入んないかな。
- [33:59] うん。
- [34:00] で、これは回転すると入って、これはそのまま入りますということですね。で、ここのところにはこの薄い色が入りますということな、
- [34:08] こういうやつなんですね。これはやっぱりちょっとアーカイもかなりひねってあって、いくつものルール。
- [34:13] これはなんかルールシンプルなんだけどこっち側の方はなんか回転もあるし
- [34:18] 反転もあるし縮小拡大もあるしということでいくつものルールを空的にやらないといけないんですけど、え、それが構成的繁ジェネラゼーション能力のと言うんですけど、すでにしてる小さなルールを新しい組み合わせ文脈速行合成し初見の初めて見る課題を特地からのことだし
- [34:39] 家なら回転とかトリミングとか色置き換えなど自由に組み合わせがう
- [34:43] で、新しい図形処理を作れるんだけども、多くの
- [34:46] AIというのは1
- [34:47] つのルールずつしか検出ないので、複数のルールを同時に使うということがなかなか難しいていうのが今の
- [34:54] AIな
- [34:54] んでそれを図る力だそうです。で、アーク
- [34:57] 2は今年3
- [34:59] 月にリースされたということですね。
- [35:00] 水論システムとテスト字時用パターンに挑戦したということでダスクはよりされており熟量が必要だけども
- [35:06] [音楽]
- [35:07] 2元にとっては遺伝として簡単
- [35:09] 400
- [35:09] 人のテストで確認したということですけど
- [35:11] GPT4.5とかラマ4
- [35:13] のような基本モデルは解けないそうです。これね。
- [35:16] うん。
- [35:16] で性的水論システム
- [35:18] 1
- [35:18] 回の思考の連鎖だけで水論するようなもんでも
- [35:21] 12%しか解けないということね。
- [35:23] うん。アクを解決するたにはテストが必要れもそれでも今のテスト適用システムは人間レベルにはほ遠いということですね。今の
- [35:32] うん、
- [35:33] テスト自適用でどんな仕組みかというと、こういう順番でね、仮説を作ってプログラムを作ってで、モデル自体も微調整してそれでできたかどうか調べるというこういうことをテスト自用なんですけど、これを完璧にもまだできていないという状況ですね。
- [35:50] 今のAIでもなかなかいい点は取れてない
- [35:52] ということですね。で、アーク2を使う
- [35:54] ことでOUのようなリーズモデルの進化を
- [35:57] 計測できるということです。で、人間に
- [35:59] とって簡単なタスクを解けないAIはAI
- [36:02] とは呼べないと人間にとって簡単なタスク
- [36:05] でAIにとってタスクを見つけるのが
- [36:08] 難しくなってくればこのベンチマクを作る
- [36:10] のがだんだん難しくなってくれば我々が
- [36:13] AJに近づいてる証拠だということですね
- [36:15] 。で、まだまだ簡単にこういう問題作れ
- [36:17] ちゃうんでということはAG全然達して
- [36:19] ますよということですね。
- [36:21] そのうちに人間にとって簡単で
- [36:23] AI
- [36:24] にとっても簡単みたいなっかりなっちゃうとそれはもう
- [36:27] A
- [36:27] 時代に近づいたことになるということなんで今はまだ全然人間にとって簡単だけど
- [36:32] AI
- [36:32] にとって難しいっていうのはまだまだあるので全然
- [36:35] Ag
- [36:35] になってないよというのが彼の意見ですね。
- [36:37] はい。
- [36:38] でその時どんなのかアク3
- [36:39] というのやってるんですけどこれ見えるかな?ゲームですね。
- [36:47] こなとね、もう今までのようなそのパズルじゃなくてゲームの操作みたいに入ってくるんでしょうけど、こういうのを今開発してるそうです。アク
- [36:56] 3というの、
- [36:58] えっと、7
- [36:59] 月に開発者向けプレビューが出て、え、来年初当に正式版にリース予定ということなんですけど、アーク
- [37:05] 1及びアーク2
- [37:06] の入力主力ペア形式から大きく離れ、今みたゲームみたいになってますからね。
- [37:10] エージェンシー体性探索対的な学習目標設定術的な目標達成の能力を評価するためのえっとベンチマークだそうです。
- [37:20] AIは捜査方法も目標も分からない全く
- [37:23] 新しい環境に置かれスペトをその場で理解
- [37:26] する必要があると効率性が重視されモデル
- [37:28] はタスクを解決できるかどうかだけでは
- [37:31] なく効率的に解決できるか身と評価さ
- [37:34] れ人間の行動効率と同じレベルの
- [37:36] 行動数制限が重せられるということなん
- [37:39] ですけどね。
- [37:41] 結構怖いすね。
- [37:43] 何が怖い?何が怖いんすか?
- [37:44] いや、だって死体性
- [37:47] 結構これまでAI
- [37:48] し体性がない話でしたけど、あ、それつけに行くんだみたいな。
- [37:54] そうですね。これで下どうやってどうやって計測するのかな。ちょっとよくわかんないですけど。
- [37:59] うん。
- [37:59] あの、
- [38:01] これもね、で、何が問題かもわかんないんでね。これどうときゃいいのかもわかんないので。どうときゃいいんだろ。
- [38:07] これ合わせるということかな?これ見たらなんか黄色を合わせるということですかね?
- [38:11] うん。
- [38:11] 黄色を合わせる方法ですかね。これはね、何が合ってるかもわかんない。
- [38:17] 何があってるかわかんないです。これ何のようなんだろう?
- [38:19] これは何をしようとしてるんだろう?みたいな。なんかわかんないですけどね。
- [38:24] うん。
- [38:25] はい。
- [38:25] こういうの今開発だということですね。
- [38:26] 俺も効率効率性を重視してるんで。
- [38:30] そうですね。
- [38:30] 効率効率よく滅ぼされたら困ります。
- [38:32] [笑い]
- [38:34] はい。ということでアーク3
- [38:36] も出てくるとこれで点数を多く取るようにこれから
- [38:39] AI
- [38:39] というのは研究開発が続けられるんだろうなというのでこれが今後の
- [38:43] AI
- [38:44] の進化の方向性だなと思いますね。どんな風に進化していくのかというと今エ藤さんが怖がった主体性をつけるということですかね。探索、対話的な学習目標設定、自的な目標達成の能力の次の段階で
- [39:00] AI
- [39:00] は身につけてくるかもしれないということですね。
- [39:03] うん。
- [39:03] ま、あれですね、多分チャット型っていうよりはエージェント向けのやつなんじゃないかなって気がします。
- [39:09] そんな感じしますね。はい。
- [39:11] うん。
- [39:11] ということで、えっと、今の現状はまだまだアーク
- [39:14] 2
- [39:14] で高得点を取れるとこまで行っていないということなんで、
- [39:17] NJ
- [39:17] はまだまだ先だろうということですね。
- [39:19] え、何が不足しているのか、これから
- [39:21] AI
- [39:21] はどのように進化していくのかということですけども、
- [39:24] AI
- [39:24] は過去のデータのパターンから未来を予測してるだけと、そんな風にこないだ言われちゃったんで、え、もう全然違うよとどんどん進化してますよという話をしたかったんで、今日の話を持ってきたんですけど、ま、でも人間も過去のデータのパターンをベースに未来を予測してるんですよね。
- [39:32] [音楽]
- [39:38] うん。うん。過去のデータのパターンを別にしない知能など存しないのではないかと思っていたらやっぱりあの修レさんもそんな話をしていて万教化説というのから言ってるんですけどもこの世の中に完全な新規なものなど何もない。
- [39:52] 全てのものは何かに似ていると、例えば一本の木は別の木と似ているし、その分岐構造は神経細胞の枝分別れにも通じると。
- [40:01] 電磁期学を支える数式は流学や重力の数式とも形が似てるし、いた形、イソモルフィズムが世界中に満ちていると世界は無限に新しく複雑に見えるけれどもそれを記日している意味の最小単位は驚ること少ない。
- [40:19] 見のものはその少数の意味の最小単位の組み合わせに過ぎない。
- [40:24] うん。
- [40:24] 知能は経験をマイニングして繰り返し現れるパターン不縁の構造共通原理を見つけるそれを抽象概念意味の原子として手持ちの道具にする新しい状況に出会ったらその抽小概念をその場で組み合わせ直して意味付けを行う能力それが知能だということですか?知能はどういうことかと利用できる傷を発掘して即興で組み替え続ける力を知能という風に彼は定義
- [40:32] [音楽]
- [40:53] しています。なんかこれ分かります?なんとなく分かるような
- [40:56] なんとなくそうですね。なんとなく分かるような気がしますね。
- [40:59] なんかあのことが環境とか宇宙とか世界の中にあるんだけどもそれを我々が認識するということにおいては認識するパターンっていうのは実はめちゃめちゃ限られているパターンの組み合わせでしかないという
- [41:11] 就傷化の組み合わせでしかない。ま、あの理解するためなんとか難しい複雑なことをできるだけ小化していきますからね、我々はね。
- [41:19] だから実はあの中小化のベースになってる概念っていうのはそんなに多くないんだよという話なんですけどもで足らないのは中小の再決合能力ということですね。
- [41:30] 知能の実想には中小化の獲得とそれから再結合をするとこの
- [41:34] 2つの能力がいるんですよね。
- [41:36] うん。
- [41:37] え、経験から利用可能な化を効的に収する能力がまず必要でで、それらをこれらの構成要素を現状の状況に適したモデル上効率的に選択し、再結合する能力とこの
- [41:50] 2
- [41:50] つの重要な部分から知能っていうのはできるということで
- [41:54] 重要なのはその効率性、データ効率とか計算効率とか何モデルを大きくしてより多くのデータで訓練するだけでは
- [42:01] AIには繋がらなかった。
- [42:03] これはモデルがその場での再結合能力を変いていた水論時に完全に性的だった事前習で学んだ解決方法しか使えなかったことそして非効率だっため例えば公配効果法なんかディープラニングのなんかあれですよね。最適な回を見つける方法かなんかですよね。ちょっとなんかやしいと思う。ま、そんなニオラネットワークのやつですね。
- [42:22] そうですよね。人間が必要するよりも数桁の奥のデータを必要するということですね。
- [42:27] あ、これがあの今日喋ったかな?どっかで喋ったあの話ですね。
- [42:31] そのデータは人間だったらいくつかで済むやつが人昔姉妹前のエア数千も数万もかかるみたい。
- [42:37] そうです。爆弾大が必要だったということですよね。で、非行率だったということですね。
- [42:41] でも今ちょうど私もここら辺の研究にや取り組んでる
- [42:46] とこだったりします。ちょうど中小の再決合みたいな。
- [42:49] なるほど。
- [42:50] 最新のAI
- [42:51] モデルでも水路のために膨大な計算主源が必要。それでもアーク
- [42:55] 2で高得点をゲットできない。
- [42:57] なぜなら動的反化さ言ばれたあのもの組み合わせる
- [43:01] 2つか3つのルールがあったらもうAIは
- [43:03] パンクしちゃうというそれが能力が足りないからとますでにしてる小さなルールを新しい組み合わせ準次を分脈て即興構成し初見の初めて見る課題を得力っていうのがまだ足らないだということですね。
- [43:17] これは初例さんか抽小に
- [43:19] 2つありますよとタイプ1とタイプ2
- [43:21] があります。え、難しいですね。
- [43:23] 対1中心中か連続的な距離関数を返すか何
- [43:27] のことか分かりません。え、タイプ2
- [43:29] プログラム中心何のことかわかんないんで
- [43:31] 僕はO3に聞きました。O3はこんな風に
- [43:35] 言ってくれます。難しいことも言うんです
- [43:36] けど、簡単に言うと人間で言うとタイプA
- [43:39] っていうのは直感的なパッと見て分かる
- [43:41] 認識とか感覚がタイプAの抽象化タイプ2
- [43:45] っていうのは頭の中で手順を分解して
- [43:48] 再構築して問題を解く論理思考確かになん
- [43:51] か抽象かって言うと確かに僕これ結構し
- [43:53] まして難しい問題があったらこれを簡単な
- [43:55] 図式に変えて簡単なモデルに変えてそれで
- [43:58] 理解してということが結構多いんでこう
- [44:00] いう抽象化しますよね。で、あとは
- [44:02] やっぱり絵なんかもパッと見て分かるとか
- [44:04] いうのも、あの、頭の中で、あ、これは犬
- [44:06] みたいな猫みたいな、すぐ言葉に置き換え
- [44:09] たりとか感覚的に抽象化してるのかなと
- [44:11] 思いますけども、この2つの重傷化がある
- [44:13] という、ま、オープンエアに説明して
- [44:15] もらうと、あ、2つは確かになるなと思い
- [44:17] ますが、え、書類さんはこんな風な難しい
- [44:19] 表現をしていました。で、全ての認知は
- [44:22] これら2つの形式の中小化の組み合わせ
- [44:24] から生まれるということなんですよね。
- [44:27] で、これってあのウさのじゃないですかということをレさんは言ってます。
- [44:31] パーセプション認識するか直感とかね、
- [44:34] そういうものそういう就職化っていうのは
- [44:37] 右能それからじっくり考えるとか、え、
- [44:40] 論理的に考えるとかそれは左能みたいな。
- [44:43] 今のAは右能的能力直感的なパッと見て
- [44:46] 分かる認識感覚は得意だけれども左能
- [44:49] 的能力頭の中で手順を分解して再構成して
- [44:53] 問題を解く論理的思考が不得意だという
- [44:55] ことでこれなんかこないだあの臨気
- [44:58] YouTuberのロブマインドの
- [44:59] 高田さんと話したら高田さんそんなこと
- [45:01] 言ってましたよねあ言ってましたね
- [45:04] なんかみんなはあのAIAIをなんか能と
- [45:07] か言いますけど僕は今のAIって
- [45:09] 能的だと思うんすよみたいな
- [45:11] で能的な論理的う
- [45:13] 考える時がついたら本当にそれは怖い話だと思いますみたいなこと高田さん言ってたんですけど高田さんの言ってたことのこの修レさん言ってることまじかなと思そうですねあの昔ながらっていうかニュロネットワークは元々この直感的というかあのちょっと前のやつ
- [45:29] あこれですね
- [45:31] 1
- [45:31] っていうのはちょっと前ちょっと前というかま今はそうかもしれないですけどニュアルネットワークとかを普通に使ってるとタイプ
- [45:38] 1に
- [45:38] そうですよね。画像認識とかね温泉認識とかそうですもんね。
- [45:41] うん。うん。そう、だからちょっと前まで
- [45:43] はAIのなんかに認知とか言ってやつじゃ
- [45:46] ないですか。なんでもう直感的に認知する
- [45:49] みたいなのがタイプ1ですよね。で、この
- [45:52] タイプ2の方はなんか難しいこと言って
- [45:56] ますけれども、ま、作能的な話ですよね。
- [45:59] そのシステム1システム2のっ思考みたい
- [46:03] なやつですよね。と、そうですね。そう
- [46:05] いう話ですよね。うん。うん。はい。と
- [46:07] いうことで、これを合わせるということが
- [46:09] 大事だということで、で、タイプ2の抽象
- [46:11] 化能力を得るために、ま、物事考えるって
- [46:14] 難しい問題も簡単な、えっと、図式に変え
- [46:17] て理解するということですかね。それを
- [46:18] 得るためにはどうすればいいのかという話
- [46:20] なんですけども、え、理算的なプログラム
- [46:22] 探索は不可欠。ま、わかんないな。
- [46:24] プログラム合成は非常にデータ効率がいい
- [46:27] が問題の複雑さがマに連れて組み合わせ
- [46:30] 爆発の壁にぶつかると機械学習は計算効率
- [46:33] がいいがデータ密度が必要わかんないです
- [46:36] ね。
- [46:36] なんとなく分かります。エ藤さん、これ分かるわ。
- [46:38] これだけ読むとプログラム探索だから、その今の
- [46:43] O3
- [46:43] とかもなんか考える途中で全部水論するんじゃなくて途中でプログラム自分で書いてなんか問題解こうとするじゃないですか。
- [46:52] 多分そういう話を言ってるんじゃないのかなっていうで後半の
- [46:57] そのことをね、オスに聞いたんですよ。これ難しいんどういうことですかっていうとオスレはこう答えてくれたんですけど、そういう話ですかね。
- [47:03] はい。
- [47:04] で、公配効果法は計算行為率がいいがデータ密のが必要っていうのはデータがいっぱいいりますよ。大量のデータ食わせなダメですよって話ですね。これはあのタイプ
- [47:14] 1のこと言ってますね。
- [47:15] そうですね。はい。で、タイプ
- [47:17] 2
- [47:17] の抽小には部品プログラムを見つけて状況ごとに組み換える力が必要だと。これを実現するためには理算的なプログラム探索エンジンが必要ということ。リ算プログラム探索エンジンってこんな仕組みで作りますよということ言ってますね。はい。
- [47:31] ちょっとわかんないですけど。
- [47:32] うん。
- [47:32] ま、これは与えられた問題が解決できるようなプログラムを作って実際うまく解けなかったら改造しますみたいな、そういう話ですか?
- [47:41] そういう話ですかね。そういう話だと思います。はい。で、
- [47:44] ACIの、え、の道としては2
- [47:46] つの抽象化の融合ということで、人間は両方の形式をの抽象化を組み合わせるのが得意。例えばチェストで直感で使って後法を絞って計算を行うとかね。
- [47:57] 真層学習に基づいた直感をガイドとして
- [48:00] プログラム空間の理算探索を行う。これに
- [48:04] よってタイプ1の迅速打が近事的な判断を
- [48:06] 活用して組み合わせ爆発を抑制し
- [48:10] プログラム探索を実用的にするとこの
- [48:12] システム新しいタスクに直面した
- [48:14] プログラマーのように振る舞い真層学習
- [48:17] サブモジュール資格などのタイプ1問題用
- [48:20] とアルゴリズムモジュールタイプ2問題用
- [48:23] を組み合わせたプログラムまたモデルを
- [48:25] その場で合成するとそれができるんだっ
- [48:27] たらAGIになっていきますよという話か
- [48:29] なと思うんですけどね。
- [48:30] で、この探索プロセスは0
- [48:32] から行われるものではなく、再利用可能な構成要素、抽象化のグローバルライブラリーを活用し、ライブラリーは学習を通じて常に進化する。最終目標は人間が既存の通れやライブラリーを活用して新しい問題を回復するのと同様に豊富な中小化ライブラリーを使用して新しい洋を
- [48:51] 20日に対応できるAI
- [48:53] を構築することということですね。
- [48:55] ああ、なるほど。
- [48:56] やっぱその場で学習したりとかウルアラムをその場で書いて問題をそれによって見たことない問題をこの場で解決できるようになるからになるみたいなそういうアプローチですね。こ
- [49:09] そうですよね。はい。
- [49:10] で、そのためにはなんかいろんなモジュールみたいなのをいっぱい持ってないといけない。
- [49:15] 人間もね、過去に経験した方をベースに未来を予測したり、未来に対応したりできるんですけど、そのモジュールを人間だと今まで生きてきた経験の中からこんだけしかないですけど、
- [49:25] AAなるとそれがものすごい数のモジュール作れちゃうんで、人間よりもはかにろんなことを試せるようになるし、いろんな状況に対応できるようになるので、人間では見つけることのできない科学のなんかルールみたいなを見つけ出す可能性がありますよということで、これができちゃうとイノベーションが起こるということで、科学の技術がものすごく進化
- [49:45] するでしょうという、それを作っていきますという話ですかね。
- [49:48] ですね、このタイプ1
- [49:49] で直感的にこのモジュールを使ったらいいんじゃないのかみたいなのを絞り込んでタイプ
- [49:54] 2
- [49:54] でそれを組み合わせながら実際解決するみたいなそういう話ですね。
- [49:59] そうですね。
- [49:59] うん。うん。
- [50:00] まあまあ人間がやってるようなようなことを
- [50:02] AI
- [50:02] でもやらさないと進化はないつことだから進化はそういう風な
- [50:06] 2
- [50:06] つの中小化の融合ということがこれからの
- [50:08] Aの進化なのかなと。
- [50:10] で、こういう風なこれ僕何のことかわかんないですけどこういうことをこういうのあげてました。
- [50:14] だけどさんどうですか?あなたがピンときます。
- [50:16] これがよくわかんなくてなんかいっぱいあるわけですよね。
- [50:21] そうですね。これ過去の経験みたいなもんですよね。これを持ってきてそれでその場で何かプログラムを作っていくということですかね。オンダフライですからその場でタスクを解決するためのプログラムをその場で作っちゃうということですかね。
- [50:33] これ、これタスク側から読むと分かりやすいかなと思って、なんかタスクがある時にで、このタスクの情報のデータを言いてきてで、そこでそれを解決するようなホログラムなのか
- [50:46] AI
- [50:46] なのかをオーバーで作るんだけれども、それをゼロからやるわけじゃなくて、そのクイックリーなんで、その上の四角は方タイプ
- [50:56] 1とこですよね。タイプ1
- [50:58] の直感でどれを使うかみたいなを持ってきてやるわけです。あ
- [51:04] あ、なるほどね。だここがタイプ1
- [51:06] でここがタイプ2
- [51:07] でみたいなことですかね。かなと思いますね。
- [51:09] はい。これを組み合わせるということがこれからの
- [51:12] AIの進化なんですよという話ですかね。
- [51:14] うん。うん。で、これがあのライブラリーが多分更新されていくんですよね。そうなると共有
- [51:21] 1
- [51:21] 人の脳だけじゃなくてみんなの経験っていうのをみんなが使えるようになるっていう話なんですかね。
- [51:26] これがすごいですよね。これが人との全然違うところで、これは人間だと本を呼んだりとかね、自分で体験したことないことは誰か話聞いてということをけ加えていかないといけなんだけど、
- [51:38] Aだったら何番体というA
- [51:40] が経験したこと全部過去のなんだろうなモジュルになっていくのでだからできることがめちゃめちゃ増えていきますよという話ですかね。
- [51:47] うん。うん。うん。うん。
- [51:48] そうですね。で、AI
- [51:50] は経済的価値のある仕事のほとんどが可能なシステムから見たこともないような課題も解けるようなシステムへと進化しようとしているという、それが今の進化ですね。エージェントからイノベーターへの進化がこれだと思うんですけどで、中小化の課題が解決し結合が効率よくできるようになればこれですよね。これが効率よく解決合できるようになればエージェント時代からイノベーターの時代へと移行するんだろうと思いますね。だから今ここの段階かなという感じはします。
- [52:16] なるほど。で、特にAI
- [52:18] は過去のデータのパターンから未来を予測しているだけという話。ま、そっから始まったんですかね、今回。これからいや、ちょっと違うんだけどと思うんですけど、
- [52:26] AI
- [52:26] が上野定知能システムだということなんですよね。これでだから過去のデータからできることで限られてますよね。
- [52:35] 意見があったんですけど、これから進化してくると過去のデータから、ま、今過去のデータからあの未来に対応するんだけどもできることがもっと増えていきますよということなんで、
- [52:46] A
- [52:46] は過去のデータのパターンからメラを予測してるだけという、こういう風に思ってる人たち違いますよ。もうこっち側になろうとしてますよという話ね。
- [52:53] こっちは進化しようとしてますよということなんで、人間が得意なこと、
- [52:57] AI
- [52:57] が得意なことがついついと変化している段階にあるので、
- [53:01] AI
- [53:01] にはこれができないと決めつけるのは今危険かなと。というとか
- [53:04] 2
- [53:04] 年先以上の未来を予測するくことも注意が必要かなと。だってこんな風に進化していきますから。
- [53:10] そうですよね。わかんないですよね。
- [53:11] ということで大きく見ればこういう風にこんなことが今起こってますということでね。
- [53:16] イノベーターの時代に行こうとしてるということで小さい話としてはいやもう
- [53:20] AI
- [53:20] って変わってきてるから去年たことが今年も通用しませんよというそういう話ですかね。
- [53:26] はい。以上でございましたですけど
- [53:28] 難しかったな。ま、でもエ藤さんと話したけだいぶ僕も理解が進みましたね。これが全く何のことかわかんなかったですけどエ藤さんに解説してもらってあ、なるほど。これがタイプ
- [53:39] AとタイプE
- [53:39] を合わせるということが分かったので、
- [53:41] ま、多分こうじゃないかなっていう話。
- [53:43] そうだと思いますね。多分そうだと思いますね。
- [53:45] うん。うん。どうですか?今日のお話は。
- [53:47] いや、でもこれ面白かったですね。うん。
- [53:51] なんかすごい自分も頭が整理されたような気がします。
- [53:54] はい。ありがとうございました。ということで今回はこんなところで。はい。じゃ、また次回お会いしましょう。さようなら。
- [54:00] うん。はい。さよなら。
- [54:05] [音楽]
