---
title: "Transcript: ZeZozy3lsJg"
video_id: "ZeZozy3lsJg"
video_url: "https://www.youtube.com/watch?v=ZeZozy3lsJg"
speaker: "Unknown"
channel: "Unknown"
date: ""
duration: "00:13:07"
tags:
  - "AI"
  - "Agents"
  - "Startup"
  - "LLM"
  - "Product Development"
topics:
  - "AI Agents"
  - "Entrepreneurship"
  - "Large Language Models"
  - "Product Development"
  - "Data"
summary: |
  動画の内容を分析中...
key_points:
  - "AI and technology discussion"
  - "Industry insights"
  - "Future perspectives"
category: "AI Agents"
confidence_level: "high"
---

# Transcript: ZeZozy3lsJg

- URL: https://www.youtube.com/watch?v=ZeZozy3lsJg
- Retrieved at: 2025-12-30T11:24:21+09:00

## Text

- [00:00] You might have heard that this is the year of AI agents, but some
- [00:06] prominent voices in the AI community, such as OpenAI Co-Founder Andrej Karpathy, they paint a bit
- [00:13] of a different picture. They're actually saying that this is the decade of AI
- [00:20] agents, and that today's AI agents, they kind of struggle with some basic tasks. They are being
- [00:27] a bit oversold, and it will take advancements over the next ten years to work through all the issues.
- [00:33] Now, why do today's AI agents struggle with many tasks? Well, there's a lot of reasons. One of them
- [00:39] is they just don't have enough intelligence, the model behind them. They also struggle with
- [00:46] computer use, interacting with a computer UI, and they lack continual
- [00:53] learning, and they lack some multi-modal capabilities. So
- [00:59] whether this is the the year or the decade of the AI agent. Let's examine
- [01:06] three use cases for agentic AI. So the first one we're going to look at number one here. That one
- [01:13] is going to be where AI agents are already providing tremendous day-to-day utility. They work
- [01:18] really well. Number two, use case number two. That's considered a common use case. It comes
- [01:25] up pretty much every time a new agentic AI model is released. But as you'll see, it kind of falls a
- [01:31] little bit short in practice today. And then finally, number three is going to be an
- [01:37] aspirational use case that's a little bit beyond current capabilities, but maybe far more
- [01:43] commonplace a decade from now. And use case number one is coding assistants, AI
- [01:50] agents that work together alongside developers. And they can do a bunch of stuff, like they can
- [01:56] write code, they can fix bugs, they can generate documentation, they can
- [02:03] review pull requests, those sort of activities. And of course, this isn't hypothetical. If
- [02:09] you're writing code today, chances are you're already taking advantage of agentic coding
- [02:16] assistance to help you. So the question is: why are coding assistance such a good fit
- [02:23] for the agentic capabilities of AI models today? Well, let's go back to those four AI agent
- [02:29] capabilities I've mentioned: intelligence, computer use, multi-modal and continual learning. So let's
- [02:35] first of all start with the capability of intelligence. Now code code
- [02:42] has a number of things going for it. It has a really good structure. Code is very structural.
- [02:49] It has a lot of well-defined rules. So the agent doesn't really need human-level
- [02:56] reasoning for most coding tasks. It needs pattern matching, pattern matching across millions
- [03:02] of code examples. And current models are really good at this sort of thing, and it doesn't hurt
- [03:07] that programing problems, they tend to have clear right and wrong answers. The code either compiles
- [03:12] and it passes tests or well, it doesn't. So that's that one. What about computer
- [03:20] use? Well, it's barely needed because these agents, they work within
- [03:26] integrated development environments (IDEs). And those are well-defined interfaces that haven't
- [03:32] really changed dramatically in years. And agents don't have to navigate inconsistent web UIs or
- [03:37] click through enterprise applications. All right. What about multi-modal capabilities? Well,
- [03:44] not really required. That's because when it comes to code, it's basically text in
- [03:51] and then text out from the model. So code comments, error messages, it's all text-based,
- [03:58] and it's highly structured. And then as for continual learning, well, yes,
- [04:05] programing languages and frameworks evolve. They change, but somewhat slowly and usually with
- [04:11] pretty extensive documentation. So an agent using a large language model, that would already have
- [04:17] been pre-trained on a lot of that information, it was part of its training set.
- [04:23] So it has knowledge already of vast amounts of source code and knowledge that applies broadly
- [04:29] across most projects. So it's a coding assistance, they play to the strengths of current AI models.
- [04:34] They operate in structured environments, they have immediate feedback loops, and they work with
- [04:40] well-defined problems. Okay. Now use case two is travel booking, and this is the one that comes up
- [04:45] in practically every demo of new agentic AI models. And the basic premise is a series of AI agents
- [04:52] that handle like booking your entire trip. So that might involve booking some flights
- [04:59] across airlines, and then maybe comparing some hotel options and then
- [05:05] booking everything, making sure that we get the optimal prices, and then ultimately kind of
- [05:11] managing your calendar. And yeah, this does seem like a perfect fit. It's a defined task
- [05:18] with clear goals: get a person from point A to point B at a reasonable cost. So
- [05:25] why does this only somewhat work today? Well, if you have what we can
- [05:32] call kind of simple happy path scenarios, well it does kind of
- [05:39] work quite well. So if you need to book a direct flight and find a standard hotel room, current
- [05:44] agent agents, they can handle that decision-making. The information they're working with, it's mostly
- [05:49] text-based, it's flight times, it's prices, it's hotel descriptions, and that's within their
- [05:54] capabilities. But it doesn't take long to run into limitations. So let's go back to those
- [06:00] four capabilities. And we're going to start again with intelligence. And the big thing with
- [06:07] intelligence is that when it comes to that edge cases, they kind of kill
- [06:14] it. What happens when a flight gets delayed? Or, if you're connecting through a city with certain
- [06:18] visa requirements or you're traveling with an infant? Well, current agents, they really don't
- [06:24] handle the the long tail of real-world complications that human travel agents do.
- [06:31] And if you've ever traveled anywhere, then you don't need me to tell you that travel is full of
- [06:36] edge cases. Okay, computer use is another big one.
- [06:43] Every airline, every hotel chain, every booking site, they all have different
- [06:49] UIs. There's a lot of UI variants. They also might have CAPTCHAs, and they might have
- [06:56] authentication flows. And in fact, many of them are intentionally made difficult to automate.
- [07:03] So when agents need to navigate the actual websites instead of using APIs, that is where they
- [07:10] can struggle a bit. Okay, what about multimodal? Well, reading flight
- [07:17] times and prices from text is fine, but there are some nuances like, take for example, if we have a
- [07:24] hotel map that we actually need to read to see if that hotel is actually walkable to your
- [07:30] conference center, or if it's just kind of technically nearby. Trust me, that's one I've
- [07:35] struggled with a few times. Well, that does require multimodal understanding that current agents, they
- [07:41] might struggle a little bit with. And then, what about the continual learning aspect? Well,
- [07:48] when it comes to continual learning, your preferences that you really matter. Now, sure, you
- [07:54] could fill out a profile. You could say you prefer aisle seats and Marriott hotels, but the real
- [08:01] challenge here isn't just filling out the profile; it's actually learning. So we need to learn by
- [08:08] observing the world and then getting feedback on those observations. And it is
- [08:14] really a loop. The agent needs to figure out that, let's say, you're willing to pay more for direct
- [08:20] flights on Monday mornings, but you like to take connections on Friday afternoons. These are
- [08:25] patterns it needs to learn from your behavior over time, rather than just the simple preferences
- [08:31] that you can think to list up-front. So travel booking, it works well enough to be
- [08:38] impressive in agentic demos with cherry-picked scenarios, but today it's probably not reliable
- [08:45] enough that you would fully trust it with your actual travel, at least without close supervision.
- [08:51] All right, so for use case number three. This is my aspirational one. It's automated IT support. So
- [08:57] this is a bit more than an agent that helps answer helpdesk tickets with cam responses. That's
- [09:03] that's kind of level one stuff. And well, I would say that does already work today. But I'm thinking
- [09:08] more about an agent that does a bit more than that. So it actually completely autonomously logs
- [09:15] into a user's this machine, then it diagnoses whatever the problem is, and then
- [09:22] it actually has full control to go and fix that problem autonomously. Now this seems
- [09:28] like the perfect use case for AI agents. It's repetitive. It often follows patterns. But would
- [09:35] you trust an autonomous AI agent with free rein on your laptop to install fixes and delete
- [09:41] applications without your consent? Yeah, probably not. So why not? Well, let's
- [09:47] take a look at the capabilities again. So what about intelligence in this case?
- [09:54] Well, every user's setup is kind of unique to them. So there are a lot of
- [10:01] different paths we could take here. I think we could say most machines have a bit of a quirky,
- [10:07] unique setup. Now, a simple outlook issue on one machine that might be a corrupted file. On another,
- [10:14] it might be a proxy setting, and then, it could be an expired certificate on a third. And current
- [10:19] agents, they often can't handle these kind of endless edge cases. Now, there are also significant
- [10:26] issues when it comes to computer use. There is a lot of requirements here. So the agent, it
- [10:32] needs to be able to navigate a lot of stuff. So what does it have to navigate? It has to navigate
- [10:38] that user's machine. And well, people have different machines. So just for one example,
- [10:45] if you're a Windows user, it will need to be able to navigate Windows settings. Or if you're on a
- [10:50] Mac, it would need to understand Mac preferences. And that's just the operating system. There's also
- [10:57] the application UIs, which are all specific to those applications and so forth. And all of
- [11:04] this, remember, is potentially running on a system that is in
- [11:11] production. Today's computer use capabilities, they just aren't reliable enough for that level of
- [11:17] trust. Okay. What about multimodal capabilities? Well, users, they're going
- [11:24] to send things like screenshots in. They, they might speak to the agents. So you're going to
- [11:31] have some kind of verbal stuff as well. And that verbal description might not be that instructive.
- [11:37] It might be saying things like, uh, it's doing that thing again. And you've got to kind of figure out
- [11:41] what it is. The agent needs to piece together whatever users can capture in the moment. And then,
- [11:48] when it comes down to continual learning, the agent needs to learn specifically
- [11:54] from outcomes, and those outcomes will adjust over time. So
- [12:01] when software updates break things, which fixes are actually going to work in your specific
- [12:07] environment? As new devices get added and new issues emerge, the agent needs to adapt based on
- [12:12] what's working and what's not in practice. It needs to learn from the feedback loop of
- [12:18] thousands of support interactions beyond a model's initial training data. So basically, this
- [12:24] use case is still emerging, but it's just not fully there yet. So year or
- [12:31] decade? Well actually both, we're in the year of AI agents for, for narrow,
- [12:38] well-defined tasks in structured environments. But we're in the decade of AI agents
- [12:43] for the broader vision, agents that handle messy real-world problems with reliable computer use,
- [12:49] with intelligence about edge cases, with true multimodal understanding and learning that
- [12:54] adapts to your specific environments. So for now, you've got a coding task. Well, an agentic
- [13:01] assistant might be just what you need. But if an AI agent offers to fix your laptop autonomously
- [13:07] with today's models, well, maybe at least ask it to show its work first.
