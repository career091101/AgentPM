---
title: "Imagine an AI that doesn't just chat, it clicks buttons."
video_id: "IaJ2jXmljmM"
video_url: "https://www.youtube.com/watch?v=IaJ2jXmljmM"
speaker: "Unknown"
channel: "Unknown"
date: ""
duration: ""
tags: ["AI", "Agents", "Technology", "Development"]
topics: ["AI", "Agents", "Technology", "Development"]
summary: |
  Imagine an AI that doesn't just chat, it clicks buttons
  It books appointments, files tickets, updates records and pings APIs
key_points:
  - "of all, it's hard to see"
  - "is the trouble with compliance"
  - "Covers ai agents concepts and applications"
category: "AI Agents"
confidence_level: "medium"
source: "Founder_Agent_Videos"
retrieved_at: "2025-12-30T10:23:31+09:00"
---

# Transcript: IaJ2jXmljmM

- URL: https://www.youtube.com/watch?v=IaJ2jXmljmM
- Retrieved at: 2025-12-30T10:23:31+09:00

## Text

- [00:00] Imagine an AI that doesn't just chat, it clicks buttons. It books appointments, files tickets,
- [00:06] updates records and pings APIs. It's not a chatbot anymore. It's a doer.
- [00:14] And that's agentic AI.
- [00:20] And here's the kicker. The biggest risk isn't just what it thinks, it's what it does. Especially
- [00:27] when shadow AI pops up outside the lines.
- [00:36] If security and governance live on different islands, that doer can outrun your oversight in
- [00:42] seconds. So we need one cockpit, one radar, one living picture of risk that follows
- [00:48] every move an agent makes. Quick pit stop. What's shadow AI and why should we
- [00:55] care? Shadow AI is the unofficial AI your team spin up to get things done with no tickets, no
- [01:02] approvals and no paper trail. Think of it as the well-meaning intern who quietly built a
- [01:08] production app on a lunch break. It starts as a tiny helper, a script here, a model there, an
- [01:14] agent wired to a SaaS tool. And suddenly it's talking to customer data. Calling third-party
- [01:21] APIs and writing to systems nobody is officially tracking. Why is this a big deal?
- [01:28] Well, first of all, it's hard to see. It's hard to see if people
- [01:35] don't know a robot helper exists. They can't keep it safe. Imagine a new puppy in the house that no one
- [01:41] told your parents about. No leash, no food bowl and doors left open. The puppy can run outside or chew
- [01:48] things. Well, hidden tech can run outside too. Second, it's easy to
- [01:55] leak. Some helpers copy and paste things or use loose keys like
- [02:01] passwords. If those aren't protected, private info can slip out. Think of writing your home address
- [02:08] on a balloon and letting it go. Anyone can read it. We want the balloon tied down.
- [02:15] Third is the trouble with compliance.
- [02:23] Teams have to show we follow the rules. If there is no record of what the helper did, it's like
- [02:29] turning in homework with no name and no steps shown. When the teacher, the auditor, asks, "How did
- [02:35] you get this answer?", you need to show your work. And fourth, there's too much access.
- [02:43] Giving a helper every permission just for now is like giving a friend the keys to your whole house
- [02:49] when they only need it to water one plant. If something goes wrong, they can open every door. We
- [02:56] should give the smallest key that does the job. And five, messy incidents tend to
- [03:02] happen. When a hidden helper breaks, people don't know who owns it, what
- [03:09] it touched or how big the mess is. That's like spilling paint and not knowing which room it came
- [03:15] from. Cleanup takes longer because you're searching for every room. And last is about
- [03:22] what you do, instead. You need to tell someone before you add a new
- [03:28] helper. Write down what it can do and what it can't do. Give it only the keys it needs. Keep a
- [03:34] small log of what it did, like a chore chart. So if something spills, you can clean it up fast.
- [03:41] All right, now back to our flight plan. Think air traffic control for AI.
- [03:48] First, you see every aircraft, including the unscheduled ones, continuously discover
- [03:55] shadow agents lurking in any reports, cloud projects and embedded systems and pull them under
- [04:01] oversight automatically. Then stress test the plan with automated red teaming.
- [04:08] Probe for prompt injection, data leakage, tool misuse and brittle configurations before
- [04:14] attackers do. Next, you enforce runtime policy: least privilege tool access,
- [04:21] guardrails on inputs and outputs, and active monitoring for risky data moves. Everything tied
- [04:28] back to a single re ... risk register both security and governance can act on.
- [04:33] Finally, you will use automated logging and controls to generate actionable evidence for
- [04:40] every AI action. And that's the shift: from scattered
- [04:46] checklist to one control plane for agentic AI. You discover,
- [04:56] assess; then you govern, you secure,
- [05:03] and last, you audit. In one
- [05:10] continuous loop. Do this well and you don't just cut
- [05:17] incidents, you speed up safely. Right now, the fastest way to scale AI is the safest way.
- [05:23] Unify how you see risk. Unify how you control it, and keep your agent honest every step of the
- [05:30] way. All right, buckle up and let's see where this gets real in two use cases: one in healthcare
- [05:37] where AI meets patients, and the other in the public sector where it serves citizens. The first
- [05:44] use case is about how AI enables patient care, and specifically why guardrails do matter.
- [05:51] Imagine the following scenario. So regular afternoon clinic slot. The patient sits down, a
- [05:57] little anxious with a list of symptoms on their phone. The room is calm. No frantic typing, no
- [06:04] screen between them and the clinician, just a small consented mic on the table and the
- [06:09] clinician's full attention. The conversation feels unhurried. The clinician asks follow-up questions,
- [06:16] makes eye contact and reflects key points back in plain language. The patient notices the
- [06:22] difference. They don't have to repeat themselves, and they actually feel heard. Behind the
- [06:28] calm, the agent is working quietly. As the patient
- [06:35] talks, it turns the dialog into a draft note. Double checks facts against the chart, flags.
- [06:41] anything that doesn't line up, proposes orders, lines up the follow-up, and prepares a friendly
- [06:47] after-visit summary. Nothing is final without the clinician's approval, but the busy work is already
- [06:54] handled. To the patient, it feels like the system finally got out of the way so the human care
- [07:00] could come through. Here are five things that actually happen under the hood and how
- [07:07] things stay safe. First, the agent turns the conversation into a tidy,
- [07:13] clinical note, including history, meds,
- [07:20] allergies, the assessment, and because it was evaluated before rollout, for accuracy and
- [07:26] faithfulness. It knows when not to over-summarize, anything uncertain is clearly flagged for a quick
- [07:32] human review, so the record stays trustworthy. Second, when the agent hears
- [07:39] Metformin 1000mg, but the chart actually shows 500mg, it raises a
- [07:45] clear mismatch for the clinician to confirm or fix. And because
- [07:52] it only has read-only least-privilege access, it can compare facts and draft a correction, but
- [07:59] cannot silently change the medication list on its own. Third, before any order
- [08:06] is placed, the agent runs drug and allergy checks and prepares everything as a draft.
- [08:16] While governance policies require a human in the loop, ferments and procedures and log any
- [08:22] exception with the reason, so speed never outruns clinical safety. Fourth, the agent
- [08:28] pre-stages the follow-up appointment and referral
- [08:35] paperwork and prior authorization with one-tap approvals, and each connected tool runs with only
- [08:41] the minimum permission it needs. Documentation can't export bulk records, scheduling can't see
- [08:48] billing, so useful automation doesn't turn into broad access. Developers can implement these
- [08:55] guardrails through APIs, permissions and audit logging frameworks. And five,
- [09:01] a patient-friendly plan with reminders is generated and every
- [09:08] instruction links back to its approved source in the note, making it super easy for staff to verify
- [09:14] or correct in seconds, and ensuring patients leave with guidance that's both clear and auditable.
- [09:21] Our next example dives into the world of citizen services. Think about everyday interactions, simple
- [09:27] tasks that can reveal a lot about user experience and government efficiency. Okay, imagine the
- [09:34] following scene. It's a Saturday morning. A citizen opens the state services app on their phone to
- [09:41] finish two chores at once: file their state taxes and renew a fishing license for the new
- [09:47] season. The interface is simple: one chatbot with optional voice. The tone is calm
- [09:54] and human. The assistant explains what it will do, ask for consent and confirms identity once.
- [10:01] No MESA Forms, no guessing which website is actually the right one.
- [10:07] Behind the com, an agent is working quietly.
- [10:16] It understands the request, pulls only the records it needs, fills in the blanks, warns about anything
- [10:22] risky and prepares the final steps for approval. Nothing is submitted or paid without the citizen's
- [10:29] okay. To the citizen, it feels like the system finally got out of the way so they can just get
- [10:35] things done. Let's take a look at the five things that actually happen under the hood and how it
- [10:41] stays safe while they happen. First, the assistant confirms identity
- [10:50] and asks for consent to access specific records for taxes and licensing, then limits its own reach
- [10:57] to just those systems so it can answer the questions without dipping into unrelated data.
- [11:03] This keeps the task focused and protects privacy by design. Second, the agent
- [11:10] retrieves last year's filing, current employer reported income and payment history.
- [11:19] And for licensing, it checks residency, prior license status, and any required education or
- [11:25] catch limits. The assistant shows what sources it used in plain language, so the citizen can see
- [11:32] where the information came from and correct anything that looks off. Third, the agent
- [11:38] prepares a tax summary with
- [11:45] line items, credits and estimated refund or amount due. And for the fishing license, it prefills the
- [11:51] renewal form and explains any new rules for the upcoming season. Key choices are highlighted and
- [11:58] explained in simple terms, and anything uncertain or unusual is flagged for the citizen to review
- [12:04] before moving on. Fourth, when the citizen is ready to submit and pay, the agent
- [12:11] uses least-privilege access to create a filing and a license renewal draft,
- [12:21] then calls the payment system only with the minimal details needed to process the transaction.
- [12:27] Prompts and outputs are filtered to prevent personal data from leaking to the wrong place, and
- [12:32] risky tool calls are blocked and logged automatically. And finally, after
- [12:39] the citizen approves, the filings are submitted. Receipts
- [12:46] are issued and reminders are set for future deadlines. The system records what was accessed,
- [12:52] which rules were applied, the versions of the models used and what the citizen approved,
- [12:57] producing an audit trail that logs every action and ensure full traceability. In the end, this
- [13:04] isn't about showy demos or shiny dashboards. It's about running AI that actually gets work
- [13:11] done safely, predictably and without creating tomorrow's crisis. Agents don't just
- [13:17] chat anymore, they act. They click buttons. They
- [13:24] move data. And they spend
- [13:31] money. That means the real risk isn't what they say, it's what they
- [13:38] do. If you can't see those actions, test them, control them and prove them, you're flying fast
- [13:45] in fog. Here's the reality: shadow AI over here
- [13:53] will show up whether you plan for it or not. Visibility isn't optional; it's oxygen. You
- [14:00] have to discover everything, especially the tools no one officially approved. Then make red
- [14:07] team by default your new normal. So prompt tricks and over-permission agents get caught in
- [14:13] rehearsal, not splashed across headlines. Least privilege is your seatbelt. Every
- [14:20] agent gets only the keys it needs, nothing more. When something fails, the damage stays small,
- [14:26] understandable and fixable. Pair that with the live monitoring, and mystery outages turn into
- [14:33] quick recoveries instead of week-long investigations. And remember, evidence beats
- [14:40] promises every time. If you can show which data was used, what rules fired, who approved and
- [14:46] what version ran, audits take minutes, not months. That's how you earn trustâ€”from patients, citizens,
- [14:53] clinicians and caseworkers who just want systems that stay calm when things get hard. For
- [15:00] healthcare, the win is human. More eye contact, fewer clicks, safer orders, cleaner
- [15:07] handoffs. For the public sector, the win is trust. Clear guidance, faster service, fewer fraud
- [15:14] losses and records that hold up under pressure. Here's the move: bring security
- [15:22] and governance into one cockpit. Run the loop
- [15:28] continuously. Discover, assess, govern, secure, audit. And do it the same way every
- [15:35] time. You won't slow down. You'll go faster because you're safer. That's how agentic AI
- [15:42] grows up, and how we keep control of the systems that now act in our name.
