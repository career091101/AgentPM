---
title: "Transcript: ZHCB09O6zUk"
video_id: "ZHCB09O6zUk"
video_url: "https://www.youtube.com/watch?v=ZHCB09O6zUk"
speaker: "Unknown"
channel: "Unknown"
date: ""
duration: "00:12:37"
tags:
  - "AI"
  - "Agents"
  - "LLM"
  - "Interview"
topics:
  - "AI Agents"
  - "Large Language Models"
summary: |
  動画の内容を分析中...
key_points:
  - "AI and technology discussion"
  - "Industry insights"
  - "Future perspectives"
category: "Technology"
confidence_level: "high"
---

# Transcript: ZHCB09O6zUk

- URL: https://www.youtube.com/watch?v=ZHCB09O6zUk
- Retrieved at: 2025-12-30T11:23:52+09:00

## Text

- [00:00] Artificial intelligence may feel like some brand-new tech trend, but the truth is AI has been
- [00:05] evolving for over 70 years. From simple math puzzles to today's powerful neural networks, each
- [00:11] generation built on the previous one. Let's take a look at where we've been and where we might be
- [00:17] going with this two-part AI series, beginning with A Brief History of AI.
- [00:24] Let's start our tour of AI with a guy named Alan Turing, who back in
- [00:30] 1950, proposed what became known as the Turing Test. Now, Turing is known as the father
- [00:37] of computer science. So, the guy did a lot. And one of his contributions was this as a way to
- [00:43] measure if the a computer was really intelligent or not. So, this is how the Turing Test works. You have
- [00:50] a human subject and they're separated it by a wall. They can't see who it is. They're typing on a
- [00:56] keyboard, and they're gonna communicate with either an a computer or another
- [01:03] person on the other side of this. And if they're typing messages and getting responses back with
- [01:09] these two things, if this person cannot tell if they're talking to another person or a computer,
- [01:15] then we will judge that this thing is considered to be intelligent. So that was what he proposed
- [01:21] with this. And that was the gold standard that was taught to me back when I was in undergrad, riding
- [01:25] my dinosaur to class. This is how we measured things, and this is where all of that stuff
- [01:30] started off. The term AI actually was coined a little bit later in 1956, and
- [01:37] then we started really progressing along this timeline.Ah. Back in the late, ah, 50s, there was a
- [01:44] programing language that came out called Lisp. And Lisp was for short for list processing. And in
- [01:50] my early days of AI programming, this is what we used. So, that was back in the the early 80s. That
- [01:57] was really still considered to be the predominant way you you did things with AI. Now remember, I said
- [02:04] programming. Our modern stuff isn't so much programmed as it is learning and will come to that
- [02:09] in a few minutes. But Lisp, ah, interestingly enough, was first implemented on an IBM 704
- [02:16] system. So, IBM was back there, ah, in those very early days, and it relied very heavily on this notion of
- [02:23] recursion, which is something that doubles back on itself. Ah. It was very complicated to program in. But
- [02:29] think about it this way if you don't know what recursion is, I I saw a definition that said the
- [02:34] definition of recursion is c recursion. So again, the thing doubles back on itself. It gets very
- [02:41] complicated really quickly, but it can also be very powerful and very elegant if you do it right.
- [02:46] But if you wanted to change and make your system smarter, you had to go back in and write more code.
- [02:52] This was programming. Now, in ah, in later in the 60s, we came out with something called ELIZA.
- [02:58] And ELIZA was really the first, ah, chatbot if you wanna think of it that way, ah, well
- [03:05] before the chatbots of today, and not nearly as sophisticated. It was designed to kind of be
- [03:10] conversational and it talked to you very much like a psychologist would. So, it would ask you, you know,
- [03:17] "How are you doing today?" You would respond and whatever you responded with, it would do the
- [03:21] standard kind of "And how do you feel about that?" and, and go with those kind of of responses. But it
- [03:27] gave us the first sense of a system that felt like it was understanding us. Now, it it also
- [03:33] did, ah, some crude version of natural language processing. So you could put your your words not
- [03:40] just in specific commands, but you could actually put it in a way that you could express yourself.
- [03:45] And people started getting the sense that they were talking to an intelligent being. In the 70s
- [03:51] then, we started having a different programing language that people started to, to glom on to, for
- [03:56] doing AI programming, and ah I I really began ah to start using it in the 80s. And the the name
- [04:03] of the language is called Prolog. It was a short for programming in logic. And the idea was instead
- [04:09] of having these recursive systems that that we had with Lisp, with Prolog, we had a bunch of rules.
- [04:15] And you would set down a whole bunch of rules, maybe relationships or things like that, and then
- [04:20] have it run inferences against those things. But again, with both of these systems, one of the major
- [04:26] hallmarks was if you wanted to make your system more intelligent, add more capability to it. You
- [04:31] had to go back and add more code. So you were programming these systems. They were not really
- [04:36] learning in the in the sense that we think of it today.Ah. Then in the 80s, this is when we started
- [04:42] having a boom in the area of expert systems. The idea was that we could have systems that would
- [04:49] learn a certain amount of things. We could put certain kind of constraints in it, and then it
- [04:53] would be able to figure out ah certain advice that it could give us in particular context. Businesses
- [04:58] were really big on the potential and there was a lot of hype, a lot of expectation, but it never
- [05:05] really delivered on that expectation, not in the big way that everybody was thinking. So, this kinda
- [05:11] went through ah, ah, if if people were getting a little bit interested. Then they started getting a
- [05:16] little less interested when they saw that the expert systems were kinda brittle. They were not
- [05:20] able to really be malleable and learn as quickly as we'd like them to. Then there was a big
- [05:26] milestone that occurred in 1997. IBM built an AI system called Deep Blue.
- [05:33] And what Deep Blue did was for the first time in history, we had a computer that beat the che the best
- [05:40] chess player in the world, Garry Kasparov. Now, it had been thought that you could write a computer
- [05:45] program that would be able to beat an average chess player, maybe even a very good chess player.
- [05:51] But to overcome the ah intelligence, the expertise, the planning skills, the strategy,
- [05:58] the creativity, the just sheer genius of what it would take to be a chess grandmaster, it was
- [06:04] thought no computer would ever be able to do that. Well, again, that happened in 1997. That was
- [06:09] actually a a good while back. And when it happened, it really signaled again a resurgence
- [06:16] in the thoughts around AI and what this thing might be able to do. Then, ah, we moved on to
- [06:23] in the in the 2000s on. Now, this technology had actually been around in research for a
- [06:29] while, but it's when it really started to catch people's imagination that we started to see the
- [06:36] growth of machine learning and deep learning algorithms, where machine learning was now doing
- [06:41] pattern matching and deep learning was simulating human intelligence through neural networks. So, this
- [06:48] thing then started to grow across. And in fact, we're still using that technology today as
- [06:53] the basis for how we're doing AI. But this was a big departure from the Prologs and the Lisps
- [06:58] where we were programing a system. In this case, the system was learning. We would show it a lot of
- [07:03] different things and then ask it to predict what the next thing was, or I show it a bunch of things
- [07:09] and ask it to tell me which one doesn't belong in this group. So it was pattern matching on steroids.
- [07:15] That was machine learning, and it was learning through seeing these patterns and recognizing
- [07:20] them. But it could do it on a massive scale that would be very hard for humans to be able to
- [07:25] accomplish. Then we took machine learning and deep learning capabilities, and there was another huge
- [07:30] milestone that happened in 2011, when the TV game show, ah, IBM used a computer called
- [07:37] Watson to play Jeopardy! And Jeopardy! is a game, if you're not familiar with it, asks a lot of
- [07:44] trivia questions in a lot of different areas. This was actually a very difficult problem to solve
- [07:50] for a number of reasons. One, because the questions come in natural language form, and the the way we
- [07:55] express ourselves with language can be varied, ah, in the great degree. There are things that we use
- [08:02] like puns and idioms, figures of speech. If I say that, ah, it's raining cats and dogs outside, you know
- [08:08] I don't mean that that there are small animals falling out of the sky. But those are the kinds of
- [08:13] things that go into the clues that are in Jeopardy! And we had to have a computer that would
- [08:18] understand those vagaries of human language and understand what to take literally and what not to.
- [08:24] You couldn't just program rules or, ah, some sort of list processing that would know and anticipate
- [08:31] all of those. You can't even list all of those that you know, those idioms. So this was a really
- [08:36] hard problem. IBM had, ah, a, a case where we use our Watson computer to play against two of the
- [08:43] all-time Jeopardy! champions. That was again in 2011, and we beat them both, ah, three nights in a row.
- [08:49] This was another big milestone in AI. And it's interesting to me that this actually came along
- [08:56] much later than winning at chess, ah, where, ah, it's because there's so much variability in this and
- [09:03] the subject matter is so broad. So you had to be an expert in this, this system, and it couldn't
- [09:10] just be going out to the internet and querying all these things. It had to be coming up with
- [09:14] answers very quickly because, you know, if you've ever seen the game show Jeopardy! if you don't
- [09:19] answer quickly, then someone else will answer it for you. And, if you answer if you're the first one
- [09:23] that answers and you're wrong, then you lose points. So you had to calculate how confident am I
- [09:29] in my answer? So, this was, ah, a lot of really important work that showed the possibility again
- [09:35] for AI, after there had been a period of kind of disappointment and people hadn't really seen much
- [09:41] come out of all of this. Around about 2022, we had another major inflection point where AI
- [09:48] suddenly got real for a lot of people, and that was when we introduced this idea of generative AI
- [09:55] based on foundation models. And here is where we started to see the rise of the chatbots. And
- [10:00] that's what got everyone's imagination, because now we were seeing not a a fairly stiff natural
- [10:06] language processor like ELIZA was. It was very limited in terms of what it could talk about. Now
- [10:12] we had something that acted like an expert, and it would do all kinds of amazing things. seemed to
- [10:17] know the answer to everything, be very conversational. And this is when for a lot of
- [10:22] people, it felt like AI finally got real. And it generates more than just text. You know, we could
- [10:28] have it write a report for us. We could have it summarize emails or documents, things like that.
- [10:33] Also, we could use it to generate images or generate sounds And from that we could also
- [10:39] generate deepfakes. So I could have something that is an impersonation of a real person that looks
- [10:45] realistic enough that it would fool someone. So, a lot of good, a lot of bad, a lot of all of this
- [10:51] happening, but a lot of excitement. And as I said, for a lot of people, this is when AI suddenly
- [10:58] got real even though it had been happening for a long time. And then where are we going with this?
- [11:04] Well, we're already seeing 2025 I think has been the year of the agents. This is when we start
- [11:10] seeing agentic AI coming in, where we're taking an AI and giving it more autonomy, where it's able
- [11:17] to operate on its own. We give it certain goals and things that it's supposed to accomplish, and
- [11:22] then it uses different services in order to accomplish those things for us. So. we're gonna
- [11:27] see a lot more of this happening as well. And now where does the future head for us? Well, the short
- [11:33] version is if all of this is a sort of artificial, narrow intelligence where the intelligence is
- [11:39] specific in particular areas, things that it can do, well, the next thing to be would be artificial
- [11:45] general intelligence, where we have something that is as smart or smarter than a person in
- [11:50] essentially every area that we could imagine. And then the next area would be artificial superintelligence,
- [11:56] where we have something that far exceeds human capabilities in terms of
- [12:01] intelligence across a wide variety of things. So you can see with this, basically, we've it's been a
- [12:07] what felt like a snail's pace of progress as we move from these early days until we started
- [12:13] adding more and more capabilities with machine learning. And then we started introducing
- [12:18] generative AI, and now we're off to the moon. For decades, it felt like AI was
- [12:25] just a pipe dream. Then suddenly it seems like AI can do everything. But can it really?
- [12:32] Well, in the next video, in this two-part series, we'll take a look at what are the limits of AI,
- [12:37] both in terms of what it can do and what it can't do, at least not yet.
