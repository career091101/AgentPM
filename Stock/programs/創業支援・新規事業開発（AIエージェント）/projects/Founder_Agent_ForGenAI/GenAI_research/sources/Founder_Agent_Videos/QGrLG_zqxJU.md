---
title: "Transcript: QGrLG_zqxJU"
video_id: "QGrLG_zqxJU"
video_url: "https://www.youtube.com/watch?v=QGrLG_zqxJU"
speaker: "Unknown"
channel: "Unknown"
date: ""
duration: "00:17:56"
tags:
  - "AI"
  - "Agents"
topics:
  - "AI Agents"
  - "Team Building"
  - "Data"
  - "Automation"
summary: |
  動画の内容を分析中...
key_points:
  - "AI and technology discussion"
  - "Industry insights"
  - "Future perspectives"
category: "AI Agents"
confidence_level: "high"
---

# Transcript: QGrLG_zqxJU

- URL: https://www.youtube.com/watch?v=QGrLG_zqxJU
- Retrieved at: 2025-12-30T10:47:24+09:00

## Text

- [00:00] Imagine you are buying a car.
- [00:06] And your car does not have any dashboard. So, what will happen?
- [00:14] Similarly, when you buy a storage array, you need to have an, uh, a very world-class
- [00:20] observability tool because buying a storage without observability is like driving a car
- [00:27] without a dashboard. You may keep moving, but you do not know when you are going to run out
- [00:34] of fuel, when you-your car is going to overheat, or you are headed for a
- [00:41] breakdown. Now, having said that, now that uh, I have established that we
- [00:48] need a world-class observability tool when you buy a storage box. What are the critical
- [00:55] operational questions that this tool can answer for you? And that I call it the seven
- [01:02] pillars of observability. So what are those pillars? Number one:
- [01:08] availability. Is my uh,
- [01:15] storage infrastructure available? Does it have enough availability for my applications? This is
- [01:20] the very basic question a storage admin needs to know. Hence that is the first pillar.
- [01:27] Second: performance. Is my
- [01:33] storage uh, infrastructure performing well? Does it give enough resources to my applications? How is
- [01:40] it doing with respect to latency and IOPS? These are the critical questions that a world-class
- [01:46] observability tool can answer once the storage array is configured. Now I moved into a very
- [01:52] critical one. The third one: capacity. Do
- [01:59] I have enough capacity now? What is that I was capacity I was using in the past? When is
- [02:06] my uh, my box running going to run out of capacity? How can I order more capacity when it's going to run
- [02:11] out? Next, and the very important pillar in the
- [02:18] recent days has become security. Is my storage infrastructure secure? Do I h, do I have
- [02:25] enough safety against the ransomware attacks? Is my security posture configured correctly? How do I
- [02:31] know this tool can answer those questions and make me safe? The next one:
- [02:38] inventory. What does my inventory look like? How many block storage devices I have? How many file
- [02:45] storage devices I have? How many of them are hyperconverged? All these critical questions so that I
- [02:51] can plan my storage infrastructure better can be answered when I know what my inventory has,
- [02:57] right? Cost. What is the current cost I am paying for my
- [03:04] storage infrastructure? How much is my cost going to escalate? Is my cost going to go out of uh,
- [03:11] a limit? Only my world-class observability tool can help, and hence this is a very critical part.
- [03:20] And last but not the least, sustainability.
- [03:29] Is my storage infrastructure doing well with respect to power consumption? What is
- [03:35] it taking for carbon emissions? Is my infrastructure aligning with my carbon goals?
- [03:42] What does the data say? Now, this is where my storage uh, observability tool will
- [03:49] help align my box. Now, having answered all the critical operational
- [03:56] questions via seven pillars of observability, let's look at use cases where the observability tool is a
- [04:02] must-have for storage boxes. The use cases that can help the admin to manage your storage
- [04:09] infrastructure better. What are those use cases? End-to-end visibility. In a
- [04:16] storage infrastructure, there are many components, from the host to switches to the storage box. And you
- [04:22] want to know all the paths from your applications and till the storage, what's exactly the
- [04:27] thing. So it helps teams understand how storage systems, applications and infrastructure are
- [04:32] interconnected to eliminate b-blind spots. Next, proactive issue
- [04:38] detection. By monitoring health performance and anomalies in real time, this enables early
- [04:45] detection and faster resolution of if-issues before the impact. Right?
- [04:53] Performance optimization. For a big time a storage admin has a problem: How is my
- [04:59] latency? How is my IOPs? How is my throughput? Now, if you have world-class observability tool, it can
- [05:06] provide insights into the workloads, bottlenecks and utilization patterns, ensuring optimal
- [05:12] performance and resource allocation. Next, capacity planning and cost
- [05:18] management. How am I doing with respect to capacity? With a world-class storage observability
- [05:24] tool, the usage trends and predictive analytics, a storage admin can plan the storage
- [05:31] growth, avoid overprovisioning, which is critical, and reduce unnecessary costs.
- [05:39] Right? In a data center today, incommon, data centers, they're generally multi-vendor
- [05:46] and hybrid environments. A world-class storage observability tool simplifies management across
- [05:51] different storage vendors and if whether it is on prem or cloud,
- [05:59] ensuring consistency and reducing complexity. It improves
- [06:05] reliability by continuously monitoring, reducing the downtime risks,
- [06:12] and enhances resilience against failures because of multiple upgrades or multiple
- [06:19] security threads. With all this, what you have in your hand is data-driven
- [06:25] decision-making. A world-class ob ... storage observability tool translates raw storage metric
- [06:31] into actionable insights
- [06:38] so that it can empower IT leaders to align their storage strategy with
- [06:45] their upcoming goals. I will go ahead and talk about the role of
- [06:52] AI in data storage observability, right? AI plays a huge part when
- [06:59] it comes to ease of storage observability. Observability is about managing
- [07:06] the data the storage array produces. And the entire infrastructure produces exabytes of data.
- [07:12] It's manually impossible to observe the data with m ... with a manual
- [07:19] way. Hence, the storage admins leverage AI in order to make storage observability and
- [07:25] management better.How, how does it help? Let's, let's go to the use cases. The first one: anomaly
- [07:32] detection.
- [07:38] AI algorithms in observability tools can learn normal storage behavior and automatically
- [07:45] detect unusual patterns. Example, sudden latency spikes, abnormal I/O or capacity
- [07:52] anomalies before they become critical issues. Second:
- [07:58] predictive analytics,right?
- [08:05] AI can forecast storage growth, performance trends
- [08:12] and proactively do capacity planning, enabling
- [08:18] proactive management and risk mitigation. Third
- [08:24] is root cause analysis. A pain
- [08:31] point for all storage admins. Instead of manually sitting through logs and
- [08:38] metrics, storage admins can leverage artificial intelligence, which can correlate
- [08:45] signals and across the infrastructure layers to
- [08:52] quickly pinpoint to the root cause behind the performance issues
- [08:58] or availability issues. And thus, it can help make storage
- [09:05] admins' life a lot simpler. Intelligent automation.
- [09:17] We all want our storage boxes to be plug and play, and AI can help us achieve that. AI can recommend
- [09:24] or even trigger actions based on the
- [09:30] data, observability data, and do load balancing,
- [09:37] or cache optimization without any human intervention, thus
- [09:43] reducing downtime and any manual operational effort.
- [09:51] Now, another big pain point for storage admins is a lot of noise.
- [09:58] All the storage boxes produce a lot of alerts because of all the components inside it. And in
- [10:05] large environments, storage admins are flooded with alerts. Here, AI comes to your rescue.
- [10:12] AI can filter the false positives and
- [10:18] prioritize what is critical and surface
- [10:25] out only what truly matters, thus achieving noise reduction.
- [10:32] Workload optimization. Are my
- [10:39] workloads running in the most efficient manner in a storage box? Well, it's very
- [10:46] difficult to figure out in a manual way, but observability tools with AI can analyze
- [10:53] user usage patterns and can suggest optimal data placement across
- [11:00] the entire storage box to-to ensure that the tiering is in
- [11:07] there to balance cost and performance. With all this in place,
- [11:15] AI is also learning from the data that the storage boxes are producing,
- [11:21] enabling in what I call as self-learning insights. So over the time, AI
- [11:28] adapts to the unique capacity characteristics of your storage box
- [11:35] and it then uses those characteristics of your workloads and storage systems
- [11:42] in order to improve the observability outcomes. With, now that we have gone through the role of
- [11:49] AI in storage observability, let's see about how agentic AI Ops
- [11:57] can help in storage observability much better. Now, before going there, I would
- [12:04] like to talk about four stages of storage observability, right? Now, first is
- [12:11] monitoring, the basic monitoring of a storage box. Second
- [12:17] is when I start observing the data that the storage box
- [12:24] produces and giving insights to the admin.
- [12:31] Third one is AI Ops, that I leveraged AI in order to make the storage
- [12:38] observability experience a lot better for the admin. And then, finally,
- [12:45] agentic AI Ops, where I have asked few agents
- [12:52] to do the work for me, which with normal AI I was unable to do. Now
- [12:59] what are those use cases where agentic AI Ops can take the
- [13:06] observability experience a notch better, right? Now, the first one: autonomous
- [13:13] monitoring and response, right? Now, what does this
- [13:19] mean? Based on the data that the observability tool is getting from the storage, it
- [13:26] can start responding real time to the storage admin. I am getting a message
- [13:33] that my drive is not available. So what do I do? What is my action?
- [13:40] So it can, in a chatbot kind of manner, provide immediate response and thus help storage
- [13:47] admins' life a lot easier. Second, a goal-driven response,
- [13:53] or goal-driven
- [14:00] operations, I must say. An admin can define the goals that
- [14:07] are needed from the observability, and when the goals are reached, the ... the relevant
- [14:14] agent starts responding with the admin, hence achieving the goal-driven operations. For
- [14:20] example, if he needs a performance latency less than
- [14:27] 10seconds. So every time it exceeds 10 seconds, it goes and autocorrects
- [14:34] and thus, helping the admin, not having to sit through and monitor through thousand alerts and
- [14:40] doing those actions, rather trusting the agent to go see the goal and take the necessary
- [14:47] actions. Right? Now, next and the most critical and which is currently
- [14:55] not appreciated by all the users, is self-healing infrastructure. Now,
- [15:02] a storage box is a complicated piece of hardware with lots of components in it,
- [15:09] and lots of software that interact with each other to give the best data storage experience. So
- [15:15] it is going to come up with issues regularly. When the issues come up, admins run around in a team to
- [15:22] figure out how do I resolve the issues? But, if
- [15:29] I can, if I am able to outsource it to agents and then they can
- [15:35] self-correct themselves, I, we're basically achieving self-healing infrastructure. So whenever,
- [15:41] let's say, for example, there is a storage drive. And that failed, right? What can I do? A
- [15:48] controller went for a toss. What can I do? A back plane had some issue. How can I
- [15:55] heal it? So, all the actions and then automated manner,if it, it goes
- [16:02] for a toss, how can I self-heal them so that I can provide a best storage
- [16:08] experience for my admin. And last, and the biggest pain point, which is still not
- [16:15] solvable by AI completely, where agentic AI can really be a lifesaver is uh, it's in lifecycle
- [16:21] management. Now, a storage admin who has 50 to 100 storage
- [16:28] arrays has to regularly upgrade patches and the new releases, the new security
- [16:35] fixes. And every storage vendor has a different lifecycle, different release
- [16:42] timelines. So, today, admins maintain everything in an Excel sheet,
- [16:48] manually, interact with their team: what-what time it is coming up, then they have a
- [16:55] downtime, they have to communicate. And it is a management nightmare. Rather, you can outsource
- [17:02] all of it to agents. The observability tool can release the agents based on
- [17:09] the certain storage boxes, and they can achieve a complete lifecycle management
- [17:16] experience, where the agents will automatically track the amount of arrays, their release
- [17:22] timelines, and depending on each of the release timelines, they will take the necessary upgrade
- [17:29] actions and send an email once that is
- [17:36] done. If the upgrade has not taken place, they can send a communication
- [17:42] on wh-what the next upgrade should be and how it can be achieved, providing
- [17:49] a complete automated way of asset lifecycle management, eliminating hours and hours of manual uh,
- [17:56] effort that the storage admin puts today. And here agentic AIOps can be really a lifesaver.
