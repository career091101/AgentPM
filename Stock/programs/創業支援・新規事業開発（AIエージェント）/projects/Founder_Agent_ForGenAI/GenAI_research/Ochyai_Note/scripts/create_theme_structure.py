#!/usr/bin/env python3
"""
è½åˆãƒãƒ¼ãƒˆ ãƒ†ãƒ¼ãƒåˆ¥ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ (T008-4)

ç›®çš„:
- Analysis/Pattern_A_Themes/ é…ä¸‹ã«ãƒ†ãƒ¼ãƒåˆ¥ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
- å„ãƒ†ãƒ¼ãƒã®README.mdã¨article_list.mdã‚’ç”Ÿæˆ
"""

from pathlib import Path
from datetime import datetime
import json
import re
from typing import Dict, List, Tuple
from collections import defaultdict

# ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹
BASE_DIR = Path("/Users/yuichi/AIPM/aipm_v0/Stock/programs/å‰µæ¥­æ”¯æ´ãƒ»æ–°è¦äº‹æ¥­é–‹ç™ºï¼ˆAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰/projects/Founder_Agent_ForGenAI/GenAI_research/Ochyai_Note")
ARTICLES_DIR = BASE_DIR / "full_run" / "articles"
ANALYSIS_DIR = BASE_DIR / "Analysis" / "Pattern_A_Themes"

# ãƒ†ãƒ¼ãƒå®šç¾©ï¼ˆ8ãƒ†ãƒ¼ãƒï¼‰
THEMES = {
    'Art_Media_Expression': {
        'ja': 'ã‚¢ãƒ¼ãƒˆãƒ»ãƒ¡ãƒ‡ã‚£ã‚¢è¡¨ç¾',
        'en': 'Art, Media & Expression',
        'description': 'ã‚¢ãƒ¼ãƒˆã€ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¢ãƒ¼ãƒˆã€æ˜ åƒè¡¨ç¾ã€è¦–è¦šæ–‡åŒ–ã«é–¢ã™ã‚‹è€ƒå¯Ÿ',
        'keywords': ['ã‚¢ãƒ¼ãƒˆ', 'ãƒ¡ãƒ‡ã‚£ã‚¢ã‚¢ãƒ¼ãƒˆ', 'æ˜ åƒ', 'è¡¨ç¾', 'ãƒ“ã‚¸ãƒ¥ã‚¢ãƒ«', 'ã‚¤ãƒ³ã‚¹ã‚¿ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', 'å±•ç¤º', 'ä½œå“', 'ç¾è¡“', 'ã‚®ãƒ£ãƒ©ãƒªãƒ¼', 'æ˜ ç”»', 'å†™çœŸ', 'ã‚«ãƒ¡ãƒ©', 'ã‚»ãƒ³ã‚µãƒ¼']
    },
    'Digital_Nature': {
        'ja': 'ãƒ‡ã‚¸ã‚¿ãƒ«ãƒã‚¤ãƒãƒ£ãƒ¼',
        'en': 'Digital Nature',
        'description': 'è¨ˆç®—æ©Ÿè‡ªç„¶ã€ãƒ‡ã‚¸ã‚¿ãƒ«ã¨ç‰©ç†ã®èåˆã€è‡ªç„¶ã¨ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã®å…±å­˜',
        'keywords': ['ãƒ‡ã‚¸ã‚¿ãƒ«ãƒã‚¤ãƒãƒ£ãƒ¼', 'è¨ˆç®—æ©Ÿè‡ªç„¶', 'ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒŠãƒ«', 'ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', 'æ‹¡å¼µç¾å®Ÿ', 'AR', 'VR', 'ãƒ¡ã‚¿ãƒãƒ¼ã‚¹', 'ãƒãƒ¼ãƒãƒ£ãƒ«']
    },
    'Physicality_Materiality': {
        'ja': 'èº«ä½“æ€§ãƒ»ç‰©è³ªæ€§',
        'en': 'Physicality & Materiality',
        'description': 'èº«ä½“æ„Ÿè¦šã€è§¦è¦šã€ç‰©ç†çš„ãƒãƒ†ãƒªã‚¢ãƒ«ã€ç´ æã¸ã®é–¢å¿ƒ',
        'keywords': ['èº«ä½“', 'è§¦è¦š', 'ç‰©è³ª', 'ãƒãƒ†ãƒªã‚¢ãƒ«', 'è³ªé‡', 'ç´ æ', 'æ‰‹è§¦ã‚Š', 'æ„Ÿè¦š', 'ä½“é¨“', 'ãƒãƒ—ãƒ†ã‚£ãƒƒã‚¯', 'ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³']
    },
    'Urban_Space_Design': {
        'ja': 'éƒ½å¸‚ãƒ»ç©ºé–“ãƒ‡ã‚¶ã‚¤ãƒ³',
        'en': 'Urban & Space Design',
        'description': 'éƒ½å¸‚è¨ˆç”»ã€å»ºç¯‰ã€ç©ºé–“è¨­è¨ˆã€ç’°å¢ƒãƒ‡ã‚¶ã‚¤ãƒ³ã«é–¢ã™ã‚‹æ€è€ƒ',
        'keywords': ['éƒ½å¸‚', 'å»ºç¯‰', 'ç©ºé–“', 'ãƒ‡ã‚¶ã‚¤ãƒ³', 'è¡—', 'ç’°å¢ƒ', 'å ´æ‰€', 'ãƒ©ãƒ³ãƒ‰ã‚¹ã‚±ãƒ¼ãƒ—', 'å…¬å…±ç©ºé–“']
    },
    'AI_Technology': {
        'ja': 'AIæŠ€è¡“ã®é€²åŒ–',
        'en': 'AI Technology Evolution',
        'description': 'äººå·¥çŸ¥èƒ½ã€æ©Ÿæ¢°å­¦ç¿’ã€ç”ŸæˆAIã€æŠ€è¡“çš„ãƒ–ãƒ¬ãƒ¼ã‚¯ã‚¹ãƒ«ãƒ¼',
        'keywords': ['AI', 'äººå·¥çŸ¥èƒ½', 'æ©Ÿæ¢°å­¦ç¿’', 'ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°', 'ChatGPT', 'GPT', 'LLM', 'ç”ŸæˆAI', 'ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ', 'ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«']
    },
    'Education_Research': {
        'ja': 'æ•™è‚²ãƒ»ç ”ç©¶ã®æœªæ¥',
        'en': 'Future of Education & Research',
        'description': 'å¤§å­¦æ•™è‚²ã€ç ”ç©¶ç’°å¢ƒã€å­¦ã³ã®æœªæ¥ã€ã‚¢ã‚«ãƒ‡ãƒŸã‚¢ã®å¤‰é©',
        'keywords': ['æ•™è‚²', 'å¤§å­¦', 'ç ”ç©¶', 'ã‚¢ã‚«ãƒ‡ãƒŸã‚¢', 'å­¦ç”Ÿ', 'æˆæ¥­', 'ã‚¼ãƒŸ', 'è«–æ–‡', 'å­¦ä¼š', 'åšå£«', 'ç­‘æ³¢', 'å­¦ã³']
    },
    'Future_Prediction': {
        'ja': 'æœªæ¥äºˆæ¸¬ãƒ»æŠ€è¡“é©æ–°',
        'en': 'Future Prediction & Innovation',
        'description': 'æœªæ¥äºˆæ¸¬ã€æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ã€ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ã‚·ãƒ•ãƒˆ',
        'keywords': ['æœªæ¥', 'äºˆæ¸¬', '10å¹´å¾Œ', '20å¹´å¾Œ', 'ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³', 'é©æ–°', 'ãƒˆãƒ¬ãƒ³ãƒ‰', 'æŠ€è¡“é©å‘½', 'ãƒ‘ãƒ©ãƒ€ã‚¤ãƒ ', 'å¤‰é©']
    },
    'Social_Structure': {
        'ja': 'ç¤¾ä¼šæ§‹é€ ãƒ»å…¬å…±è²¡',
        'en': 'Social Structure & Public Goods',
        'description': 'ç¤¾ä¼šã‚·ã‚¹ãƒ†ãƒ ã€å…¬å…±è²¡ã€æ”¿ç­–ã€ç¤¾ä¼šèª²é¡Œã¸ã®æè¨€',
        'keywords': ['ç¤¾ä¼š', 'å…¬å…±', 'æ”¿ç­–', 'ã‚·ã‚¹ãƒ†ãƒ ', 'åˆ¶åº¦', 'èª²é¡Œ', 'å•é¡Œ', 'æè¨€', 'ã‚¤ãƒ³ãƒ•ãƒ©', 'å…¬å…±è²¡', 'æ°‘ä¸»ä¸»ç¾©']
    }
}


def extract_date_from_filename(filename: str) -> str:
    """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º"""
    match = re.match(r'(\d{4}-\d{2}-\d{2})', filename)
    return match.group(1) if match else 'ä¸æ˜'


def classify_article(article_path: Path) -> List[str]:
    """è¨˜äº‹ã‚’èª­ã¿è¾¼ã¿ãƒ†ãƒ¼ãƒåˆ†é¡ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ï¼‰"""
    try:
        content = article_path.read_text(encoding='utf-8')
        title_match = re.search(r'^#\s+(.+)', content, re.MULTILINE)
        title = title_match.group(1) if title_match else article_path.stem

        # å…¨ãƒ†ã‚­ã‚¹ãƒˆã‚’å¯¾è±¡ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°
        full_text = f"{title}\n{content}".lower()

        matched_themes = []
        for theme_id, theme_info in THEMES.items():
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
            score = sum(1 for keyword in theme_info['keywords'] if keyword.lower() in full_text)
            if score >= 2:  # 2ã¤ä»¥ä¸Šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒãƒãƒƒãƒã—ãŸã‚‰ãƒ†ãƒ¼ãƒã«åˆ†é¡
                matched_themes.append(theme_id)

        # ãƒãƒƒãƒã—ãªã‹ã£ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not matched_themes:
            # ã‚¿ã‚¤ãƒˆãƒ«ã ã‘ã§ã‚‚å†ãƒã‚§ãƒƒã‚¯
            for theme_id, theme_info in THEMES.items():
                if any(keyword.lower() in title.lower() for keyword in theme_info['keywords'][:3]):
                    matched_themes.append(theme_id)
                    break

        return matched_themes if matched_themes else ['Art_Media_Expression']  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ã‚¢ãƒ¼ãƒˆ

    except Exception as e:
        print(f"âš ï¸  Error processing {article_path}: {e}")
        return ['Art_Media_Expression']


def analyze_articles() -> Dict[str, List[Dict]]:
    """å…¨è¨˜äº‹ã‚’åˆ†æã—ã¦ãƒ†ãƒ¼ãƒåˆ¥ã«åˆ†é¡"""
    theme_articles = defaultdict(list)

    print(f"ğŸ“‚ Analyzing articles in {ARTICLES_DIR}...")

    article_files = sorted(ARTICLES_DIR.glob("*.md"))
    total = len(article_files)

    for idx, article_path in enumerate(article_files, 1):
        if idx % 100 == 0:
            print(f"   Progress: {idx}/{total}")

        date = extract_date_from_filename(article_path.name)
        themes = classify_article(article_path)

        article_info = {
            'filename': article_path.name,
            'date': date,
            'path': article_path,
            'relative_path': f"../../full_run/articles/{article_path.name}"
        }

        for theme in themes:
            theme_articles[theme].append(article_info)

    print(f"âœ… Analyzed {total} articles")
    return theme_articles


def create_theme_folders():
    """ãƒ†ãƒ¼ãƒãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ"""
    print(f"\nğŸ“ Creating theme folders in {ANALYSIS_DIR}...")

    for theme_id, theme_info in THEMES.items():
        folder_path = ANALYSIS_DIR / theme_id
        folder_path.mkdir(parents=True, exist_ok=True)
        print(f"   âœ“ {theme_id}/")

    print("âœ… Theme folders created")


def create_article_list(theme_id: str, articles: List[Dict]) -> str:
    """article_list.mdã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ"""
    theme_info = THEMES[theme_id]

    # å¹´åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    by_year = defaultdict(list)
    for article in articles:
        year = article['date'][:4] if article['date'] != 'ä¸æ˜' else 'ä¸æ˜'
        by_year[year].append(article)

    content = f"""# {theme_info['ja']} - é–¢é€£è¨˜äº‹ä¸€è¦§

**ç·è¨˜äº‹æ•°**: {len(articles)}ä»¶
**æœ€çµ‚æ›´æ–°**: {datetime.now().strftime('%Y-%m-%d')}

## è¨˜äº‹ãƒªã‚¹ãƒˆï¼ˆæ—¥ä»˜é™é †ï¼‰

"""

    # å¹´ã”ã¨ã«ã‚½ãƒ¼ãƒˆã—ã¦å‡ºåŠ›
    for year in sorted(by_year.keys(), reverse=True):
        year_articles = sorted(by_year[year], key=lambda x: x['date'], reverse=True)
        content += f"\n### {year}å¹´ï¼ˆ{len(year_articles)}ä»¶ï¼‰\n\n"

        for article in year_articles:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡º
            title = article['filename'].replace('.md', '').split('_', 1)[1] if '_' in article['filename'] else article['filename']
            content += f"#### {article['date']}: {title}\n"
            content += f"- **ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: `{article['relative_path']}`\n"
            content += f"- **ãƒ•ã‚¡ã‚¤ãƒ«å**: `{article['filename']}`\n\n"

    return content


def create_theme_readme(theme_id: str, articles: List[Dict]) -> str:
    """å„ãƒ†ãƒ¼ãƒã®README.mdã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆ"""
    theme_info = THEMES[theme_id]

    # çµ±è¨ˆæƒ…å ±
    total_articles = len(articles)
    dates = [a['date'] for a in articles if a['date'] != 'ä¸æ˜']
    date_range = f"{min(dates)} ï½ {max(dates)}" if dates else "ä¸æ˜"

    # å¹´åˆ¥é›†è¨ˆ
    by_year = defaultdict(int)
    for article in articles:
        year = article['date'][:4] if article['date'] != 'ä¸æ˜' else 'ä¸æ˜'
        by_year[year] += 1

    # ä»£è¡¨è¨˜äº‹ï¼ˆæœ€æ–°5ä»¶ï¼‰
    top_articles = sorted(articles, key=lambda x: x['date'], reverse=True)[:5]

    content = f"""# {theme_info['ja']} - {theme_info['en']}

## æ¦‚è¦

{theme_info['description']}

## çµ±è¨ˆ

- **è¨˜äº‹æ•°**: {total_articles}ä»¶
- **æœŸé–“**: {date_range}
- **å…¨ä½“æ¯”ç‡**: è¨ˆç®—ä¸­

## ä¸»è¦ã‚³ãƒ³ã‚»ãƒ—ãƒˆ

{theme_info['ja']}ã«é–¢é€£ã™ã‚‹ä»¥ä¸‹ã®ã‚ˆã†ãªæ¦‚å¿µã‚’æ‰±ã£ã¦ã„ã¾ã™ï¼š

"""

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’3ã¤ãšã¤è¡¨ç¤º
    for i in range(0, min(9, len(theme_info['keywords'])), 3):
        keywords_chunk = theme_info['keywords'][i:i+3]
        content += f"- **{'ãƒ»'.join(keywords_chunk)}**\n"

    content += f"""
## ä»£è¡¨è¨˜äº‹ï¼ˆæœ€æ–°5ä»¶ï¼‰

"""

    for idx, article in enumerate(top_articles, 1):
        title = article['filename'].replace('.md', '').split('_', 1)[1] if '_' in article['filename'] else article['filename']
        content += f"""### {idx}. {title}
- **æ—¥ä»˜**: {article['date']}
- **ãƒ•ã‚¡ã‚¤ãƒ«**: `{article['filename']}`

"""

    content += f"""## é–¢é€£è¨˜äº‹ãƒªã‚¹ãƒˆ

å…¨{total_articles}è¨˜äº‹ã®ãƒªã‚¹ãƒˆã¯ [article_list.md](./article_list.md) ã‚’å‚ç…§ã€‚

## æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰

"""

    for year in sorted(by_year.keys(), reverse=True):
        count = by_year[year]
        content += f"- **{year}å¹´**: {count}ä»¶\n"

    content += f"""
## ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰

"""

    for keyword in theme_info['keywords'][:15]:
        content += f"- {keyword}\n"

    content += """
## åˆ†æãƒ¡ãƒ¢

ã“ã®ãƒ†ãƒ¼ãƒã«é–¢ã™ã‚‹è©³ç´°ãªåˆ†æã¯ä»Šå¾Œè¿½åŠ äºˆå®šã§ã™ã€‚

"""

    return content


def create_main_readme(theme_articles: Dict[str, List[Dict]]) -> str:
    """Pattern_A_Themeså…¨ä½“ã®README.mdã‚’ç”Ÿæˆ"""
    total_articles = sum(len(articles) for articles in theme_articles.values())

    # ãƒ†ãƒ¼ãƒåˆ¥è¨˜äº‹æ•°ã§ã‚½ãƒ¼ãƒˆ
    sorted_themes = sorted(
        theme_articles.items(),
        key=lambda x: len(x[1]),
        reverse=True
    )

    content = f"""# è½åˆãƒãƒ¼ãƒˆ ãƒ†ãƒ¼ãƒåˆ¥åˆ†æï¼ˆPattern Aï¼‰

**åˆ†ææ—¥**: {datetime.now().strftime('%Y-%m-%d')}
**ç·è¨˜äº‹æ•°**: {total_articles}ä»¶
**ãƒ†ãƒ¼ãƒæ•°**: {len(THEMES)}ãƒ†ãƒ¼ãƒ

## åˆ†ææ¦‚è¦

è½åˆé™½ä¸€æ°ã®noteè¨˜äº‹ã‚’8ã¤ã®ä¸»è¦ãƒ†ãƒ¼ãƒã«åˆ†é¡ã—ã€å„ãƒ†ãƒ¼ãƒã”ã¨ã®ç‰¹å¾´ã‚„æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æã—ã¦ã„ã¾ã™ã€‚

## ãƒ†ãƒ¼ãƒä¸€è¦§

"""

    for idx, (theme_id, articles) in enumerate(sorted_themes, 1):
        theme_info = THEMES[theme_id]
        count = len(articles)
        percentage = (count / total_articles * 100) if total_articles > 0 else 0
        content += f"{idx}. [{theme_info['ja']}](./{theme_id}/) - {count}è¨˜äº‹ï¼ˆ{percentage:.1f}%ï¼‰\n"

    content += f"""
## ä½¿ã„æ–¹

å„ãƒ†ãƒ¼ãƒãƒ•ã‚©ãƒ«ãƒ€ã«ç§»å‹•ã—ã¦ã€README.mdã¨ article_list.md ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

### ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ 

```
Pattern_A_Themes/
â”œâ”€â”€ README.md                      # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ Art_Media_Expression/          # ã‚¢ãƒ¼ãƒˆãƒ»ãƒ¡ãƒ‡ã‚£ã‚¢è¡¨ç¾
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ article_list.md
â”œâ”€â”€ Digital_Nature/                # ãƒ‡ã‚¸ã‚¿ãƒ«ãƒã‚¤ãƒãƒ£ãƒ¼
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ article_list.md
... (ä»¥ä¸‹åŒæ§˜)
```

## ãƒ†ãƒ¼ãƒå®šç¾©

### 1. {THEMES['Art_Media_Expression']['ja']}
{THEMES['Art_Media_Expression']['description']}

### 2. {THEMES['Digital_Nature']['ja']}
{THEMES['Digital_Nature']['description']}

### 3. {THEMES['Physicality_Materiality']['ja']}
{THEMES['Physicality_Materiality']['description']}

### 4. {THEMES['Urban_Space_Design']['ja']}
{THEMES['Urban_Space_Design']['description']}

### 5. {THEMES['AI_Technology']['ja']}
{THEMES['AI_Technology']['description']}

### 6. {THEMES['Education_Research']['ja']}
{THEMES['Education_Research']['description']}

### 7. {THEMES['Future_Prediction']['ja']}
{THEMES['Future_Prediction']['description']}

### 8. {THEMES['Social_Structure']['ja']}
{THEMES['Social_Structure']['description']}

## åˆ†ææ‰‹æ³•

è¨˜äº‹å†…å®¹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°ã«ã‚ˆã‚Šè‡ªå‹•åˆ†é¡ã€‚1ã¤ã®è¨˜äº‹ãŒè¤‡æ•°ã®ãƒ†ãƒ¼ãƒã«åˆ†é¡ã•ã‚Œã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

- Pattern B: æ™‚ç³»åˆ—åˆ†æï¼ˆéå»ãƒ»ç¾åœ¨ãƒ»æœªæ¥ï¼‰ã®å®Ÿæ–½
- ãƒ†ãƒ¼ãƒé–“ã®é–¢é€£æ€§åˆ†æ
- ä¸»è¦æ¦‚å¿µã®æŠ½å‡ºã¨å¯è¦–åŒ–

---

**ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**ã‚¹ã‚¯ãƒªãƒ—ãƒˆ**: create_theme_structure.py (T008-4)
"""

    return content


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("  è½åˆãƒãƒ¼ãƒˆ ãƒ†ãƒ¼ãƒåˆ¥ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ä½œæˆ")
    print("  Task: T008-4")
    print("=" * 60)

    # STEP 1: ãƒ•ã‚©ãƒ«ãƒ€ä½œæˆ
    create_theme_folders()

    # STEP 2: è¨˜äº‹åˆ†æ
    theme_articles = analyze_articles()

    # STEP 3: å„ãƒ†ãƒ¼ãƒã®READMEã¨article_listä½œæˆ
    print("\nğŸ“ Creating theme documentation...")
    for theme_id, articles in theme_articles.items():
        theme_folder = ANALYSIS_DIR / theme_id

        # README.mdä½œæˆ
        readme_content = create_theme_readme(theme_id, articles)
        (theme_folder / "README.md").write_text(readme_content, encoding='utf-8')

        # article_list.mdä½œæˆ
        article_list_content = create_article_list(theme_id, articles)
        (theme_folder / "article_list.md").write_text(article_list_content, encoding='utf-8')

        print(f"   âœ“ {theme_id}/ ({len(articles)} articles)")

    # STEP 4: å…¨ä½“ã®READMEä½œæˆ
    print("\nğŸ“ Creating main README...")
    main_readme_content = create_main_readme(theme_articles)
    (ANALYSIS_DIR / "README.md").write_text(main_readme_content, encoding='utf-8')

    print("\n" + "=" * 60)
    print("âœ… å®Œäº†ï¼")
    print(f"ğŸ“‚ å‡ºåŠ›å…ˆ: {ANALYSIS_DIR}")
    print("=" * 60)

    # ã‚µãƒãƒªãƒ¼å‡ºåŠ›
    print("\nğŸ“Š ãƒ†ãƒ¼ãƒåˆ¥è¨˜äº‹æ•°ã‚µãƒãƒªãƒ¼:")
    sorted_themes = sorted(
        theme_articles.items(),
        key=lambda x: len(x[1]),
        reverse=True
    )
    for theme_id, articles in sorted_themes:
        theme_info = THEMES[theme_id]
        print(f"   {theme_info['ja']:20} : {len(articles):4}è¨˜äº‹")


if __name__ == "__main__":
    main()
