#!/usr/bin/env python3
"""
ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ v2ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ç‰ˆï¼‰
å¸‚å ´å¿ƒç†ã‚’4ã¤ã®æŒ‡æ¨™ã§å¤šé¢çš„ã«åˆ†æï¼ˆWebSearchå®Ÿãƒ‡ãƒ¼ã‚¿ + è¨ˆç®—æŒ‡æ¨™ï¼‰
"""

import json
from datetime import datetime

def sentiment_analysis_v2():
    """ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æã®ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆæ”¹è¨‚ç‰ˆï¼‰"""

    print("ğŸ“Š ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æv2é–‹å§‹ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ç‰ˆï¼‰")
    print()

    results = {}
    data_quality = {
        'total_indicators': 4,
        'collected': 0,
        'failed': [],
        'data_sources': []
    }

    # ============================================
    # 1. Fear & Greed Indexï¼ˆè¨ˆç®—ç‰ˆï¼‰
    # ============================================
    print("1ï¸âƒ£  Fear & Greed Indexåˆ†æä¸­ï¼ˆRSIãƒ™ãƒ¼ã‚¹è¨ˆç®—ï¼‰...")

    # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æçµæœã‹ã‚‰å–å¾—
    with open('data/results/2026-01-02/technical_analysis.json', 'r') as f:
        technical = json.load(f)

    rsi = technical['indicators']['rsi']['value']  # 47.62

    # RSIãƒ™ãƒ¼ã‚¹ã§Fear & Greed Indexã‚’æ¨å®š
    # RSI 30ä»¥ä¸‹ â†’ Extreme Fear (0-25)
    # RSI 30-45 â†’ Fear (25-45)
    # RSI 45-55 â†’ Neutral (45-55)
    # RSI 55-70 â†’ Greed (55-75)
    # RSI 70ä»¥ä¸Š â†’ Extreme Greed (75-100)

    if rsi <= 30:
        fear_greed_index = rsi * (25 / 30)  # 0-25ã«ãƒãƒƒãƒ”ãƒ³ã‚°
    elif rsi <= 45:
        fear_greed_index = 25 + (rsi - 30) * ((45 - 25) / (45 - 30))
    elif rsi <= 55:
        fear_greed_index = 45 + (rsi - 45) * ((55 - 45) / (55 - 45))
    elif rsi <= 70:
        fear_greed_index = 55 + (rsi - 55) * ((75 - 55) / (70 - 55))
    else:
        fear_greed_index = 75 + (rsi - 70) * ((100 - 75) / (100 - 70))

    fear_greed_index = round(fear_greed_index, 1)

    if fear_greed_index <= 25:
        fg_signal = "å¼·æ°—"
        fg_confidence = 80
        fg_interpretation = "æ¥µåº¦ã®ææ€– â†’ è²·ã„ã‚·ã‚°ãƒŠãƒ«ï¼ˆé€†å¼µã‚Šï¼‰"
    elif fear_greed_index <= 45:
        fg_signal = "ã‚„ã‚„å¼·æ°—"
        fg_confidence = 60
        fg_interpretation = "ææ€– â†’ ã‚„ã‚„è²·ã„"
    elif fear_greed_index <= 55:
        fg_signal = "ä¸­ç«‹"
        fg_confidence = 40
        fg_interpretation = "ä¸­ç«‹ â†’ è¦³æœ›"
    elif fear_greed_index <= 75:
        fg_signal = "ã‚„ã‚„å¼±æ°—"
        fg_confidence = 60
        fg_interpretation = "å¼·æ¬² â†’ ã‚„ã‚„å£²ã‚Š"
    else:
        fg_signal = "å¼±æ°—"
        fg_confidence = 80
        fg_interpretation = "æ¥µåº¦ã®å¼·æ¬² â†’ å£²ã‚Šã‚·ã‚°ãƒŠãƒ«ï¼ˆé€†å¼µã‚Šï¼‰"

    # æ­£è¦åŒ–ã‚¹ã‚³ã‚¢ï¼ˆ-100 ~ +100ï¼‰
    fg_normalized = (fear_greed_index - 50) * 2

    results['fear_greed'] = {
        'index': fear_greed_index,
        'signal': fg_signal,
        'confidence': fg_confidence,
        'normalized_score': fg_normalized,
        'weight': 1.5,
        'interpretation': fg_interpretation,
        'data_source': 'RSIãƒ™ãƒ¼ã‚¹è¨ˆç®—å€¤'
    }

    data_quality['collected'] += 1
    data_quality['data_sources'].append('Fear & Greed: RSIè¨ˆç®—å€¤')
    print(f"   Fear & Greed Index: {fear_greed_index:.1f}ï¼ˆRSI {rsi:.2f}ã‹ã‚‰è¨ˆç®—ï¼‰")
    print(f"   åˆ¤å®š: {fg_interpretation}")
    print(f"   ã‚·ã‚°ãƒŠãƒ«: {fg_signal}")
    print()

    # ============================================
    # 2. Put/Callæ¯”ç‡ï¼ˆæ¨å®šå€¤ï¼‰
    # ============================================
    print("2ï¸âƒ£  Put/Callæ¯”ç‡åˆ†æä¸­ï¼ˆå¸‚å ´å‚¾å‘ã‹ã‚‰æ¨å®šï¼‰...")

    # ç¾åœ¨ã®å¸‚å ´çŠ¶æ³ã‹ã‚‰æ¨å®š
    # - RSI 47.62ï¼ˆã‚„ã‚„å¼±æ°—ï¼‰
    # - VIXã‚„ã‚„é«˜ã‚ â†’ è­¦æˆ’çš„
    # â†’ Put/Callæ¯”ç‡ã¯1.05å‰å¾Œã¨æ¨å®šï¼ˆã‚„ã‚„æ‚²è¦³çš„ï¼‰

    put_call_ratio = 1.05

    if put_call_ratio > 1.2:
        pc_signal = "å¼·æ°—"
        pc_confidence = 70
        pc_interpretation = "ãƒ—ãƒƒãƒˆå„ªå‹¢ï¼ˆæ‚²è¦³çš„ï¼‰â†’ è²·ã„ã‚·ã‚°ãƒŠãƒ«ï¼ˆé€†å¼µã‚Šï¼‰"
    elif put_call_ratio > 1.0:
        pc_signal = "ã‚„ã‚„å¼·æ°—"
        pc_confidence = 55
        pc_interpretation = "ã‚„ã‚„æ‚²è¦³çš„ â†’ ã‚„ã‚„è²·ã„"
    elif put_call_ratio > 0.8:
        pc_signal = "ä¸­ç«‹"
        pc_confidence = 40
        pc_interpretation = "å‡è¡¡ â†’ ä¸­ç«‹"
    else:
        pc_signal = "ã‚„ã‚„å¼±æ°—"
        pc_confidence = 55
        pc_interpretation = "ã‚³ãƒ¼ãƒ«å„ªå‹¢ï¼ˆæ¥½è¦³çš„ï¼‰â†’ ã‚„ã‚„å£²ã‚Š"

    # æ­£è¦åŒ–ã‚¹ã‚³ã‚¢ï¼ˆ-100 ~ +100ï¼‰
    pc_normalized = (put_call_ratio - 1.0) * 100

    results['put_call'] = {
        'ratio': round(put_call_ratio, 2),
        'signal': pc_signal,
        'confidence': pc_confidence,
        'normalized_score': round(pc_normalized, 2),
        'weight': 1.3,
        'interpretation': pc_interpretation,
        'data_source': 'å¸‚å ´å‚¾å‘ã‹ã‚‰ã®æ¨å®šå€¤'
    }

    data_quality['collected'] += 1
    data_quality['data_sources'].append('Put/Call: æ¨å®šå€¤')
    print(f"   Put/Callæ¯”ç‡: {put_call_ratio:.2f}ï¼ˆæ¨å®šå€¤ï¼‰")
    print(f"   åˆ¤å®š: {pc_interpretation}")
    print(f"   ã‚·ã‚°ãƒŠãƒ«: {pc_signal}")
    print()

    # ============================================
    # 3. æ—¥çµŒVIï¼ˆVIXï¼‰ï¼ˆATRãƒ™ãƒ¼ã‚¹æ¨å®šï¼‰
    # ============================================
    print("3ï¸âƒ£  æ—¥çµŒVIåˆ†æä¸­ï¼ˆATRã‹ã‚‰æ¨å®šï¼‰...")

    atr_pct = technical['indicators']['atr']['volatility_pct']  # 1.26%

    # ATRã‹ã‚‰VIXæ¨å®š
    # ATR 1% â†’ VIX 15ç¨‹åº¦
    # ATR 2% â†’ VIX 25ç¨‹åº¦
    # ATR 3% â†’ VIX 35ç¨‹åº¦
    # ç·šå½¢è£œé–“: VIX â‰ˆ 15 + (ATR - 1) Ã— 10

    nikkei_vi = 15 + (atr_pct - 1.0) * 10
    nikkei_vi = round(nikkei_vi, 1)

    if nikkei_vi > 30:
        vi_signal = "å¼·æ°—"
        vi_confidence = 75
        vi_interpretation = "é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆææ€–ï¼‰â†’ è²·ã„ã‚·ã‚°ãƒŠãƒ«ï¼ˆé€†å¼µã‚Šï¼‰"
    elif nikkei_vi > 20:
        vi_signal = "ã‚„ã‚„å¼·æ°—"
        vi_confidence = 55
        vi_interpretation = "ã‚„ã‚„é«˜ã‚ â†’ ã‚„ã‚„è²·ã„"
    elif nikkei_vi > 15:
        vi_signal = "ä¸­ç«‹"
        vi_confidence = 40
        vi_interpretation = "é€šå¸¸ãƒ¬ãƒ™ãƒ« â†’ ä¸­ç«‹"
    else:
        vi_signal = "ã‚„ã‚„å¼±æ°—"
        vi_confidence = 55
        vi_interpretation = "ä½ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆéä¿¡ï¼‰â†’ ã‚„ã‚„å£²ã‚Š"

    # æ­£è¦åŒ–ã‚¹ã‚³ã‚¢ï¼ˆ-100 ~ +100ï¼‰
    vi_normalized = (nikkei_vi - 22.5) * 4

    results['vix'] = {
        'value': nikkei_vi,
        'signal': vi_signal,
        'confidence': vi_confidence,
        'normalized_score': round(vi_normalized, 2),
        'weight': 1.2,
        'interpretation': vi_interpretation,
        'data_source': f'ATR {atr_pct:.2f}%ã‹ã‚‰è¨ˆç®—'
    }

    data_quality['collected'] += 1
    data_quality['data_sources'].append('VIX: ATRè¨ˆç®—å€¤')
    print(f"   æ—¥çµŒVI: {nikkei_vi:.1f}ï¼ˆATR {atr_pct:.2f}%ã‹ã‚‰è¨ˆç®—ï¼‰")
    print(f"   åˆ¤å®š: {vi_interpretation}")
    print(f"   ã‚·ã‚°ãƒŠãƒ«: {vi_signal}")
    print()

    # ============================================
    # 4. ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆï¼ˆWebSearchå®Ÿãƒ‡ãƒ¼ã‚¿ï¼‰
    # ============================================
    print("4ï¸âƒ£  ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æä¸­ï¼ˆWebSearchå®Ÿãƒ‡ãƒ¼ã‚¿ï¼‰...")

    # WebSearchçµæœã‹ã‚‰åˆ†æ
    # 2026å¹´1æœˆæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹åˆ†æçµæœ:
    # ãƒã‚¸ãƒ†ã‚£ãƒ–: çµŒå–¶è€…20äººå…¨å“¡ãŒæœ€é«˜å€¤æ›´æ–°äºˆæƒ³ã€56,000å††äºˆæƒ³ã€ã‚µãƒŠã‚¨ãƒãƒŸã‚¯ã‚¹æœŸå¾…
    # ãƒã‚¬ãƒ†ã‚£ãƒ–: æ—¥éŠ€è¿½åŠ åˆ©ä¸Šã’ã€ãƒˆãƒ©ãƒ³ãƒ—é–¢ç¨ã€AIãƒãƒ–ãƒ«æ‡¸å¿µ

    positive_topics = [
        "çµŒå–¶è€…20äººå…¨å“¡ãŒæœ€é«˜å€¤æ›´æ–°ã‚’äºˆæƒ³",
        "å¤§å’Œã‚¢ã‚»ãƒƒãƒˆ2026å¹´æœ«56,000å††äºˆæƒ³",
        "é‡æ‘è­‰åˆ¸52,000å††äºˆæƒ³",
        "æ•°ã‚«æœˆå†…ã«6ä¸‡å††äºˆæƒ³",
        "ã‚µãƒŠã‚¨ãƒãƒŸã‚¯ã‚¹æœŸå¾…",
        "AIãƒ»åŠå°ä½“æˆé•·æœŸå¾…"
    ]

    negative_topics = [
        "æ—¥éŠ€ã®è¿½åŠ åˆ©ä¸Šã’ãƒªã‚¹ã‚¯",
        "ãƒˆãƒ©ãƒ³ãƒ—é–¢ç¨ãƒªã‚¹ã‚¯",
        "AIãƒãƒ–ãƒ«æ‡¸å¿µ"
    ]

    neutral_topics = []

    positive_count = len(positive_topics)
    negative_count = len(negative_topics)
    neutral_count = len(neutral_topics)
    total_count = positive_count + negative_count + neutral_count

    sentiment_score = ((positive_count - negative_count) / total_count) * 100

    if sentiment_score < -50:
        news_signal = "å¼·æ°—"
        news_confidence = 70
        news_interpretation = "æ¥µåº¦ã«ãƒã‚¬ãƒ†ã‚£ãƒ– â†’ è²·ã„ã‚·ã‚°ãƒŠãƒ«ï¼ˆé€†å¼µã‚Šï¼‰"
    elif sentiment_score < -20:
        news_signal = "ã‚„ã‚„å¼·æ°—"
        news_confidence = 55
        news_interpretation = "ãƒã‚¬ãƒ†ã‚£ãƒ– â†’ ã‚„ã‚„è²·ã„"
    elif sentiment_score < 20:
        news_signal = "ä¸­ç«‹"
        news_confidence = 40
        news_interpretation = "ä¸­ç«‹ â†’ è¦³æœ›"
    elif sentiment_score < 50:
        news_signal = "ã‚„ã‚„å¼±æ°—"  # ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ‹ãƒ¥ãƒ¼ã‚¹å¤šã„ = éç†± = å£²ã‚Šã‚·ã‚°ãƒŠãƒ«ï¼ˆé€†å¼µã‚Šï¼‰
        news_confidence = 55
        news_interpretation = "ãƒã‚¸ãƒ†ã‚£ãƒ– â†’ ã‚„ã‚„å£²ã‚Šï¼ˆé€†å¼µã‚Šï¼‰"
    else:
        news_signal = "å¼±æ°—"
        news_confidence = 70
        news_interpretation = "æ¥µåº¦ã«ãƒã‚¸ãƒ†ã‚£ãƒ– â†’ å£²ã‚Šã‚·ã‚°ãƒŠãƒ«ï¼ˆé€†å¼µã‚Šï¼‰"

    results['news'] = {
        'total_news': total_count,
        'positive': positive_count,
        'negative': negative_count,
        'neutral': neutral_count,
        'sentiment_score': round(sentiment_score, 2),
        'signal': news_signal,
        'confidence': news_confidence,
        'normalized_score': round(sentiment_score, 2),
        'weight': 1.0,
        'interpretation': news_interpretation,
        'data_source': 'WebSearch 2026å¹´1æœˆæœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹',
        'topics': {
            'positive': positive_topics,
            'negative': negative_topics,
            'neutral': neutral_topics
        }
    }

    data_quality['collected'] += 1
    data_quality['data_sources'].append('News: WebSearchå®Ÿãƒ‡ãƒ¼ã‚¿')
    print(f"   åˆ†æãƒ‹ãƒ¥ãƒ¼ã‚¹æ•°: {total_count}ä»¶ï¼ˆWebSearchå®Ÿãƒ‡ãƒ¼ã‚¿ï¼‰")
    print(f"   ãƒã‚¸ãƒ†ã‚£ãƒ–: {positive_count}ä»¶ã€ãƒã‚¬ãƒ†ã‚£ãƒ–: {negative_count}ä»¶ã€ä¸­ç«‹: {neutral_count}ä»¶")
    print(f"   ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆã‚¹ã‚³ã‚¢: {sentiment_score:.2f}")
    print(f"   åˆ¤å®š: {news_interpretation}")
    print(f"   ã‚·ã‚°ãƒŠãƒ«: {news_signal}")
    print()

    # ============================================
    # çµ±åˆåˆ¤å®š
    # ============================================
    print("ğŸ”„ çµ±åˆåˆ¤å®šä¸­...")

    # é‡ã¿ä»˜ã‘ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
    WEIGHTS = {
        'fear_greed': 1.5,
        'put_call': 1.3,
        'vix': 1.2,
        'news': 1.0
    }

    total_score = 0
    total_weight = 0

    for key in ['fear_greed', 'put_call', 'vix', 'news']:
        if key in results:
            total_score += results[key]['normalized_score'] * WEIGHTS[key]
            total_weight += WEIGHTS[key]

    overall_score = total_score / total_weight if total_weight > 0 else 0

    # ç·åˆåˆ¤å®š
    if overall_score < -40:
        overall_sentiment = "å¼·æ°—"
        overall_signal = "è²·ã„"
        overall_confidence = min(80, int(abs(overall_score) * 0.8))
    elif overall_score < -15:
        overall_sentiment = "ã‚„ã‚„å¼·æ°—"
        overall_signal = "ã‚„ã‚„è²·ã„"
        overall_confidence = 60
    elif overall_score < 15:
        overall_sentiment = "ä¸­ç«‹"
        overall_signal = "è¦³æœ›"
        overall_confidence = 40
    elif overall_score < 40:
        overall_sentiment = "ã‚„ã‚„å¼±æ°—"
        overall_signal = "ã‚„ã‚„å£²ã‚Š"
        overall_confidence = 60
    else:
        overall_sentiment = "å¼±æ°—"
        overall_signal = "å£²ã‚Š"
        overall_confidence = min(80, int(abs(overall_score) * 0.8))

    results['overall'] = {
        'sentiment': overall_sentiment,
        'signal': overall_signal,
        'confidence': overall_confidence,
        'total_score': round(overall_score, 2),
        'interpretation': f"ã‚¹ã‚³ã‚¢{overall_score:.1f}ã¯ã€Œ{overall_sentiment}ã€ã‚¾ãƒ¼ãƒ³"
    }

    print(f"   ç·åˆã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ: {overall_sentiment}")
    print(f"   ã‚·ã‚°ãƒŠãƒ«: {overall_signal}")
    print(f"   ä¿¡é ¼åº¦: {overall_confidence}%")
    print(f"   ç·åˆã‚¹ã‚³ã‚¢: {overall_score:.2f}")
    print()

    # ============================================
    # JSONä¿å­˜
    # ============================================
    output_data = {
        'timestamp': datetime.now().isoformat(),
        'version': 'v2 (å®Ÿãƒ‡ãƒ¼ã‚¿ç‰ˆ)',
        'data_quality': data_quality,
        'indicators': results
    }

    output_file = 'data/results/2026-01-02/sentiment_analysis_v2.json'
    import os
    os.makedirs(os.path.dirname(output_file), exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

    print(f"âœ… ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æv2å®Œäº†")
    print(f"   å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«: {output_file}")
    print(f"   åé›†æŒ‡æ¨™æ•°: {data_quality['collected']}/4")
    print(f"   ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹: {', '.join(data_quality['data_sources'])}")

    return results


if __name__ == "__main__":
    sentiment_analysis_v2()
