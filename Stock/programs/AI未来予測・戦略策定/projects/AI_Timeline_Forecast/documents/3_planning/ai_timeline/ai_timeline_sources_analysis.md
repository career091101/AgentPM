# AI Timeline主要情報源分析

**プロジェクト**: AI_Timeline_Forecast
**作成日**: 2026-01-01
**最終更新**: 2026-01-01
**バージョン**: v1.0

---

## 1. エグゼクティブサマリー

本ドキュメントは、AI未来予測の基盤となる3つの主要情報源（Situational Awareness、AI-2027、AI Futures Model）を詳細に分析し、統合的な予測アプローチを提案するものである。

### 主要結論

| 情報源 | 信頼性評価 | AGI到来予測 | 強み | 推奨用途 |
|--------|-----------|-----------|------|---------|
| **Situational Awareness** | ★★★★★ (85/100) | **2027年** | 包括的視点、内部者視点 | 中期予測（2026-2027年）の主軸 |
| **AI Futures Model** | ★★★★☆ (80/100) | **2031年頃** | 定量的予測、収益トレンド | 長期予測（2028-2035年）の主軸 |
| **AI-2027** | ★★★★☆ (75/100) | **2027年末** | 月単位シナリオ、具体性 | 短期予測（2025-2026年）の主軸 |

### 統合アプローチ（推奨）

AI Timeline予測において、**時間軸別に主軸となる情報源を使い分ける**戦略を採用する:

- **短期（2025-2026年）**: AI-2027主軸 - 月単位の具体的マイルストーン
- **中期（2026-2027年）**: Situational Awareness主軸 - AGI到来シナリオの包括的分析
- **長期（2028-2035年）**: AI Futures Model主軸 - 定量的収益・能力トレンド

### 予測の不確実性

3つの情報源のAGI到来時期予測には最大4年の幅がある（2027年 vs 2031年）。この不確実性に対応するため、**3シナリオ（楽観・標準・悲観）アプローチ**を採用し、月次での予測精度検証を実施する。

---

## 2. Situational Awareness 詳細分析

### 2.1 基本情報

| 項目 | 詳細 |
|------|------|
| **タイトル** | Situational Awareness: The Decade Ahead |
| **著者** | Leopold Aschenbrenner |
| **発表時期** | 2024年6月 |
| **形式** | 165ページ、5章、50,000語のエッセイ |
| **入手方法** | https://situational-awareness.ai/ （全文公開） |
| **最終更新** | 2024年6月（2026年1月現在、更新なし） |

### 2.2 著者プロフィール

**Leopold Aschenbrenner** (生年: 2001/2002年)
- ドイツ出身のAI研究者・投資家
- 元OpenAI「Superalignment」チームメンバー（2024年4月に解雇）
- 解雇理由: 情報漏洩疑惑（Aschenbrenner本人は否定）
- **内部者視点**: OpenAIの最前線にいた人物によるAI開発の実態報告

**信頼性への影響**:
- ✅ **強み**: AI研究の最前線での実体験に基づく予測
- ⚠️ **懸念**: OpenAI解雇後のバイアス可能性、検証可能性の限界

### 2.3 主要予測内容

#### 2.3.1 AGI到来時期: **2027年**

**根拠**: GPT-2 → GPT-4の4年間で「幼稚園児レベル → 高校生レベル」に進化。同じペースで進めば、2027年にGPT-4 → AGI（大学卒業生レベル以上）到達が「極めて妥当（strikingly plausible）」

#### 2.3.2 計算スケーリング予測

- **年間改善率**: 約0.5桁（OOM: Order of Magnitude）/年
- **計算要求量**: GPT-4 (10²⁵ FLOP) → Agent-0 (10²⁷ FLOP) → 計画システム (10²⁸ FLOP、GPT-4の1,000倍)
- **電力消費**: 2026年までにグローバルAI電力消費が38ギガワット

#### 2.3.3 アルゴリズム効率改善

- **年間改善率**: 約0.5桁/年
- **unhobbling gains**: チャットボット → エージェントへの質的変化

#### 2.3.4 Intelligence Explosion（知能爆発）

- **2027年以降**: 数億のAGIがAI研究を自動化
- **加速効果**: 10年分の進歩を1年以内に圧縮
- **超知能（Superintelligence）到来**: 2020年代末

#### 2.3.5 主要課題

1. **セキュリティ**: 米国のAI研究所がAGIの秘密を中国に「銀の皿で差し出している」状態
2. **地政学的競争**: 米中間のAGI開発競争
3. **Superalignment**: AGIの制御問題
4. **兆ドル規模クラスタへの競争**: 計算インフラの巨大化

### 2.4 予測手法

**アプローチ**: トレンドライン外挿法（Trend Extrapolation）

- **計算スケーリング**: 過去の計算量増加トレンドを外挿
- **アルゴリズム効率**: 過去のアルゴリズム改善トレンドを外挿
- **unhobbling gains**: 定性的な能力向上の予測

**前提条件**:
- 計算スケーリング法則が継続的に機能する
- 半導体製造能力の継続的向上（TSMC等）
- AI研究への巨額投資が継続する
- 規制による大幅な制約がない

### 2.5 強み・弱み分析

#### 強み

1. **内部者視点**: OpenAI内部の実体験に基づく具体的な予測
2. **包括的分析**: 技術・経済・地政学・安全性の統合的視点
3. **トレンド根拠**: 過去4年の実績トレンドに基づく外挿
4. **具体的な数値**: 計算量（FLOP）、電力消費、OOMの具体的な数値予測
5. **影響力**: AI業界で広く参照される（Axios、Goodreads等で取り上げ）

#### 弱み

1. **更新停止**: 2024年6月以降の更新なし（2026年1月時点で1.5年前）
2. **単一著者**: 個人の見解であり、組織的検証なし
3. **検証困難性**: OpenAI内部情報が多く、第三者検証が困難
4. **楽観的バイアス**: AGI 2027予測は最も楽観的なシナリオの可能性
5. **規制・社会的制約の過小評価**: 技術的制約のみに焦点、規制リスクの議論が薄い

### 2.6 信頼性評価

**総合スコア**: 85/100

| 評価軸 | スコア | 理由 |
|--------|--------|------|
| **著者の専門性** | 18/20 | OpenAI内部者、AI研究の最前線 |
| **予測根拠の明確性** | 17/20 | トレンドライン、具体的数値あり |
| **更新頻度** | 12/20 | 2024年6月以降更新なし（-8点） |
| **検証可能性** | 15/20 | 一部は検証困難だが、トレンドは確認可能 |
| **網羅性** | 18/20 | 技術・経済・地政学の統合視点 |
| **影響力** | 15/20 | AI業界で広く参照される |

**推奨**: 中期予測（2026-2027年）の主軸として採用。短期の具体的マイルストーンは他情報源で補完。

---

## 3. AI-2027 詳細分析

### 3.1 基本情報

| 項目 | 詳細 |
|------|------|
| **タイトル** | AI-2027: A month-by-month prediction for AI development |
| **著者** | Daniel Kokotajlo, Scott Alexander, Thomas Larsen, Eli Lifland, Romeo Dean |
| **発表時期** | 2024年（具体的日時不明） |
| **形式** | 月単位シナリオ予測（PDFレポート、Webサイト） |
| **入手方法** | https://ai-2027.com/ |
| **最終更新** | 2025年9月（LessWrongでの追跡投稿による） |

### 3.2 著者チーム

**複数の専門家による共同予測**:
- Daniel Kokotajlo: AI予測研究者
- Scott Alexander: Astral Codex Ten（AI・合理主義ブログ）
- Thomas Larsen, Eli Lifland, Romeo Dean: AI forecasters

**信頼性への影響**:
- ✅ **強み**: 複数専門家の合議による予測、多様な視点
- ✅ **強み**: 予測コミュニティ（LessWrong等）での継続的検証

### 3.3 主要予測内容

#### 3.3.1 AGI到来時期: **2027年末**

**ASI（人工超知能）到来**: 2027年12月

#### 3.3.2 月単位マイルストーン（2025-2027年）

| 時期 | マイルストーン | 詳細 |
|------|----------------|------|
| **2025年半ば** | AIエージェント登場 | 信頼性は低いが改善中の自律ツール |
| **2026年初頭** | コーディング自動化50%加速 | AI研究assistantsがAI研究を50%加速 |
| **2026年半ば** | 中国政府がAGI競争本格化 | 中国モデルは米国の6-9ヶ月遅れ |
| **2027年初頭** | Agent-2登場 | OpenBrainの内部開発後継モデル、重要な転換点 |
| **2027年3月** | 超人的コーダー登場 | トップエンジニア相当、より高速・安価 |
| **2027年8月** | 超人的AI研究者登場 | 全認知研究タスク対応可能 |
| **2027年9月** | Agent-4が研究加速 | 「1週間で1年分」の研究生産性達成 |
| **2027年12月** | ASI出現 | 全認知領域で人間を超える人工超知能 |

#### 3.3.3 計算要求量

- **Agent-0**: 10²⁷ FLOP（GPT-4の100倍）
- **計画システム**: 10²⁸ FLOP（GPT-4の1,000倍）

#### 3.3.4 専門予測の分類

AI-2027は以下の3つの専門的予測を含む:
1. **Timelines forecast**: AIがトッププログラマーを超えるまでの時間
2. **Takeoff forecast**: トッププログラマー超え → ASI到達の時間
3. **Security forecast**: 米中がアルゴリズム秘密・モデル重みを保護するまでの時間

### 3.4 予測手法

**アプローチ**: シナリオベース予測（Scenario Planning）

- **月単位の具体的シナリオ**: 2025-2027年の各月のイベントを詳述
- **複数専門家の合議**: 予測コミュニティでの議論を経た予測
- **実績追跡**: LessWrongコミュニティが実績との比較を継続的に実施

**前提条件**:
- AI開発競争が継続的に加速する
- 規制による大幅な制約がない
- 米中の技術格差が6-9ヶ月以内に維持される

### 3.5 実績との比較（2025年9月時点）

**LessWrong追跡投稿による検証**:
- AI-2027の2025年8月予測は2025年9月に実現（数週間遅れ、月単位では誤差範囲内）
- **短期予測精度**: 比較的高い

**懸念点（Gary Marcusによる批判）**:
- 「2025年末までにPhD-level knowledgeをすべての分野で達成」→ 過度に楽観的
- 実現までの時間を**年単位で過小評価**している可能性

### 3.6 強み・弱み分析

#### 強み

1. **月単位の具体性**: 2025-2027年の各月の詳細シナリオ
2. **複数専門家の合議**: 単一著者バイアスの軽減
3. **継続的検証**: LessWrongコミュニティによる実績追跡
4. **短期予測精度**: 2025年の予測が比較的的中
5. **専門的予測の分類**: Timelines、Takeoff、Securityの3軸予測

#### 弱み

1. **楽観的バイアス**: AGI 2027予測は最も楽観的なシナリオの可能性
2. **規制・社会的制約の過小評価**: 技術的制約のみに焦点
3. **検証困難性**: 2027年までの予測は未検証
4. **著者の利害関係不明**: 予測者の背景・バイアスが不明確
5. **更新頻度の不確実性**: 最終更新が2025年9月（追跡投稿による）、公式更新は不明

### 3.7 信頼性評価

**総合スコア**: 75/100

| 評価軸 | スコア | 理由 |
|--------|--------|------|
| **著者の専門性** | 16/20 | 複数専門家、予測コミュニティ |
| **予測根拠の明確性** | 14/20 | シナリオベース、計算根拠あり |
| **更新頻度** | 14/20 | 2025年9月追跡あり、公式更新は不明 |
| **検証可能性** | 16/20 | LessWrongで継続的検証 |
| **網羅性** | 15/20 | 技術中心、規制・社会的制約は薄い |
| **影響力** | 10/20 | 予測コミュニティで参照、一般的認知は限定的 |

**推奨**: 短期予測（2025-2026年）の主軸として採用。月単位の具体的マイルストーンを活用。

---

## 4. AI Futures Model 詳細分析

### 4.1 基本情報

| 項目 | 詳細 |
|------|------|
| **タイトル** | AI Futures Model |
| **提供元** | AI Futures organization |
| **発表時期** | 継続的（最新: 2025年12月） |
| **形式** | 定量的予測モデル（ブログ更新） |
| **入手方法** | https://blog.ai-futures.org/ |
| **最終更新** | 2025年12月（2026年1月現在、1ヶ月前） |

### 4.2 提供元

**AI Futures organization**
- 定量的AI予測に特化した組織
- ブログで定期的に予測モデルを更新
- **最新性**: 3つの情報源の中で最も最近更新されている（2025年12月）

### 4.3 主要予測内容

#### 4.3.1 収益トレンド予測

| 指標 | 現在（2025年末） | 年間成長率 | 到達時期予測 |
|------|-----------------|-----------|-------------|
| **Frontier AI企業収益** | 約$20B | 約4.1倍/年 | **$100T annualized** (2031年末頃) |

#### 4.3.2 AI研究加速予測

- **コーディング労働乗数**: 2032年頃に現在の約675,000倍
- **研究「テイスト」**: 2032年頃にSARレベル、2033年にSIARレベルへ
- **自動化率**: 現在約1% → 研究期間内に50%以上の可能性

#### 4.3.3 主要マイルストーン予測

| マイルストーン | 予測時期 | 詳細 |
|--------------|---------|------|
| **Claude 3.7 Sonnet** | 2025年 | 大幅に強化されたコーディング性能 |
| **o3** | 2025年 | 21.4倍のソフトウェア進捗乗数 |
| **AI2027-SCマイルストーン** | 2032年 | コーディング労働乗数が675,000倍 |

#### 4.3.4 加速確率予測

- **2026年末までの大幅加速確率**: 約9%

### 4.4 予測手法

**アプローチ**: 定量的トレンド外挿（Quantitative Trend Extrapolation）

- **収益トレンド**: Frontier AI企業の収益成長率を外挿
- **能力トレンド**: AIのソフトウェアR&D自動化能力をトラッキング
- **過去実績トレンド**: 「intuitions alone」よりも高い予測精度を主張

**前提条件**:
- 収益成長率（4.1倍/年）が継続する
- AI研究の自動化が加速する
- 規制による大幅な制約がない

### 4.5 強み・弱み分析

#### 強み

1. **最新性**: 2025年12月更新（最も新しい）
2. **定量的予測**: 収益、成長率、確率の具体的数値
3. **継続的更新**: 月次での予測モデル更新
4. **過去実績重視**: トレンド外挿法による予測
5. **データドリブン**: 収益データ、能力データに基づく予測

#### 弱み

1. **AGI到来時期の明示なし**: 2031年$100T到達予測だが、AGI到来時期は明示されていない
2. **シナリオの具体性欠如**: 月単位の具体的マイルストーンなし
3. **検証可能性の限界**: 2031年予測は未検証
4. **著者・組織の背景不明**: AI Futures organizationの詳細不明
5. **規制・社会的制約の過小評価**: 収益トレンドのみに焦点

### 4.6 信頼性評価

**総合スコア**: 80/100

| 評価軸 | スコア | 理由 |
|--------|--------|------|
| **著者の専門性** | 15/20 | 組織の背景は不明だが、定量的予測に特化 |
| **予測根拠の明確性** | 18/20 | 収益トレンド、成長率の具体的数値 |
| **更新頻度** | 20/20 | 2025年12月更新（最新） |
| **検証可能性** | 15/20 | 収益トレンドは検証可能、長期予測は未検証 |
| **網羅性** | 12/20 | 収益・能力トレンド中心、シナリオの具体性欠如 |
| **影響力** | 10/20 | 一般的認知は限定的 |

**推奨**: 長期予測（2028-2035年）の主軸として採用。収益・能力トレンドを補完的に活用。

---

## 5. 3情報源の比較分析

### 5.1 予測手法の比較

| 情報源 | 予測手法 | 定性/定量 | 時間粒度 | 強み | 弱み |
|--------|---------|----------|---------|------|------|
| **Situational Awareness** | トレンドライン外挿 | 定性＋定量 | 年単位 | 包括的視点、内部者視点 | 更新停止（2024年6月） |
| **AI-2027** | シナリオベース予測 | 定性中心 | 月単位 | 具体的シナリオ、短期精度 | 楽観的バイアス |
| **AI Futures Model** | 定量的トレンド外挿 | 定量中心 | 年単位 | 最新性、データドリブン | シナリオの具体性欠如 |

### 5.2 AGI到来時期の比較

| 情報源 | AGI到来予測 | ASI到来予測 | 予測幅 |
|--------|------------|------------|--------|
| **Situational Awareness** | **2027年** | 2020年代末 | ±1年 |
| **AI-2027** | **2027年末** | 2027年12月 | ±6ヶ月 |
| **AI Futures Model** | **2031年頃**（$100T到達時） | 不明 | ±2年 |

**予測幅**: 最大4年の差（2027年 vs 2031年）

### 5.3 重要な相違点

#### 相違点1: AGI到来時期

- **楽観的**: AI-2027、Situational Awareness（2027年）
- **保守的**: AI Futures Model（2031年頃）

#### 相違点2: 予測の具体性

- **具体的**: AI-2027（月単位マイルストーン）
- **抽象的**: AI Futures Model（収益トレンドのみ）

#### 相違点3: 更新頻度

- **高頻度**: AI Futures Model（月次更新）
- **低頻度**: Situational Awareness（2024年6月以降更新なし）

### 5.4 共通点

1. **計算スケーリングの重視**: 3つすべてが計算量増加を重要視
2. **AI研究の自動化**: AIがAI研究を加速するフィードバックループを予測
3. **規制・社会的制約の過小評価**: 技術的制約のみに焦点、規制リスクの議論が薄い
4. **楽観的バイアス**: 3つすべてがAGI到来を2027-2032年と予測（一般的な予測より楽観的）

### 5.5 予測の不一致をどう解釈するか

**不一致の原因**:
1. **AGI定義の違い**: 「大学卒業生レベル」 vs 「全認知タスク対応」 vs 「$100T収益」
2. **前提条件の違い**: 規制、資金調達、技術的ブレークスルーの前提
3. **予測手法の違い**: トレンドライン外挿 vs シナリオベース vs 収益トレンド

**対応策**:
- **3シナリオアプローチ**: 楽観（2027年）、標準（2028-2029年）、悲観（2031年以降）
- **月次での予測精度検証**: 実績との比較で予測を調整

---

## 6. 信頼性評価の総括

### 6.1 総合ランキング

| 順位 | 情報源 | 総合スコア | 推奨用途 |
|------|--------|-----------|---------|
| 1位 | **Situational Awareness** | 85/100 | 中期予測（2026-2027年）の主軸 |
| 2位 | **AI Futures Model** | 80/100 | 長期予測（2028-2035年）の主軸 |
| 3位 | **AI-2027** | 75/100 | 短期予測（2025-2026年）の主軸 |

### 6.2 各情報源の適用場面

#### Situational Awareness: 中期予測の主軸

**推奨用途**:
- 2026-2027年のAGI到来シナリオの分析
- 地政学的競争、セキュリティリスクの評価
- Intelligence Explosion（知能爆発）の影響予測

**補完すべき点**:
- 短期の月単位マイルストーン（AI-2027で補完）
- 最新の収益・能力トレンド（AI Futures Modelで補完）

#### AI-2027: 短期予測の主軸

**推奨用途**:
- 2025-2026年の月単位マイルストーンの特定
- 短期投資タイミングの判断（GPT-5、Claude 4等）
- 早期警戒指標の設定

**補完すべき点**:
- 包括的視点（Situational Awarenessで補完）
- 定量的トレンド（AI Futures Modelで補完）

#### AI Futures Model: 長期予測の主軸

**推奨用途**:
- 2028-2035年の長期トレンド予測
- 収益・能力トレンドの定量的トラッキング
- 月次での予測モデル更新

**補完すべき点**:
- 具体的シナリオ（AI-2027で補完）
- 地政学的視点（Situational Awarenessで補完）

---

## 7. 統合アプローチの提案

### 7.1 時間軸別統合戦略

#### 短期（2025-2026年）: AI-2027主軸

**主要マイルストーン**:
- 2025年半ば: AIエージェント登場
- 2025年末: GPT-5、Claude 4リリース（予測）
- 2026年初頭: コーディング自動化50%加速
- 2026年半ば: 中国政府がAGI競争本格化

**活用方法**:
- AI-2027の月単位シナリオを主軸
- Situational Awarenessで地政学的視点を補完
- AI Futures Modelで収益トレンドを補完

#### 中期（2026-2027年）: Situational Awareness主軸

**主要マイルストーン**:
- 2027年初頭: Agent-2登場
- 2027年3月: 超人的コーダー登場
- 2027年末: AGI到来

**活用方法**:
- Situational AwarenessのAGI到来シナリオを主軸
- AI-2027で月単位の具体的イベントを補完
- AI Futures Modelで収益・能力トレンドを補完

#### 長期（2028-2035年）: AI Futures Model主軸

**主要マイルストーン**:
- 2028-2030年: AGI の社会実装拡大
- 2031年末: $100T annualized収益到達
- 2032年: コーディング労働乗数675,000倍

**活用方法**:
- AI Futures Modelの収益・能力トレンドを主軸
- Situational Awarenessで超知能シナリオを補完
- 定量的データで予測精度を継続的に検証

### 7.2 3シナリオへの統合

#### 楽観シナリオ（AI-2027ベース、発生確率30%）

- **AGI到来**: 2027年末
- **ASI到来**: 2027年12月
- **主要前提**: 規制制約なし、技術的ブレークスルー順調

#### 標準シナリオ（Situational Awarenessベース、発生確率50%）

- **AGI到来**: 2027年
- **超知能到来**: 2020年代末
- **主要前提**: トレンドライン継続、中程度の規制

#### 悲観シナリオ（AI Futures Model保守的解釈、発生確率20%）

- **AGI到来**: 2031年頃
- **主要前提**: 規制強化、技術的制約、資金調達困難

### 7.3 統合予測マップ作成指針

1. **月単位マイルストーン（2025-2027年）**: AI-2027を主軸に作成
2. **年単位マイルストーン（2028-2035年）**: AI Futures Modelを主軸に作成
3. **地政学的視点**: Situational Awarenessのセキュリティ・競争分析を統合
4. **発生確率**: 3シナリオの確率を月次で更新
5. **早期警戒指標**: 短期マイルストーン（GPT-5性能等）で予測精度を検証

---

## 8. 追加すべき情報源

### 8.1 公式発表（高優先度）

| 情報源 | URL | 更新頻度 | 重要度 | 活用方法 |
|--------|-----|---------|--------|---------|
| **OpenAI Blog** | https://openai.com/blog/ | 不定期 | ★★★★★ | GPT-5等のモデルリリース情報 |
| **Anthropic Blog** | https://www.anthropic.com/news | 不定期 | ★★★★★ | Claude 4等の開発状況 |
| **DeepMind Blog** | https://deepmind.google/discover/blog/ | 不定期 | ★★★★☆ | AlphaFold等の研究成果 |
| **Microsoft AI Blog** | https://blogs.microsoft.com/ai/ | 週次 | ★★★★☆ | OpenAI統合、Azure AI情報 |
| **Google AI Blog** | https://ai.googleblog.com/ | 週次 | ★★★★☆ | Gemini等のモデル情報 |

### 8.2 学術論文（中優先度）

| 情報源 | URL | 更新頻度 | 重要度 | 活用方法 |
|--------|-----|---------|--------|---------|
| **arXiv (cs.AI)** | https://arxiv.org/list/cs.AI/recent | 日次 | ★★★★☆ | AI研究の最新トレンド |
| **arXiv (cs.LG)** | https://arxiv.org/list/cs.LG/recent | 日次 | ★★★★☆ | 機械学習の最新研究 |
| **NeurIPS** | https://neurips.cc/ | 年次 | ★★★★☆ | AI研究の主要学会 |
| **ICML** | https://icml.cc/ | 年次 | ★★★★☆ | 機械学習の主要学会 |

### 8.3 予測コミュニティ（中優先度）

| 情報源 | URL | 更新頻度 | 重要度 | 活用方法 |
|--------|-----|---------|--------|---------|
| **LessWrong** | https://www.lesswrong.com/ | 日次 | ★★★★☆ | AI予測・戦略議論 |
| **AI Alignment Forum** | https://www.alignmentforum.org/ | 日次 | ★★★☆☆ | AI安全性研究 |
| **Metaculus** | https://www.metaculus.com/ | 日次 | ★★★☆☆ | 予測市場（AGI到来時期等） |

### 8.4 メディア・解説（低優先度）

| 情報源 | URL | 更新頻度 | 重要度 | 活用方法 |
|--------|-----|---------|--------|---------|
| **Stanford HAI** | https://hai.stanford.edu/ | 週次 | ★★★☆☆ | 学術的AI研究動向 |
| **MIT Technology Review** | https://www.technologyreview.com/ | 日次 | ★★★☆☆ | AI技術トレンド解説 |
| **Axios AI+** | https://www.axios.com/ai-plus | 週次 | ★★☆☆☆ | AI業界ニュース |

### 8.5 情報収集の優先順位

**月次レビュー時の優先順位**:
1. **公式発表（OpenAI、Anthropic、DeepMind）**: 最優先
2. **AI Futures Model更新**: 定量的トレンドの確認
3. **LessWrong追跡投稿**: AI-2027の予測精度検証
4. **arXiv新着論文**: 技術的ブレークスルーの早期検出
5. **メディア解説**: 補完的な視点

---

## 9. 月次更新プロセスの設計

### 9.1 月次更新の目的

- **予測精度の検証**: 実績との比較で予測モデルを調整
- **最新情報の統合**: 新しいマイルストーン、技術的ブレークスルーの反映
- **シナリオ確率の更新**: 楽観・標準・悲観シナリオの確率調整

### 9.2 月次更新チェックリスト

#### Step 1: 情報源の最新情報確認（毎月1日、30分）

- [ ] **Situational Awareness**: 更新あり / なし（2024年6月以降更新なし想定）
- [ ] **AI-2027**: LessWrongでの追跡投稿確認
- [ ] **AI Futures Model**: https://blog.ai-futures.org/ の最新更新確認
- [ ] **OpenAI Blog**: GPT-5等のモデルリリース情報
- [ ] **Anthropic Blog**: Claude 4等の開発状況
- [ ] **arXiv (cs.AI)**: 重要論文（引用数100以上）のチェック

#### Step 2: マイルストーン進捗確認（毎月1日、30分）

- [ ] **GPT-5リリース**（予測: 2025年Q1-Q2）: 実現 ✅ / 未達成 ⏳
- [ ] **Claude 4リリース**（予測: 2025年Q2）: 実現 ✅ / 未達成 ⏳
- [ ] **50%コーディング自動化**（予測: 2026年Q1）: 進捗XX%
- [ ] **中国政府のAGI競争本格化**（予測: 2026年半ば）: 兆候あり / なし

#### Step 3: 予測精度検証（毎月1日、30分）

| マイルストーン | 予測時期 | 実績時期 | 誤差 | 予測的中 |
|--------------|---------|---------|------|---------|
| GPT-5リリース | 2025年3月 | 2025年X月 | +Xヶ月 | ✅ / ❌ |

**予測精度KPI**: 主要マイルストーン予測と実績の一致率 80%以上目標

#### Step 4: シナリオ確率更新（毎月1日、30分）

**現在の確率**: 楽観30%、標準50%、悲観20%

**更新基準**:
- 楽観シナリオへの調整: 予測より早い技術的ブレークスルー
- 悲観シナリオへの調整: 規制強化、技術的制約、資金調達困難

**ベイズ更新**:
```
事後確率 = 事前確率 × 尤度 / 正規化定数
```

#### Step 5: アクション決定（毎月1日、30分）

- [ ] **投資ポートフォリオ**: 変更あり（詳細: ） / なし
- [ ] **キャリア戦略**: 変更あり（詳細: ） / なし
- [ ] **副業戦略**: 変更あり（詳細: ） / なし
- [ ] **次月重点**: （記入）

### 9.3 四半期レビュー（深い分析）

**四半期レビュー時の追加タスク**（3, 6, 9, 12月1日、2時間）:
- [ ] 3情報源の信頼性再評価
- [ ] 新しい情報源の追加検討
- [ ] 統合アプローチの調整
- [ ] 予測精度の総括レポート作成

### 9.4 緊急時対応（突発的な技術的ブレークスルー）

**緊急レビュートリガー**:
- GPT-5性能が予測を大幅に上回る
- 中国が米国を追い抜く
- 規制による大幅な制約

**緊急時対応プロセス**:
1. 即座にタイムライン再評価（48時間以内）
2. シナリオ確率の大幅調整
3. 投資・キャリア・副業戦略の緊急見直し

### 9.5 自動化支援ツール

#### RSS フィード設定

```
https://openai.com/blog/feed/
https://www.anthropic.com/news/rss
https://deepmind.google/discover/blog/feed/
https://blog.ai-futures.org/feed
```

#### Google Alerts 設定

```
"GPT-5" OR "Claude 4" OR "AGI 2027"
"Situational Awareness" Leopold Aschenbrenner
"AI-2027" timeline
"AI Futures Model" update
```

---

## 10. 更新履歴

| 日付 | 更新内容 |
|------|---------|
| 2026-01-01 | 初回作成（v1.0） |

---

## Sources

- [Introduction - SITUATIONAL AWARENESS: The Decade Ahead](https://situational-awareness.ai/)
- [Leopold Aschenbrenner: Situational Awareness — Stanford Digital Economy Lab](https://digitaleconomy.stanford.edu/event/leopold-aschenbrenner-situational-awareness/)
- [Summary of Situational Awareness - The Decade Ahead — EA Forum](https://forum.effectivealtruism.org/posts/zmRTWsYZ4ifQKrX26/summary-of-situational-awareness-the-decade-ahead)
- [Leopold Aschenbrenner - Wikipedia](https://en.wikipedia.org/wiki/Leopold_Aschenbrenner)
- [AI-2027: a month-by-month prediction for AI development](https://roland-ewald.github.io/2025/04/05/ai-2027.html)
- [The "AI 2027" Scenario: How realistic is it?](https://garymarcus.substack.com/p/the-ai-2027-scenario-how-realistic)
- [Checking in on AI-2027](https://www.lesswrong.com/posts/hmZHPE4ZJvEc3khgQ/checking-in-on-ai-2027)
- [AI 2027: What Superintelligence Looks Like](https://www.lesswrong.com/posts/TpSFoqoG2M5MAAesg/ai-2027-what-superintelligence-looks-like-1)
- [AI Goals Forecast — AI 2027](https://ai-2027.com/research/ai-goals-forecast)
- [AI Futures Model: Dec 2025 Update](https://blog.ai-futures.org/p/ai-futures-model-dec-2025-update)
