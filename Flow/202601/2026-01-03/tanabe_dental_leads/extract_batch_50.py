#!/usr/bin/env python3
"""
ç”°è¾ºç©å…·å‘ã‘æ­¯ç§‘åŒ»é™¢å–¶æ¥­ãƒªã‚¹ãƒˆ - ãƒãƒƒãƒå‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ50ä»¶/ãƒãƒƒãƒç‰ˆï¼‰

ä½¿ç”¨æ–¹æ³•:
    python extract_batch_50.py --batch 1

ãƒãƒƒãƒç•ªå·:
    1-360 (50ä»¶ãšã¤ã€ç·è¨ˆ15,880ä»¶)
    - ãƒãƒƒãƒ1-8: é’æ£®çœŒï¼ˆ353ä»¶ï¼‰
    - ãƒãƒƒãƒ9-16: å²©æ‰‹çœŒï¼ˆ353ä»¶ï¼‰
    - ... (å…¨45éƒ½åºœçœŒ)
    - ãƒãƒƒãƒ353-360: é¹¿å…å³¶çœŒï¼ˆ352ä»¶ï¼‰
"""

import os
import sys
import json
import csv
import time
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
import googlemaps
import argparse

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()
API_KEY = os.environ.get('GOOGLE_MAPS_API_KEY')

if not API_KEY:
    print("âŒ Error: GOOGLE_MAPS_API_KEY not found in .env")
    sys.exit(1)

# Google Maps Clientã®åˆæœŸåŒ–
gmaps = googlemaps.Client(key=API_KEY)

# éƒ½é“åºœçœŒãƒªã‚¹ãƒˆï¼ˆæœ¬å·ãƒ»å››å›½ãƒ»ä¹å·45éƒ½åºœçœŒï¼‰
PREFECTURES = [
    # æ±åŒ—ï¼ˆ6çœŒï¼‰
    'é’æ£®çœŒ', 'å²©æ‰‹çœŒ', 'å®®åŸçœŒ', 'ç§‹ç”°çœŒ', 'å±±å½¢çœŒ', 'ç¦å³¶çœŒ',
    # é–¢æ±ï¼ˆ7éƒ½çœŒï¼‰
    'èŒ¨åŸçœŒ', 'æ ƒæœ¨çœŒ', 'ç¾¤é¦¬çœŒ', 'åŸ¼ç‰çœŒ', 'åƒè‘‰çœŒ', 'æ±äº¬éƒ½', 'ç¥å¥ˆå·çœŒ',
    # ä¸­éƒ¨ï¼ˆ9çœŒï¼‰
    'æ–°æ½ŸçœŒ', 'å¯Œå±±çœŒ', 'çŸ³å·çœŒ', 'ç¦äº•çœŒ', 'å±±æ¢¨çœŒ', 'é•·é‡çœŒ', 'å²é˜œçœŒ', 'é™å²¡çœŒ', 'æ„›çŸ¥çœŒ',
    # è¿‘ç•¿ï¼ˆ7åºœçœŒï¼‰
    'ä¸‰é‡çœŒ', 'æ»‹è³€çœŒ', 'äº¬éƒ½åºœ', 'å¤§é˜ªåºœ', 'å…µåº«çœŒ', 'å¥ˆè‰¯çœŒ', 'å’Œæ­Œå±±çœŒ',
    # ä¸­å›½ï¼ˆ5çœŒï¼‰
    'é³¥å–çœŒ', 'å³¶æ ¹çœŒ', 'å²¡å±±çœŒ', 'åºƒå³¶çœŒ', 'å±±å£çœŒ',
    # å››å›½ï¼ˆ4çœŒï¼‰
    'å¾³å³¶çœŒ', 'é¦™å·çœŒ', 'æ„›åª›çœŒ', 'é«˜çŸ¥çœŒ',
    # ä¹å·ï¼ˆ7çœŒï¼‰
    'ç¦å²¡çœŒ', 'ä½è³€çœŒ', 'é•·å´çœŒ', 'ç†Šæœ¬çœŒ', 'å¤§åˆ†çœŒ', 'å®®å´çœŒ', 'é¹¿å…å³¶çœŒ'
]

# æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
SEARCH_KEYWORDS = ['å°å…æ­¯ç§‘', 'çŸ¯æ­£æ­¯ç§‘']

# é‡è¤‡æ’é™¤ç”¨ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚»ãƒƒãƒˆ
seen_place_ids = set()


def load_existing_place_ids(batch_num):
    """æ—¢å­˜ãƒãƒƒãƒã‹ã‚‰æ—¢ã«ã‚¯ãƒ­ãƒ¼ãƒ«ã—ãŸplace_idã‚’èª­ã¿è¾¼ã¿ã€é‡è¤‡ã‚’é˜²ã"""
    global seen_place_ids

    for i in range(1, batch_num):
        csv_file = f"dental_leads_production_batch_{i:03d}.csv"
        if Path(csv_file).exists():
            with open(csv_file, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    # Google Maps URLã‹ã‚‰place_idã‚’æŠ½å‡ºï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
                    # å®Ÿéš›ã®URLãƒ‘ãƒ¼ã‚¹å‡¦ç†ãŒå¿…è¦ãªå ´åˆã¯è¿½åŠ å®Ÿè£…
                    seen_place_ids.add(row.get('Google Maps URL', ''))


def clean_address(address, postal_code):
    """ä½æ‰€ã‹ã‚‰ã€Œæ—¥æœ¬ã€ã€ã¨ã€Œã€’éƒµä¾¿ç•ªå· ã€ã‚’å‰Šé™¤"""
    cleaned = address.replace('æ—¥æœ¬ã€', '')
    if postal_code:
        cleaned = cleaned.replace(f'ã€’{postal_code} ', '')
        cleaned = cleaned.replace(f'ã€’{postal_code}', '')
    return cleaned.strip()


def extract_postal_code(address_components):
    """address_componentsã‹ã‚‰éƒµä¾¿ç•ªå·ã‚’æŠ½å‡º"""
    for component in address_components:
        if 'postal_code' in component['types']:
            return component['long_name']
    return None


def search_dental_clinics(prefecture, keyword, max_results=25):
    """
    æŒ‡å®šéƒ½é“åºœçœŒã§æ­¯ç§‘åŒ»é™¢ã‚’æ¤œç´¢

    Args:
        prefecture: éƒ½é“åºœçœŒå
        keyword: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå°å…æ­¯ç§‘ or çŸ¯æ­£æ­¯ç§‘ï¼‰
        max_results: æœ€å¤§å–å¾—ä»¶æ•°

    Returns:
        list: Place Detailsæƒ…å ±ã®ãƒªã‚¹ãƒˆ
    """
    query = f"{keyword} {prefecture}"
    results = []

    try:
        # Text Search APIã§æ¤œç´¢
        places_result = gmaps.places(
            query=query,
            language='ja',
            region='jp'
        )

        # æœ€åˆã®20ä»¶ã‚’å–å¾—
        initial_results = places_result.get('results', [])[:20]

        for place in initial_results:
            place_id = place['place_id']

            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if place_id in seen_place_ids:
                continue

            # Place Details APIã§è©³ç´°æƒ…å ±å–å¾—
            try:
                place_details = gmaps.place(
                    place_id=place_id,
                    language='ja',
                    fields=[
                        'name', 'formatted_address', 'address_component',
                        'formatted_phone_number', 'website', 'rating',
                        'user_ratings_total', 'url', 'type', 'photo'
                    ]
                )

                details = place_details.get('result', {})

                # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãƒã‚§ãƒƒã‚¯
                if not details.get('name'):
                    continue

                seen_place_ids.add(place_id)
                results.append(details)

                # æœ€å¤§ä»¶æ•°ãƒã‚§ãƒƒã‚¯
                if len(results) >= max_results:
                    break

                # APIåˆ¶é™å¯¾ç­–
                time.sleep(0.1)

            except Exception as e:
                print(f"âš ï¸  Place Details API error for {place_id}: {e}")
                continue

        # æ¬¡ã®ãƒšãƒ¼ã‚¸ãŒã‚ã‚Œã°å–å¾—ï¼ˆæœ€å¤§60ä»¶ã¾ã§ï¼‰
        next_page_token = places_result.get('next_page_token')
        if next_page_token and len(results) < max_results:
            time.sleep(2)  # next_page_tokenã¯2ç§’å¾Œã«æœ‰åŠ¹åŒ–
            try:
                next_result = gmaps.places(
                    page_token=next_page_token,
                    language='ja'
                )

                for place in next_result.get('results', []):
                    place_id = place['place_id']

                    if place_id in seen_place_ids:
                        continue

                    place_details = gmaps.place(
                        place_id=place_id,
                        language='ja',
                        fields=[
                            'name', 'formatted_address', 'address_component',
                            'formatted_phone_number', 'website', 'rating',
                            'user_ratings_total', 'url', 'type', 'photo'
                        ]
                    )

                    details = place_details.get('result', {})

                    if not details.get('name'):
                        continue

                    seen_place_ids.add(place_id)
                    results.append(details)

                    if len(results) >= max_results:
                        break

                    time.sleep(0.1)

            except Exception as e:
                print(f"âš ï¸  Next page fetch error: {e}")

    except Exception as e:
        print(f"âŒ Search error for {query}: {e}")

    return results


def extract_batch(batch_num, target_count=50):
    """
    æŒ‡å®šãƒãƒƒãƒç•ªå·ã®50ä»¶ã‚’å–å¾—

    Args:
        batch_num: ãƒãƒƒãƒç•ªå·ï¼ˆ1-360ï¼‰
        target_count: ç›®æ¨™å–å¾—ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ50ï¼‰

    Returns:
        list: å–å¾—ã—ãŸæ­¯ç§‘åŒ»é™¢ãƒ‡ãƒ¼ã‚¿
    """
    print(f"\n{'='*60}")
    print(f"ãƒãƒƒãƒ {batch_num}/360 é–‹å§‹ï¼ˆç›®æ¨™: {target_count}ä»¶ï¼‰")
    print(f"{'='*60}\n")

    # æ—¢å­˜place_idã‚’èª­ã¿è¾¼ã¿ï¼ˆé‡è¤‡æ’é™¤ï¼‰
    load_existing_place_ids(batch_num)
    print(f"âœ… æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(seen_place_ids)}ä»¶ã®place_idã‚’ã‚¹ã‚­ãƒƒãƒ—\n")

    results = []
    pref_idx = 0
    keyword_idx = 0

    while len(results) < target_count and pref_idx < len(PREFECTURES):
        prefecture = PREFECTURES[pref_idx]
        keyword = SEARCH_KEYWORDS[keyword_idx]

        print(f"ğŸ” æ¤œç´¢ä¸­: {keyword} {prefecture} (ç¾åœ¨: {len(results)}/{target_count}ä»¶)")

        # æ¤œç´¢å®Ÿè¡Œï¼ˆæœ€å¤§25ä»¶ï¼‰
        batch_results = search_dental_clinics(prefecture, keyword, max_results=25)
        results.extend(batch_results)

        print(f"   â†’ {len(batch_results)}ä»¶å–å¾—ï¼ˆç´¯è¨ˆ: {len(results)}ä»¶ï¼‰\n")

        # æ¬¡ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¸
        keyword_idx += 1
        if keyword_idx >= len(SEARCH_KEYWORDS):
            keyword_idx = 0
            pref_idx += 1

        # APIåˆ¶é™å¯¾ç­–
        time.sleep(1)

    print(f"\nâœ… ãƒãƒƒãƒ {batch_num} ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†: {len(results)}ä»¶\n")

    return results[:target_count]


def main():
    parser = argparse.ArgumentParser(description='ç”°è¾ºç©å…·å‘ã‘æ­¯ç§‘åŒ»é™¢å–¶æ¥­ãƒªã‚¹ãƒˆ - ãƒãƒƒãƒå‡¦ç†')
    parser.add_argument('--batch', type=int, required=True, help='ãƒãƒƒãƒç•ªå·ï¼ˆ1-360ï¼‰')
    args = parser.parse_args()

    batch_num = args.batch

    if batch_num < 1 or batch_num > 360:
        print("âŒ Error: ãƒãƒƒãƒç•ªå·ã¯1-360ã®ç¯„å›²ã§æŒ‡å®šã—ã¦ãã ã•ã„")
        sys.exit(1)

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # ãƒãƒƒãƒå®Ÿè¡Œ
    clinics = extract_batch(batch_num, target_count=50)

    if not clinics:
        print("âŒ Error: ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)

    # JSONä¿å­˜ï¼ˆå¾Œã§ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã«æ¸¡ã™ï¼‰
    json_file = f"batch_{batch_num:03d}_raw_data_{timestamp}.json"
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump({
            'metadata': {
                'batch_number': batch_num,
                'total_clinics': len(clinics),
                'timestamp': timestamp
            },
            'clinics': clinics
        }, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… RAWãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {json_file}")
    print(f"\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"1. ã‚µãƒ–ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆ/analyze-dental-websitesï¼‰ã§Webã‚µã‚¤ãƒˆåˆ†æã‚’å®Ÿè¡Œ")
    print(f"2. åˆ†æçµæœã¨ã“ã®JSONã‚’çµ±åˆã—ã¦CSVå‡ºåŠ›\n")


if __name__ == '__main__':
    main()
