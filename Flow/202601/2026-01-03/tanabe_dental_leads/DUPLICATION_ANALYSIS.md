# バッチ内重複データ調査レポート

**調査日時**: 2026-01-04
**調査対象**: batch_002, batch_003, batch_004

## 重大な発見

各バッチのCSVファイルには**極めて高い重複率**のデータが含まれています。

---

## バッチ002の重複状況

**総行数**: 500行
**ユニーク医院数**: 4医院

| 医院名 | 出現回数 | 出現率 |
|--------|---------|--------|
| 盛岡となん歯科･こども矯正歯科 | 199回 | 39.8% |
| 松尾歯科･おとなこども矯正歯科 | 199回 | 39.8% |
| 高橋衛歯科医院 | 62回 | 12.4% |
| 八戸総合歯科・矯正歯科 | 40回 | 8.0% |

**重複率**: **99.2%** (496/500件が重複)

---

## バッチ003の重複状況

**総行数**: 500行
**ユニーク医院数**: 114医院

| 医院名 | 出現回数 | 出現率 |
|--------|---------|--------|
| 村井産婦人科小児歯科医院 | 163回 | 32.6% |
| のへじ矯正小児歯科 | 163回 | 32.6% |
| 盛岡となん歯科･こども矯正歯科 | 23回 | 4.6% |
| 松尾歯科･おとなこども矯正歯科 | 22回 | 4.4% |
| 八戸総合歯科・矯正歯科 | 15回 | 3.0% |
| その他109医院 | 各1回 | 21.8% |

**重複率**: **77.2%** (386/500件が重複)

---

## バッチ004の重複状況

**総行数**: 500行
**ユニーク医院数**: 169医院

| 医院名 | 出現回数 | 出現率 |
|--------|---------|--------|
| 村井産婦人科小児歯科医院 | 164回 | 32.8% |
| のへじ矯正小児歯科 | 164回 | 32.8% |
| たなべ歯科・矯正歯科医院 | 19回 | 3.8% |
| あおき矯正歯科 | 2回 | 0.4% |
| その他165医院 | 各1回 | 33.0% |

**重複率**: **66.2%** (331/500件が重複)

---

## 問題の影響

### 1. WebFetch負荷の無駄

- **バッチ002**: 500件中496件が無駄なWebFetch（同じURLを何度もfetch）
- **バッチ003**: 500件中386件が無駄なWebFetch
- **バッチ004**: 500件中331件が無駄なWebFetch

### 2. コスト増大

- WebFetch APIコストが**60-99%無駄**
- LLM推論コストが重複データ分無駄

### 3. 医院長名抽出率100%の誤解

- 実際には**ユニーク医院の抽出率**を見るべき
- 重複データで100%達成は当然（同じ医院を何度も分析）

### 4. データ品質への影響

- 特定医院（上位2-4医院）に偏った分析結果
- 17,952件の多様性が失われている可能性

---

## 原因推測

### 元データ（17,952件）の分割方法に問題

おそらく以下のいずれか：

1. **単純な500件ごと分割**を行ったが、元データ自体が重複を含んでいた
2. Google Maps APIの**検索結果が重複**していた（同じ医院が複数の検索クエリでヒット）
3. CSVマージ時に**意図しない重複**が発生した

---

## 推奨対策

### 即座対応（Priority 1）

1. **元データの重複確認**
   ```bash
   # 元の統合CSVの重複率を確認
   cut -d',' -f2 tanabe_dental_leads_all_batches_20260104_123142.csv | tail -n +2 | sort | uniq -c | sort -rn | head -20
   ```

2. **ユニーク医院のみに絞る**
   - 各バッチCSVからユニーク医院のみを抽出
   - 重複行を削除してから500件ずつ分割し直す

3. **WebFetch実行済みバッチの再利用**
   - バッチ002-004は既にWebFetch完了
   - ユニーク医院のみのJSON結果として保存
   - 残りバッチは重複削除後に実行

### 中期対応（Priority 2）

4. **最終統合時の重複排除**
   - `integrate_scoring_results.py` に重複排除ロジック追加
   - 医院名またはGoogle Maps URLでユニークキーを設定

5. **レポート修正**
   - EXECUTION_REPORT.md の「総件数: 11,233件」は実際のユニーク数か確認
   - 重複率を明記

---

## 次のアクション

### ステップ1: 元データ確認（今すぐ実行）

```bash
# 元の統合CSVの重複状況を確認
cd /Users/yuichi/AIPM/aipm_v0/Flow/202601/2026-01-03/tanabe_dental_leads
cut -d',' -f2 tanabe_dental_leads_all_batches_20260104_123142.csv | tail -n +2 | wc -l
cut -d',' -f2 tanabe_dental_leads_all_batches_20260104_123142.csv | tail -n +2 | sort -u | wc -l
```

### ステップ2: ユーザーに確認

**重要な質問**:
1. 元データ（17,952件）は本当にユニークな医院か？
2. 同じ医院の重複データが多数含まれている可能性があるが、これは想定内か？
3. このまま残りバッチを実行すべきか、元データの重複削除を先に行うべきか？

### ステップ3: 対応方針の決定

**選択肢A**: このまま継続（重複を許容）
- 残り15バッチを順次実行
- 最終統合時にユニーク化

**選択肢B**: 元データを重複削除してから再実行
- 統合CSVからユニーク医院のみ抽出
- 36バッチを再分割（各バッチが真の500件ユニーク）
- バッチ002-004は既にWebFetch済みなので再利用

**推奨**: **選択肢B**（データ品質と効率を優先）

---

## 証拠ファイル

- `batch_002_to_score.csv` - 4ユニーク医院、重複率99.2%
- `batch_003_to_score.csv` - 114ユニーク医院、重複率77.2%
- `batch_004_to_score.csv` - 169ユニーク医院、重複率66.2%
