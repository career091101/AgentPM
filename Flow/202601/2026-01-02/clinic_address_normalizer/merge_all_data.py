#!/usr/bin/env python3
"""
å…¨ãƒ‡ãƒ¼ã‚¿çµ±åˆï¼ˆæ—¢å­˜75ä»¶ + æ–°è¦98ä»¶ + æ®‹ã‚Šåœ°åŸŸï¼‰
"""

import csv
from datetime import datetime
from collections import Counter

# æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«
existing_file = "pediatric_filtered_output.csv"  # æ±äº¬ãƒ»å¤§é˜ªãƒ»æ„›çŸ¥75ä»¶
remaining_file = "pediatric_dental_remaining_20260102_221959.csv"  # æ„›åª›ã€œé¹¿å…å³¶98ä»¶

# çµ±åˆ
all_data = []
seen_place_ids = set()

print("=" * 60)
print("å…¨ãƒ‡ãƒ¼ã‚¿çµ±åˆ")
print("=" * 60)

# æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
print(f"\næ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {existing_file}")
with open(existing_file, 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    for row in reader:
        # place_id ãŒãªã„å ´åˆã¯åŒ»é™¢å+ä½æ‰€ã§ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–
        unique_key = f"{row['åŒ»é™¢å']}_{row['ä½æ‰€']}"
        if unique_key not in seen_place_ids:
            seen_place_ids.add(unique_key)
            # è¨ºç™‚ç§‘ç›®ã¨éƒ½é“åºœçœŒã‚’è¿½åŠ ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã«ã¯ãªã„å ´åˆï¼‰
            if 'è¨ºç™‚ç§‘ç›®' not in row:
                row['è¨ºç™‚ç§‘ç›®'] = row.get('æ¤œç´¢ã‚¯ã‚¨ãƒª', '').split()[0] if 'æ¤œç´¢ã‚¯ã‚¨ãƒª' in row else ''
            if 'éƒ½é“åºœçœŒ' not in row:
                # ä½æ‰€ã‹ã‚‰éƒ½é“åºœçœŒã‚’æŠ½å‡º
                address = row['ä½æ‰€']
                for pref in ['æ±äº¬éƒ½', 'å¤§é˜ªåºœ', 'æ„›çŸ¥çœŒ']:
                    if pref in address:
                        row['éƒ½é“åºœçœŒ'] = pref
                        break
            all_data.append(row)

print(f"  èª­ã¿è¾¼ã¿: {len(all_data)}ä»¶")

# æ–°è¦ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
print(f"\næ–°è¦ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {remaining_file}")
initial_count = len(all_data)
with open(remaining_file, 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    for row in reader:
        unique_key = f"{row['åŒ»é™¢å']}_{row['ä½æ‰€']}"
        if unique_key not in seen_place_ids:
            seen_place_ids.add(unique_key)
            all_data.append(row)

print(f"  èª­ã¿è¾¼ã¿: {len(all_data) - initial_count}ä»¶")

# é‡è¤‡å‰Šé™¤ç¢ºèª
print(f"\nçµ±åˆå¾Œ: {len(all_data)}ä»¶ï¼ˆé‡è¤‡ãªã—ï¼‰")

# çµ±è¨ˆ
print(f"\n{'=' * 60}")
print("ğŸ“Š çµ±è¨ˆã‚µãƒãƒªãƒ¼")
print(f"{'=' * 60}")

total = len(all_data)
avg_rating = sum(float(r["è©•ä¾¡"]) for r in all_data if r["è©•ä¾¡"]) / len([r for r in all_data if r["è©•ä¾¡"]])
avg_reviews = sum(int(r["å£ã‚³ãƒŸä»¶æ•°"]) for r in all_data) / len(all_data)
has_website = sum(1 for r in all_data if r.get("å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ"))

print(f"ç·ä»¶æ•°: {total}ä»¶")
print(f"å¹³å‡è©•ä¾¡: â­{avg_rating:.2f}")
print(f"å¹³å‡å£ã‚³ãƒŸä»¶æ•°: {avg_reviews:.0f}ä»¶")
print(f"å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã‚ã‚Š: {has_website}/{total} ({has_website/total*100:.1f}%)")

# éƒ½é“åºœçœŒåˆ¥å†…è¨³
prefecture_counts = Counter(r.get("éƒ½é“åºœçœŒ", "ä¸æ˜") for r in all_data)
print(f"\néƒ½é“åºœçœŒåˆ¥å†…è¨³:")
for pref, count in sorted(prefecture_counts.items(), key=lambda x: x[1], reverse=True):
    print(f"  {pref}: {count}ä»¶")

# è¨ºç™‚ç§‘ç›®åˆ¥å†…è¨³
specialty_counts = Counter(r.get("è¨ºç™‚ç§‘ç›®", "ä¸æ˜") for r in all_data)
print(f"\nè¨ºç™‚ç§‘ç›®åˆ¥å†…è¨³:")
for spec, count in sorted(specialty_counts.items()):
    print(f"  {spec}: {count}ä»¶")

# æœ€çµ‚CSVå‡ºåŠ›
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
output_file = f"nationwide_pediatric_dental_final_{timestamp}.csv"

fieldnames = ["åŒ»é™¢å", "ä½æ‰€", "éƒµä¾¿ç•ªå·", "è©•ä¾¡", "å£ã‚³ãƒŸä»¶æ•°", "Google Maps URL", "å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ", "éƒ½é“åºœçœŒ", "è¨ºç™‚ç§‘ç›®"]

with open(output_file, 'w', encoding='utf-8', newline='') as f:
    writer = csv.DictWriter(f, fieldnames=fieldnames)
    writer.writeheader()
    for row in all_data:
        # å¿…è¦ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿å‡ºåŠ›
        output_row = {k: row.get(k, '') for k in fieldnames}
        writer.writerow(output_row)

print(f"\nâœ… æœ€çµ‚CSVå‡ºåŠ›å®Œäº†: {output_file}")
print(f"{'=' * 60}")
