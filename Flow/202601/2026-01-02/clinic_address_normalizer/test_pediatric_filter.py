#!/usr/bin/env python3
"""
å°å…æ­¯ç§‘ãƒ»çŸ¯æ­£æ­¯ç§‘ã®çµã‚Šè¾¼ã¿ãƒ†ã‚¹ãƒˆ

çµã‚Šè¾¼ã¿æ¡ä»¶:
1. åŒ—æµ·é“ãƒ»æ²–ç¸„ã‚’é™¤å¤–
2. ãƒ¬ãƒ“ãƒ¥ãƒ¼ä»¶æ•° >= 50
3. è©•ä¾¡ >= 3.0
4. å°å…æ­¯ç§‘ãƒ»çŸ¯æ­£æ­¯ç§‘ãªã©å­ä¾›å‘ã‘åŒ»é™¢
"""

import os
import csv
import re
import requests

API_KEY = os.environ.get("GOOGLE_MAPS_API_KEY")

if not API_KEY:
    print("âŒ Error: GOOGLE_MAPS_API_KEY environment variable not set")
    exit(1)


def search_pediatric_dental(prefecture: str, specialty: str) -> list:
    """
    å°å…æ­¯ç§‘ãƒ»çŸ¯æ­£æ­¯ç§‘ã‚’æ¤œç´¢

    specialty: "å°å…æ­¯ç§‘" or "çŸ¯æ­£æ­¯ç§‘"
    """
    query = f"{specialty} {prefecture}"
    print(f"\nğŸ” Searching: {query}")

    search_url = "https://places.googleapis.com/v1/places:searchText"
    search_headers = {
        "X-Goog-Api-Key": API_KEY,
        "Content-Type": "application/json",
        "X-Goog-FieldMask": "places.id,places.displayName,places.formattedAddress,places.rating,places.userRatingCount,places.googleMapsUri,places.websiteUri"
    }
    search_body = {
        "textQuery": query,
        "languageCode": "ja",
        "maxResultCount": 20  # ã‚ˆã‚Šå¤šãã®å€™è£œã‚’å–å¾—
    }

    try:
        response = requests.post(search_url, headers=search_headers, json=search_body, timeout=20)

        if response.status_code != 200:
            print(f"âŒ Search failed: {response.status_code}")
            return []

        data = response.json()
        places = data.get("places", [])

        if not places:
            print("âš ï¸  No results found")
            return []

        print(f"âœ… Found {len(places)} raw candidates")

        # è©³ç´°æƒ…å ±ã‚’å–å¾—
        results = []
        for place in places:
            place_id = place.get("id")
            display_name = place.get("displayName", {}).get("text", "")
            formatted_address = place.get("formattedAddress", "")
            rating = place.get("rating", 0)
            user_rating_count = place.get("userRatingCount", 0)
            google_maps_uri = place.get("googleMapsUri", "")
            website_uri = place.get("websiteUri", "")

            # Place Details ã§éƒµä¾¿ç•ªå·å–å¾—
            postal_code = ""
            details_url = f"https://places.googleapis.com/v1/places/{place_id}"
            details_headers = {
                "X-Goog-Api-Key": API_KEY,
                "X-Goog-FieldMask": "addressComponents"
            }
            details_params = {"languageCode": "ja"}

            try:
                details_response = requests.get(details_url, headers=details_headers, params=details_params, timeout=20)
                if details_response.status_code == 200:
                    details_data = details_response.json()
                    address_components = details_data.get("addressComponents", [])
                    for component in address_components:
                        if "postal_code" in component.get("types", []):
                            postal_code = component.get("longText", "")
                            break
            except Exception as e:
                pass

            results.append({
                "åŒ»é™¢å": display_name,
                "ä½æ‰€": formatted_address,
                "éƒµä¾¿ç•ªå·": postal_code,
                "è©•ä¾¡": rating,
                "å£ã‚³ãƒŸä»¶æ•°": user_rating_count,
                "Google Maps URL": google_maps_uri,
                "å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ": website_uri,
                "æ¤œç´¢ã‚¯ã‚¨ãƒª": query
            })

        return results

    except Exception as e:
        print(f"âŒ Exception: {e}")
        return []


def filter_results(results: list) -> tuple:
    """
    çµã‚Šè¾¼ã¿æ¡ä»¶ã‚’é©ç”¨

    è¿”ã‚Šå€¤: (ãƒ•ã‚£ãƒ«ã‚¿å¾Œã®ãƒªã‚¹ãƒˆ, é™¤å¤–ã•ã‚ŒãŸãƒªã‚¹ãƒˆ)
    """
    filtered = []
    excluded = []

    for row in results:
        address = row["ä½æ‰€"]
        rating = row["è©•ä¾¡"]
        review_count = row["å£ã‚³ãƒŸä»¶æ•°"]
        clinic_name = row["åŒ»é™¢å"]

        # é™¤å¤–ç†ç”±ã‚’è¨˜éŒ²
        exclusion_reasons = []

        # 1. åŒ—æµ·é“ãƒ»æ²–ç¸„ã‚’é™¤å¤–
        if "åŒ—æµ·é“" in address or "æ²–ç¸„" in address:
            exclusion_reasons.append("åŒ—æµ·é“ãƒ»æ²–ç¸„")

        # 2. ãƒ¬ãƒ“ãƒ¥ãƒ¼ä»¶æ•° < 50
        if review_count < 50:
            exclusion_reasons.append(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼{review_count}ä»¶(<50)")

        # 3. è©•ä¾¡ < 3.0
        if rating and rating < 3.0:
            exclusion_reasons.append(f"è©•ä¾¡{rating}(<3.0)")

        # 4. å°å…ãƒ»çŸ¯æ­£é–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å«ã¾ãªã„ï¼ˆåŒ»é™¢åãƒã‚§ãƒƒã‚¯ï¼‰
        keywords = ["å°å…", "ã“ã©ã‚‚", "å­ä¾›", "ã‚­ãƒƒã‚º", "çŸ¯æ­£", "Kids"]
        has_keyword = any(kw in clinic_name for kw in keywords)

        # ãŸã ã—æ¤œç´¢ã‚¯ã‚¨ãƒªã«å«ã¾ã‚Œã¦ã„ã‚Œã°ã€åŒ»é™¢åã«ãªãã¦ã‚‚OK
        # ï¼ˆGoogleãŒé–¢é€£æ€§ã‚’åˆ¤æ–­ã—ã¦è¿”ã—ã¦ã„ã‚‹ï¼‰
        if not has_keyword:
            # ç·©å’Œ: æ¤œç´¢ã‚¯ã‚¨ãƒªã«ä¸€è‡´ã—ã¦ã„ã‚Œã°OK
            pass

        if exclusion_reasons:
            row["é™¤å¤–ç†ç”±"] = ", ".join(exclusion_reasons)
            excluded.append(row)
        else:
            filtered.append(row)

    return filtered, excluded


# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
test_prefectures = [
    "æ±äº¬éƒ½",
    "å¤§é˜ªåºœ",
    "æ„›çŸ¥çœŒ"
]

specialties = ["å°å…æ­¯ç§‘", "çŸ¯æ­£æ­¯ç§‘"]

all_results = []

for prefecture in test_prefectures:
    for specialty in specialties:
        results = search_pediatric_dental(prefecture, specialty)
        all_results.extend(results)
        print(f"  â†’ {len(results)} candidates")

print(f"\nğŸ“Š Total raw results: {len(all_results)}")

# ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
filtered, excluded = filter_results(all_results)

print(f"âœ… Filtered results: {len(filtered)}")
print(f"âŒ Excluded results: {len(excluded)}")

# CSVå‡ºåŠ›ï¼ˆãƒ•ã‚£ãƒ«ã‚¿å¾Œï¼‰
if filtered:
    output_file = "pediatric_filtered_output.csv"
    with open(output_file, 'w', encoding='utf-8', newline='') as f:
        fieldnames = ["åŒ»é™¢å", "ä½æ‰€", "éƒµä¾¿ç•ªå·", "è©•ä¾¡", "å£ã‚³ãƒŸä»¶æ•°", "Google Maps URL", "å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ", "æ¤œç´¢ã‚¯ã‚¨ãƒª"]
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for row in filtered:
            # é™¤å¤–ç†ç”±ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’å‰Šé™¤
            row_clean = {k: v for k, v in row.items() if k != "é™¤å¤–ç†ç”±"}
            writer.writerow(row_clean)
    print(f"\nâœ… Filtered results saved to: {output_file}")

# CSVå‡ºåŠ›ï¼ˆé™¤å¤–åˆ†ï¼‰
if excluded:
    excluded_file = "pediatric_excluded_output.csv"
    with open(excluded_file, 'w', encoding='utf-8', newline='') as f:
        fieldnames = ["åŒ»é™¢å", "ä½æ‰€", "è©•ä¾¡", "å£ã‚³ãƒŸä»¶æ•°", "é™¤å¤–ç†ç”±"]
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for row in excluded:
            writer.writerow({
                "åŒ»é™¢å": row["åŒ»é™¢å"],
                "ä½æ‰€": row["ä½æ‰€"],
                "è©•ä¾¡": row["è©•ä¾¡"],
                "å£ã‚³ãƒŸä»¶æ•°": row["å£ã‚³ãƒŸä»¶æ•°"],
                "é™¤å¤–ç†ç”±": row["é™¤å¤–ç†ç”±"]
            })
    print(f"ğŸ“‹ Excluded results saved to: {excluded_file}")

# çµ±è¨ˆã‚µãƒãƒªãƒ¼
print(f"\nğŸ“ˆ Statistics:")
print(f"  Total searched: {len(all_results)}")
print(f"  Passed filters: {len(filtered)} ({len(filtered)/len(all_results)*100:.1f}%)")
print(f"  Excluded: {len(excluded)} ({len(excluded)/len(all_results)*100:.1f}%)")

if filtered:
    avg_rating = sum(r["è©•ä¾¡"] for r in filtered if r["è©•ä¾¡"]) / len([r for r in filtered if r["è©•ä¾¡"]])
    avg_reviews = sum(r["å£ã‚³ãƒŸä»¶æ•°"] for r in filtered) / len(filtered)
    has_website = sum(1 for r in filtered if r["å…¬å¼ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆ"])

    print(f"\n  Filtered results quality:")
    print(f"    Average rating: â­{avg_rating:.2f}")
    print(f"    Average reviews: {avg_reviews:.0f}ä»¶")
    print(f"    Has website: {has_website}/{len(filtered)} ({has_website/len(filtered)*100:.1f}%)")
