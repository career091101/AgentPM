#!/usr/bin/env python3
"""
Claude Code ãƒãƒƒãƒãƒ©ãƒ³ãƒŠãƒ¼ - å®Ÿæˆ¦ç‰ˆ
å®Œå…¨è‡ªå‹•ã§Claude Codeã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ç®¡ç†ã—ã€ä¸¦åˆ—ã‚¿ã‚¹ã‚¯å®Ÿè¡Œ

ç‰¹å¾´:
- è¤‡æ•°ã®ãƒãƒƒãƒã‚’åŒæ™‚ä¸¦åˆ—å®Ÿè¡Œ
- å„ãƒãƒƒãƒã¯ç‹¬ç«‹ã—ãŸã‚¿ã‚¹ã‚¯ã‚»ãƒƒãƒˆã‚’æŒã¤
- è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—ç›£è¦–
- Humanä»‹å…¥å®Œå…¨ä¸è¦

ä½œæˆæ—¥: 2025-12-29
"""

import subprocess
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Optional
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import argparse


class ClaudeCodeBatchRunner:
    """Claude Codeãƒãƒƒãƒå®Ÿè¡Œãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼"""

    def __init__(
        self,
        working_dir: str,
        max_concurrent_batches: int = 5,
        timeout_seconds_per_batch: int = 8 * 60 * 60,
        claude_cmd: str = "claude",
    ):
        """
        åˆæœŸåŒ–

        Args:
            working_dir: ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
            max_concurrent_batches: åŒæ™‚å®Ÿè¡Œã™ã‚‹æœ€å¤§ãƒãƒƒãƒæ•°
            timeout_seconds_per_batch: 1ãƒãƒƒãƒã‚ãŸã‚Šã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆç§’
            claude_cmd: Claude Code CLIã®ã‚³ãƒãƒ³ãƒ‰å
        """
        self.working_dir = Path(working_dir)
        self.max_concurrent_batches = max_concurrent_batches
        self.timeout_seconds_per_batch = timeout_seconds_per_batch
        self.claude_cmd = claude_cmd
        self.flow_dir = self.working_dir / "Flow/202512/2025-12-29"
        self.log_dir = self.flow_dir / "logs"
        self.log_dir.mkdir(exist_ok=True, parents=True)

        # ãƒãƒƒãƒã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
        self.batch_status = {}
        self.lock = threading.Lock()

    def _generate_batch_prompt(self, batch_id: int, tasks: List[Dict]) -> str:
        """ãƒãƒƒãƒç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""

        prompt = f"""# Batch {batch_id} è‡ªå‹•å®Ÿè¡Œ

ä»¥ä¸‹ã®{len(tasks)}ä»¶ã®ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚’è‡ªå‹•ä½œæˆã—ã¦ãã ã•ã„ã€‚
ã™ã¹ã¦Humanä»‹å…¥ä¸è¦ã§ã€å®Œå…¨è‡ªå‹•ã§å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

## å®Ÿè¡Œè¨­å®š

- **å“è³ªåŸºæº–**: 85ç‚¹ä»¥ä¸Šã€12ã‚½ãƒ¼ã‚¹ä»¥ä¸Š
- **è‡ªå‹•ä¿å­˜**: å„ã‚¿ã‚¹ã‚¯å®Œäº†å¾Œã«è‡ªå‹•ä¿å­˜
- **ã‚¨ãƒ©ãƒ¼å‡¦ç†**: å¤±æ•—æ™‚ã¯3å›ã¾ã§ãƒªãƒˆãƒ©ã‚¤
- **ä¸¦åˆ—å®Ÿè¡Œ**: Task tool ã§å¯èƒ½ãªé™ã‚Šä¸¦åˆ—å‡¦ç†ã‚’ä½¿ç”¨

## ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆ

"""

        for idx, task in enumerate(tasks, 1):
            prompt += f"{idx}. **{task['id']}**: {task.get('name', 'N/A')}\n"

        prompt += f"""

## å®Ÿè¡Œæ‰‹é †

å„ã‚¿ã‚¹ã‚¯ã«ã¤ã„ã¦:

1. ä¼æ¥­ãƒ»å‰µæ¥­è€…ã®åŸºæœ¬æƒ…å ±ã‚’ãƒªã‚µãƒ¼ãƒ
2. CPFï¼ˆCustomer Problem Fitï¼‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
3. PSFï¼ˆProduct Solution Fitï¼‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
4. ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ
5. å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆ85ç‚¹ä»¥ä¸Šç¢ºèªï¼‰
6. ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
7. æ¬¡ã®ã‚¿ã‚¹ã‚¯ã¸é€²ã‚€

ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ãŒå®Œäº†ã—ãŸã‚‰ã€å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

**é‡è¦**: ã™ã¹ã¦ã®å‡¦ç†ã‚’è‡ªå‹•ã§å®Ÿè¡Œã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®è³ªå•ã‚„ç¢ºèªã¯ä¸€åˆ‡è¡Œã‚ãªã„ã§ãã ã•ã„ã€‚
"""

        return prompt

    def run_batch(self, batch_id: int, tasks: List[Dict]):
        """
        ãƒãƒƒãƒã‚’å®Ÿè¡Œ

        Args:
            batch_id: ãƒãƒƒãƒID
            tasks: ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆ
        """
        with self.lock:
            self.batch_status[f"Batch-{batch_id}"] = {
                'status': 'starting',
                'total_tasks': len(tasks),
                'start_time': datetime.now()
            }

        print(f"ğŸš€ Batch {batch_id} èµ·å‹•ä¸­... ({len(tasks)}ä»¶)")

        try:
            prompt = self._generate_batch_prompt(batch_id, tasks)
            log_file = self.log_dir / f"batch_{batch_id}.log"

            result = subprocess.run(
                [self.claude_cmd, "code", "-p", prompt],
                cwd=self.working_dir,
                capture_output=True,
                text=True,
                timeout=self.timeout_seconds_per_batch,
            )

            with self.lock:
                self.batch_status[f"Batch-{batch_id}"].update({
                    'status': 'completed' if result.returncode == 0 else 'failed',
                    'end_time': datetime.now(),
                    'return_code': result.returncode,
                    'log_file': str(log_file),
                })

            log_file.write_text(
                (
                    f"=== Batch {batch_id} log ===\n"
                    f"started_at: {self.batch_status[f'Batch-{batch_id}']['start_time']}\n"
                    f"ended_at: {self.batch_status[f'Batch-{batch_id}']['end_time']}\n"
                    f"return_code: {result.returncode}\n\n"
                    "----- STDOUT -----\n"
                    f"{result.stdout}\n\n"
                    "----- STDERR -----\n"
                    f"{result.stderr}\n"
                ),
                encoding="utf-8",
            )

            print(f"âœ… Batch {batch_id} å®Œäº†")

        except subprocess.TimeoutExpired:
            with self.lock:
                self.batch_status[f"Batch-{batch_id}"].update({
                    'status': 'timeout',
                    'end_time': datetime.now()
                })
            print(f"â±ï¸ Batch {batch_id} ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")

        except Exception as e:
            with self.lock:
                self.batch_status[f"Batch-{batch_id}"].update({
                    'status': 'error',
                    'end_time': datetime.now(),
                    'error': str(e)
                })
            print(f"âŒ Batch {batch_id} ã‚¨ãƒ©ãƒ¼: {e}")

    def run_parallel_batches(self, batch_assignments: List[Dict]):
        """
        è¤‡æ•°ã®ãƒãƒƒãƒã‚’ä¸¦åˆ—å®Ÿè¡Œ

        Args:
            batch_assignments: ãƒãƒƒãƒå‰²ã‚Šå½“ã¦ãƒªã‚¹ãƒˆ
        """
        print("\n" + "="*70)
        print("ğŸš€ Claude Code ä¸¦åˆ—ãƒãƒƒãƒå®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ èµ·å‹•")
        print("="*70)
        print(f"ãƒãƒƒãƒæ•°: {len(batch_assignments)}")
        print(f"é–‹å§‹æ™‚åˆ»: {datetime.now()}")
        print(f"åŒæ™‚å®Ÿè¡Œä¸Šé™: {self.max_concurrent_batches}")
        print("="*70 + "\n")

        with ThreadPoolExecutor(max_workers=self.max_concurrent_batches) as executor:
            futures = [
                executor.submit(self.run_batch, batch["batch_id"], batch["tasks"])
                for batch in batch_assignments
            ]
            for _ in as_completed(futures):
                pass

        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
        self._print_final_report()

    def _print_final_report(self):
        """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º"""
        print("\n" + "="*70)
        print("ğŸ“‹ å®Ÿè¡Œå®Œäº†ãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*70 + "\n")

        for batch_name, status in self.batch_status.items():
            print(f"{batch_name}:")
            print(f"  ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {status['status']}")
            print(f"  ã‚¿ã‚¹ã‚¯æ•°: {status['total_tasks']}")

            if 'start_time' in status and 'end_time' in status:
                duration = (status['end_time'] - status['start_time']).total_seconds() / 60
                print(f"  å®Ÿè¡Œæ™‚é–“: {duration:.1f}åˆ†")

            if 'error' in status:
                print(f"  ã‚¨ãƒ©ãƒ¼: {status['error']}")

            print()

        print("="*70 + "\n")


def load_tasks_from_files(flow_dir: Path, task_files: List[str]) -> List[Dict]:
    """ã‚¿ã‚¹ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¿ã‚¹ã‚¯ã‚’èª­ã¿è¾¼ã¿"""
    import re

    all_tasks = []

    for task_file in task_files:
        task_path = flow_dir / task_file

        if task_path.exists():
            with open(task_path, 'r', encoding='utf-8') as f:
                content = f.read()

            # å„ç¨®IDå½¢å¼ã‚’æŠ½å‡ºï¼ˆFOUNDER/PIVOT/FAILURE/EMERGINGï¼‰
            tasks = re.findall(r'- \[ \] ((?:FOUNDER|PIVOT|FAILURE|EMERGING)_\d+:.*)', content)

            for task in tasks:
                parts = task.split(':', 1)
                all_tasks.append({
                    'id': parts[0].strip(),
                    'name': parts[1].strip() if len(parts) > 1 else '',
                    'source_file': task_file
                })

    return all_tasks


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""

    parser = argparse.ArgumentParser(description="Claude Code ãƒãƒƒãƒãƒ©ãƒ³ãƒŠãƒ¼ï¼ˆã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆãªã—ï¼‰")
    parser.add_argument("--working-dir", type=str, default=str(Path(__file__).resolve().parents[3]))
    parser.add_argument("--max-concurrent-batches", type=int, default=5)
    parser.add_argument("--timeout-hours", type=float, default=8.0)
    parser.add_argument(
        "--task-files",
        nargs="*",
        default=[
            "cli1_vc_backed_tasks.md",
            "cli2_pivot_success_tasks.md",
            "cli3_failure_study_tasks.md",
            "cli4_emerging_part1_tasks.md",
            "cli5_emerging_part2_tasks.md",
        ],
    )
    parser.add_argument("--dry-run", action="store_true")
    args = parser.parse_args()

    print(
        "\n".join(
            [
                "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—",
                "â•‘         Claude Code ãƒãƒƒãƒãƒ©ãƒ³ãƒŠãƒ¼ - å®Ÿæˆ¦ç‰ˆ                       â•‘",
                "â•‘                                                                  â•‘",
                "â•‘  - .shç­‰ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆãªã—ï¼ˆclaude code -p ã‚’ç›´æ¥å®Ÿè¡Œï¼‰         â•‘",
                "â•‘  - åŒæ™‚å®Ÿè¡Œã¯æœ€å¤§Nï¼ˆæ—¢å®š5ï¼‰                                      â•‘",
                "â•‘  - Humanä»‹å…¥ä¸è¦ï¼ˆinputå¾…ã¡ãªã—ï¼‰                                 â•‘",
                "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•",
            ]
        )
    )

    working_dir = args.working_dir
    flow_dir = Path(working_dir) / "Flow/202512/2025-12-29"

    # ãƒ©ãƒ³ãƒŠãƒ¼åˆæœŸåŒ–
    runner = ClaudeCodeBatchRunner(
        working_dir=working_dir,
        max_concurrent_batches=args.max_concurrent_batches,
        timeout_seconds_per_batch=int(args.timeout_hours * 60 * 60),
    )

    # ã‚¿ã‚¹ã‚¯èª­ã¿è¾¼ã¿
    all_tasks = load_tasks_from_files(flow_dir, args.task_files)

    print(f"âœ… {len(all_tasks)}ä»¶ã®ã‚¿ã‚¹ã‚¯ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ\n")

    # ã‚¿ã‚¹ã‚¯ã‚’5ã¤ã®ãƒãƒƒãƒã«åˆ†å‰²
    batch_size = len(all_tasks) // 5 + (1 if len(all_tasks) % 5 != 0 else 0)

    batch_assignments = []
    for i in range(5):
        start_idx = i * batch_size
        end_idx = min((i + 1) * batch_size, len(all_tasks))
        batch_assignments.append({
            'batch_id': i + 1,
            'tasks': all_tasks[start_idx:end_idx]
        })

    # è¨­å®šè¡¨ç¤º
    print(f"è¨­å®š:")
    print(f"  ãƒãƒƒãƒæ•°: {len(batch_assignments)}")
    print(f"  ç·ã‚¿ã‚¹ã‚¯æ•°: {len(all_tasks)}")
    print(f"  å„ãƒãƒƒãƒæ‹…å½“: ç´„{batch_size}ä»¶\n")

    for batch in batch_assignments:
        print(f"  Batch {batch['batch_id']}: {len(batch['tasks'])}ä»¶")

    if args.dry_run:
        print("\n(dry-run) å®Ÿè¡Œã¯è¡Œã„ã¾ã›ã‚“ã€‚")
        return

    # ä¸¦åˆ—å®Ÿè¡Œ
    runner.run_parallel_batches(batch_assignments)

    print("\nâœ… ã™ã¹ã¦ã®ãƒãƒƒãƒå®Ÿè¡ŒãŒå®Œäº†ã—ã¾ã—ãŸï¼")


if __name__ == "__main__":
    main()
