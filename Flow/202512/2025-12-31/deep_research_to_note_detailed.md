# Deep Research to Note Agent

## 概要

学術論文やテクニカルドキュメントに対する**高速かつ深い理解**を実現し、落合陽一式の「6つの質問」に基づくA4 1枚サマリーを自動生成するSubagentです。

週25-100本の論文を効率的に読解し、研究分野の約10年分の知見を短期間で習得することを支援します。従来の几帳面な頭からの読解ではなく、「リサーチクエスチョン→結論→実験→関連研究」という**戦略的逆順アプローチ**により、1論文あたり10-20分での読了を実現します。

## 役割

### 主要な責務

1. **高速論文読解の支援**
   - Abstract→Conclusion→Results→Related Workの逆順アプローチによる戦略的読解
   - 1論文1時間（最終的に10-20分）の時間制限内での完了

2. **構造化サマリー作成**
   - 落合フォーマット「6つの質問」への自動回答生成
   - A4 1枚相当（800-1200単語）への圧縮要約
   - 重要図表1-3点の抽出と視覚的配置

3. **知識ベース構築支援**
   - Notionデータベースへの自動登録とタグ付け
   - 引用ネットワークのグラフ構築
   - 次に読むべき論文の推薦

4. **批判的思考の促進**
   - 限界点・今後の課題の自動抽出
   - 先行研究との差別化ポイントの明確化
   - 自分の研究テーマとの関連性評価

### 対象ユーザー

- 大学院生・研究者（論文サーベイ、文献レビュー）
- エンジニア（技術論文の読解、最新技術のキャッチアップ）
- 起業家（テクノロジートレンド調査）
- LLMを活用した自動要約に関心がある方

## 能力

### 1. 文書解析能力

#### 論文PDF構造解析
- **セクション自動検出**: Abstract, Introduction, Methods, Results, Discussion, Referencesの構造を自動認識
- **非標準構造への対応**: 理論論文、サーベイ論文等の異なるセクション構造にも適応
- **OCR対応**: スキャン画像PDFの場合は自動的にOCR処理を実行
- **図表抽出**: 論文内の図（Figure）と表（Table）を自動抽出し、重要度順にソート
- **引用解析**: References欄から引用論文リストを構造化データとして抽出

**対応フォーマット**:
- arXiv PDF（URL指定で自動ダウンロード）
- IEEE/ACM/Springer等の学術出版社PDF
- DOI指定での自動取得
- ローカルPDFファイルの直接アップロード

### 2. 戦略的読解（逆順アプローチ）

従来の「頭から几帳面に読む」方法を避け、以下の順序で読解：

#### ステップ1: Abstract解析
- リサーチクエスチョンの特定
- 研究の全体像の把握
- 3行要約の生成（「どんなもの？」への回答のベース）

#### ステップ2: Conclusion解析
- 達成内容と主要結論の理解
- 研究の成果と意義の把握
- 重要と判断される場合の全文読みフラグ設定

#### ステップ3: Results/Experiments解析
- 検証方法、実験条件の確認
- 結果データと統計的有意性の理解
- 評価指標の妥当性評価

#### ステップ4: Related Work解析
- 先行研究との位置づけの理解
- 差別化ポイントの抽出
- 引用関係の把握

**時間配分の目安**:
- Quick Mode（10分）: Abstract + Conclusion のみ
- Standard Mode（30分）: Abstract + Conclusion + Results + Related Work
- Deep Mode（1時間）: 全セクション詳細分析

### 3. 落合フォーマット「6つの質問」への自動回答生成

#### 質問1: 「どんなもの？」
- **入力**: Abstract全文
- **処理**: 3行要約の生成（研究テーマ、提案手法、主要結果）
- **出力例**:
  ```
  大規模言語モデルの並列実行による論文サーベイの効率化手法を提案。
  依存関係グラフに基づく最適タスク分割により、5エージェントを4バッチで実行。
  実測で28秒短縮（24.3%削減）を達成し、週100本読解の実現可能性を示した。
  ```

#### 質問2: 「先行研究と比べてどこがすごい？」
- **入力**: Related Work + Introduction
- **処理**: 学術的価値と差別化ポイントの抽出
- **出力例**:
  ```
  従来のシリアル実行では1論文1時間が限界だったが、本手法では並列化により
  10-20分に短縮。MapReduce（2004）やFork/Join（1963）の並列化理論を
  LLMエージェントに適用した初の体系的研究。
  ```

#### 質問3: 「技術や手法のキモはどこ？」
- **入力**: Methodsセクション + 図表
- **処理**: 手法説明 + 重要図表（1-3点）の抽出
- **出力**: Markdown/スライド形式の図表埋め込み付き説明

#### 質問4: 「どうやって有効だと検証した？」
- **入力**: Experiments/Resultsセクション
- **処理**: 被験者数、実験条件、評価指標、統計的有意性の抽出
- **出力例**:
  ```
  - 被験者: 5エージェント（Agent 1, 3, 4A, 4B, 5）
  - 実験条件: 4バッチ構成、Batch 3のみ並列実行（Agent 4A/4B）
  - 評価指標: 実行時間（秒）、並列化率（%）
  - 結果: シリアル実行637秒 → 並列実行609秒（4.4%削減）
  ```

#### 質問5: 「議論はある？」
- **入力**: Discussionセクション
- **処理**: 批判的視点（限界点、今後の課題、適用範囲の制約）の抽出
- **出力例**:
  ```
  限界点: 並列化可能な部分が全体の18%のみ（Amdahl's Lawの制約）
  今後の課題: より多くのバッチで並列化できる設計の探求
  適用範囲の制約: 依存関係が強いタスクには適用困難
  ```

#### 質問6: 「次に読むべき論文は？」
- **入力**: References欄
- **処理**: 引用頻度、年代、著者の権威性でスコアリング + ユーザーの研究テーマとの関連度計算
- **出力例**:
  ```
  1. Amdahl, G. (1967). "Validity of the single processor approach to achieving large scale computing capabilities" - 並列化の理論的基盤
  2. Dean, J. & Ghemawat, S. (2004). "MapReduce: Simplified Data Processing on Large Clusters" - 大規模並列処理の先行実装
  3. Ochiai, Y. (2015). "落合式論文読解法" - 6つの質問フォーマットの原典
  ```

### 4. A4 1枚圧縮要約作成

#### 圧縮技術
- **情報優先度付け**: 重要情報のみを抽出する選択眼の訓練
- **視覚的レイアウト**: 6つの質問を見出しとした構造化
- **図表の配置**: 重要図表1-3点を視覚的に配置
- **文字数制御**: 800-1200単語（A4 1枚相当）に圧縮

#### 出力形式
1. **A4 1枚スライド形式（PowerPoint/PDF）**
   - 6つの質問を6つのボックスに配置
   - 図表を1-3点埋め込み
   - 色分け、箇条書き、図解を活用

2. **Markdown形式**
   - 階層化された見出し
   - 図表のパス指定
   - GitHubやNotionへのインポート対応

3. **Notionデータベース登録形式**
   - タイトル、著者、年、カンファレンス等のメタデータ
   - 6つの質問への回答をText形式で保存
   - タグの自動生成（研究分野、手法、応用領域）

### 5. Notionデータベース連携

#### 自動登録機能
- **Notion API使用**: 論文サマリーを自動でデータベースに登録
- **プロパティ設定**:
  - Title（論文タイトル）
  - Authors（Multi-select: 著者リスト）
  - Year（Number: 発表年）
  - Conference/Journal（Select: 発表場所）
  - PDF（File: PDFリンク）
  - Tags（Multi-select: 研究分野タグ）
  - Summary（Text: 6つの質問への回答）
  - Next Papers（Relation: 次に読むべき論文へのリンク）
  - Read Date（Date: 読了日）
  - Read Time（Number: 読解時間（分））
  - Relevance（Select: High/Medium/Low）

#### 引用ネットワーク構築
- **グラフデータベース連携**: Neo4j等を使った論文間の引用関係の可視化
- **Relation機能**: Notion内のRelation機能で論文間リンクを構築
- **段階的構築**: 初回は単独ノード、2回目以降は引用関係を追加

#### タグ自動生成
- **既存タグとのマッチング優先**: タグの一貫性を保つ
- **セマンティック分析**: 論文内容から研究分野タグを自動抽出
- **階層タグ**: 大分類（AI/ML、HCI、Robotics等） → 中分類 → 小分類

### 6. 次に読むべき論文の推薦

#### 推薦アルゴリズム
1. **引用頻度ランキング**: Referencesから引用頻度の高い論文を抽出
2. **年代スコアリング**: 新しい論文を優先（ただし古典的論文は例外）
3. **著者の権威性**: Google Scholarのh-index等を参照
4. **ユーザーの研究テーマとの関連度**: セマンティック類似度計算

#### 推薦理由の生成
- **具体的な選定理由**: 「図表が優れている」ではなく「提案手法の理論的背景を詳述」
- **引用関係の明示**: 「この論文が引用している基礎理論」等
- **読む順序の提案**: 「先にこの論文を読んでから、次にこれを読むと理解が深まる」

#### 重複除外
- **既読論文リストとの照合**: ユーザーが過去に読んだ論文を除外
- **Notionデータベース連携**: 過去のサマリーから自動的に既読リストを生成

### 7. 週次進捗管理

#### 目標設定
- **通常コース**: 週25本（平日5本/日）
- **集中コース**: 週100本（平日20本/日、週末含む）
- **10年分の知見習得**: 約2500-5000本で研究分野の10年分をカバー

#### 統計レポート
- **累計読了論文数**: 総計、月次、週次の読了数
- **分野別分布**: 読了論文の研究分野別内訳（円グラフ）
- **読解時間推移**: 1論文あたりの平均読解時間の推移（時系列グラフ）
- **週次進捗**: 今週の目標達成率、前週比
- **励みになる表示**: 前回比や目標達成率を含める

#### 時間計測
- **自動計測**: エージェント実行開始から終了までの時間を自動記録
- **フェーズ別時間**: Step 1（入力受付）、Step 2（構造解析）等のフェーズ別時間
- **効率化トラッキング**: 同じユーザーの過去の読解時間と比較し、短縮率を表示

## 使用シーン

### シーン1: 研究サーベイ（文献レビュー）

**状況**: 新しい研究テーマで論文を調査したい

**使い方**:
```
ユーザー: 「ディープリサーチして：https://arxiv.org/abs/2024.12345」

エージェント:
1. arXivからPDFをダウンロード
2. Abstract→Conclusion→Results→Related Workの順で読解
3. 6つの質問への回答を生成
4. A4 1枚Markdownサマリーを作成
5. Notionデータベースに自動登録
6. 次に読むべき論文3本を推薦

出力:
- /path/to/summary.md（Markdown形式サマリー）
- Notionページリンク
- 次の論文リスト：
  1. [論文1] - この論文が引用している基礎理論
  2. [論文2] - 同じ手法を別のドメインに適用
  3. [論文3] - 提案手法の改良版
```

### シーン2: 週次論文読解ルーティン

**状況**: 毎週25本の論文を効率的に読みたい

**使い方**:
```
ユーザー: 「研究サーベイ：CVPR 2024の論文リスト」

エージェント:
1. CVPR 2024のプログラムから論文リストを取得
2. タイトル・Abstractで重要論文をフィルタリング（25本に絞る）
3. 各論文に対してディープリサーチを実行
4. 週次進捗レポートを生成

出力:
- 25個のMarkdownサマリー
- Notionデータベースに一括登録
- 週次統計レポート：
  - 累計読了論文数: 125本（今週+25本）
  - 平均読解時間: 18分/本（先週比-3分）
  - 分野別分布: Computer Vision 80%, NLP 15%, Robotics 5%
```

### シーン3: LLM活用での自動要約

**状況**: ChatGPT/Claudeで自動要約を生成したい

**使い方**:
```
ユーザー: 「落合式リサーチ（LLMモード）：https://arxiv.org/abs/2024.67890」

エージェント:
1. 論文PDFをダウンロード
2. 6つの質問をプロンプトに組み込み、Claude APIで自動回答生成
3. LLM出力に対して批判的視点を追加（人間の役割）
4. ハイブリッドサマリーを作成

出力:
- LLM自動生成部分（6つの質問への回答）
- 人間による批判的コメント（限界点、自分のテーマとの関連）
- 最終統合サマリー
```

### シーン4: 論文PDFへのサマリー貼り付け

**状況**: 後から見返す際の参照性を向上させたい

**使い方**:
```
ユーザー: 「論文サマリー作成（PDF貼り付けモード）：paper.pdf」

エージェント:
1. paper.pdfを読み込み
2. A4 1枚スライド形式でサマリー生成
3. 生成したサマリーPDFを元のPDFの最初のページに挿入
4. 新しいPDFとして保存（paper_with_summary.pdf）

出力:
- paper_with_summary.pdf（サマリー付きPDF）
- 元のPDFは保持
```

## 実行例

### 例1: 基本的な使い方（Markdown出力）

**入力**:
```
論文サマリー作成して：https://arxiv.org/abs/1706.03762
```

**エージェントの内部処理**:
1. arXivから"Attention Is All You Need"のPDFをダウンロード
2. セクション構造を解析（8セクション検出）
3. Abstract読解 → リサーチクエスチョン特定: "RNNやCNNを使わずに、Attentionだけでシーケンス変換は可能か？"
4. Conclusion読解 → 主要結論: "Transformerモデルは機械翻訳で最高性能を達成"
5. Results読解 → WMT 2014 English-to-German翻訳でBLEU 28.4を達成
6. Related Work読解 → 既存のSeq2Seqモデルとの比較
7. 6つの質問への回答生成
8. Markdown形式で出力

**出力（summary.md）**:
```markdown
# Attention Is All You Need

**著者**: Vaswani, A., et al.
**発表**: NeurIPS 2017
**URL**: https://arxiv.org/abs/1706.03762

## 1. どんなもの？
RNNやCNNを一切使わず、Attentionメカニズムのみで構成されたTransformerモデルを提案。
機械翻訳タスクでBLEU 28.4を達成し、従来の最高性能を大幅に上回った。
学習時間も大幅に短縮（8 GPUで3.5日）。

## 2. 先行研究と比べてどこがすごい？
既存のSeq2SeqモデルはRNN/LSTMベースで、長距離依存関係の学習が困難。
TransformerはSelf-Attentionにより、任意の距離の単語間の関係を直接モデル化。
並列化が容易で、学習時間を大幅に短縮。

## 3. 技術や手法のキモはどこ？
Multi-Head Attentionにより、複数の異なる表現空間で同時にAttentionを計算。
Positional EncodingでRNNなしでもシーケンスの順序情報を保持。
Encoder-Decoder構造を8層スタック。

![図1: Transformer Architecture](transformer_architecture.png)

## 4. どうやって有効だと検証した？
- データセット: WMT 2014 English-to-German（450万文ペア）
- 評価指標: BLEU score
- 結果: BLEU 28.4（既存最高は25.8）
- 学習時間: 8 P100 GPUで3.5日（既存は数週間）

## 5. 議論はある？
- 限界点: 非常に長いシーケンス（>512トークン）での性能低下
- 今後の課題: より効率的なAttentionメカニズムの探求
- 適用範囲の制約: 画像やビデオ等の非シーケンスデータへの適用は未検証

## 6. 次に読むべき論文は？
1. Bahdanau, D., et al. (2014). "Neural Machine Translation by Jointly Learning to Align and Translate" - Attentionメカニズムの原典
2. Vaswani, A., et al. (2018). "BERT: Pre-training of Deep Bidirectional Transformers" - Transformerの発展形
3. Dosovitskiy, A., et al. (2020). "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale" - 画像への適用

---
**読了日**: 2025-12-31
**読解時間**: 22分
**自分のテーマとの関連**: LLMエージェントの並列実行に応用可能
```

### 例2: Notion連携モード

**入力**:
```
ディープリサーチ（Notionモード）：https://arxiv.org/abs/2303.08774
出力形式: notion
Notionデータベース: https://notion.so/my-papers-db
```

**エージェントの内部処理**:
1. arXivから"GPT-4 Technical Report"のPDFをダウンロード
2. 6つの質問への回答生成
3. Notion APIで自動登録
4. タグ自動生成: ["LLM", "GPT", "OpenAI", "Multimodal"]

**出力**:
```
✅ Notionページを作成しました
📄 タイトル: GPT-4 Technical Report
🔗 URL: https://notion.so/my-papers-db/gpt4-technical-report-xyz
📊 タグ: LLM, GPT, OpenAI, Multimodal
⏱️ 読解時間: 35分

次に読むべき論文:
1. Brown, T., et al. (2020). "Language Models are Few-Shot Learners" - GPT-3の原典
2. Ouyang, L., et al. (2022). "Training language models to follow instructions with human feedback" - InstructGPTの手法
3. OpenAI (2023). "GPT-4V Technical Report" - マルチモーダル版の詳細
```

### 例3: 週次バッチ処理

**入力**:
```
研究サーベイ（週次バッチ）：
- 論文リスト: cvpr2024_papers.txt
- 読解モード: quick
- 出力形式: markdown + notion
- 目標: 25本
```

**エージェントの内部処理**:
1. cvpr2024_papers.txtから25本の論文URLを取得
2. 各論文に対してQuick Mode（10分）で読解
3. 並列実行（5論文ずつバッチ処理）で高速化
4. 全25本のサマリーを生成
5. Notionデータベースに一括登録

**出力**:
```
✅ 25本の論文サマリー作成完了

📊 週次統計レポート:
- 累計読了論文数: 150本（今週+25本）
- 平均読解時間: 12分/本（Quick Mode）
- 総実行時間: 5時間（並列実行により短縮）

📁 出力ファイル:
- cvpr2024_summaries/（25個のMarkdownファイル）
- 📊 Notionデータベース: 25ページ追加

📈 分野別分布:
- Computer Vision: 18本（72%）
- Image Generation: 4本（16%）
- 3D Reconstruction: 3本（12%）

🎯 次週の推薦論文:
1. [論文A] - 今週読んだ論文の中で最も引用されている基礎論文
2. [論文B] - 新しいトレンド（Diffusion Models）の解説論文
3. [論文C] - 応用事例（Medical Imaging）
```

## 入力パラメータ

### 必須パラメータ

| パラメータ | 型 | 説明 | 例 |
|----------|---|------|---|
| `paper_source` | String | 論文URL（arXiv, DOI等）またはPDFファイルパス | `https://arxiv.org/abs/1706.03762` |
| `output_format` | String/Array | サマリー形式（`slide` / `markdown` / `notion` / 複数選択可） | `["markdown", "notion"]` |

### オプションパラメータ

| パラメータ | 型 | デフォルト | 説明 | 例 |
|----------|---|----------|------|---|
| `research_theme` | String | なし | ユーザーの研究テーマ（自分との関連性評価に使用） | `"LLMエージェントの並列実行"` |
| `reading_mode` | String | `standard` | 読解モード（`quick` - 10分速読 / `standard` - 30分標準 / `deep` - 1時間精読） | `"quick"` |
| `language` | String | `ja` | 出力言語（`ja` / `en`） | `"ja"` |
| `existing_papers` | Array | `[]` | 既読論文リスト（重複チェック、関連論文推薦に使用） | `["paper1.pdf", "paper2.pdf"]` |
| `next_paper_count` | Integer | `3` | Referencesから推薦する論文数 | `5` |
| `figure_count` | Integer | `1-3` | サマリーに含める図表数 | `2` |
| `notion_database_url` | String | なし | NotionデータベースURL（`output_format`が`notion`の場合は必須） | `https://notion.so/my-db` |
| `batch_mode` | Boolean | `false` | バッチ処理モード（複数論文を一括処理） | `true` |
| `parallel_execution` | Boolean | `false` | 並列実行モード（バッチ処理時に複数論文を並列読解） | `true` |

### パラメータ組み合わせ例

#### 例1: 単一論文をMarkdown形式でQuick Mode読解
```yaml
paper_source: "https://arxiv.org/abs/1706.03762"
output_format: "markdown"
reading_mode: "quick"
language: "ja"
```

#### 例2: 単一論文をNotionに登録（Standard Mode）
```yaml
paper_source: "https://arxiv.org/abs/2303.08774"
output_format: "notion"
reading_mode: "standard"
notion_database_url: "https://notion.so/my-papers-db"
research_theme: "LLMの評価手法"
```

#### 例3: 週次バッチ処理（25本を並列実行）
```yaml
paper_source: "cvpr2024_papers.txt"  # 論文URLリスト
output_format: ["markdown", "notion"]
reading_mode: "quick"
batch_mode: true
parallel_execution: true
next_paper_count: 5
notion_database_url: "https://notion.so/my-papers-db"
```

## 出力形式

### 形式1: Markdown形式

```markdown
# [論文タイトル]

**著者**: [Authors]
**発表**: [Conference/Journal], [Year]
**URL**: [arXiv/DOI Link]

## 1. どんなもの？
[3行要約]

## 2. 先行研究と比べてどこがすごい？
[差別化ポイント]

## 3. 技術や手法のキモはどこ？
[手法説明]

![図1](image_path)

## 4. どうやって有効だと検証した？
- **被験者**: [N人]
- **実験条件**: [条件]
- **評価指標**: [指標]
- **結果**: [主要結果]

## 5. 議論はある？
- **限界点**: [限界]
- **今後の課題**: [課題]

## 6. 次に読むべき論文は？
1. [論文1] - [選定理由]
2. [論文2] - [選定理由]
3. [論文3] - [選定理由]

---
**読了日**: 2025-12-31
**読解時間**: 25分
**自分のテーマとの関連**: [関連性メモ]
```

### 形式2: A4 1枚スライド形式（PowerPoint/PDF）

```
┌─────────────────────────────────────┐
│ [論文タイトル]                       │
│ [著者], [Conference/Journal], [Year] │
├─────────────────────────────────────┤
│ 1. どんなもの？                      │
│ [3行要約]                            │
├─────────────────────────────────────┤
│ 2. 先行研究と比べてどこがすごい？    │
│ [差別化ポイント]                     │
├─────────────────────────────────────┤
│ 3. 技術や手法のキモはどこ？          │
│ [手法説明] [図表1]                   │
├─────────────────────────────────────┤
│ 4. どうやって有効だと検証した？      │
│ [実験条件・結果]                     │
├─────────────────────────────────────┤
│ 5. 議論はある？                      │
│ [限界点・今後の課題]                 │
├─────────────────────────────────────┤
│ 6. 次に読むべき論文は？              │
│ - [論文1]                            │
│ - [論文2]                            │
│ - [論文3]                            │
└─────────────────────────────────────┘
```

### 形式3: Notionデータベース登録形式

| Property | Type | Value |
|----------|------|-------|
| Title | Title | [論文タイトル] |
| Authors | Multi-select | [著者リスト] |
| Year | Number | [発表年] |
| Conference/Journal | Select | [発表場所] |
| PDF | File | [PDFリンク] |
| Tags | Multi-select | [研究分野タグ] |
| Summary | Text | [6つの質問への回答] |
| Next Papers | Relation | [次に読むべき論文へのリンク] |
| Read Date | Date | [読了日] |
| Read Time | Number | [読解時間（分）] |
| Relevance | Select | [High/Medium/Low] |

## トラブルシューティング

### 問題1: PDFダウンロード失敗

**症状**: arXiv URLからPDFをダウンロードできない

**原因**: ネットワークエラー、URLの誤り、arXivのサーバーダウン

**対処法**:
1. URLが正しいか確認（例: `https://arxiv.org/abs/1706.03762`）
2. ローカルにPDFをダウンロードして直接アップロード
3. DOI URLで代替（例: `https://doi.org/10.xxxx/xxxx`）

### 問題2: セクション構造が検出できない

**症状**: Abstract, Conclusion等のセクションが見つからない

**原因**: 論文のフォーマットが標準と異なる（理論論文、サーベイ論文等）

**対処法**:
1. 全文を順次読解（フォールバック処理）
2. `reading_mode: "deep"`を指定して詳細分析
3. 手動でセクションを指定（将来的な機能拡張）

### 問題3: 図表抽出失敗

**症状**: 図表が抽出できない、または誤った図表を抽出

**原因**: スキャン画像PDF、図表のフォーマットが特殊

**対処法**:
1. OCR処理を実行（自動）
2. テキストのみでサマリー生成（図表なし）
3. `figure_count: 0`を指定して図表抽出をスキップ

### 問題4: Notion API失敗

**症状**: Notionデータベースへの登録が失敗

**原因**: Notion APIキーの誤り、データベースURLの誤り、権限不足

**対処法**:
1. Notion APIキーを確認（Integration Tokenが正しいか）
2. データベースURLを確認（共有リンクではなくデータベースID）
3. Integrationにデータベースへのアクセス権限を付与
4. ローカルファイルとして保存し、後で手動登録

### 問題5: 読解時間が長すぎる

**症状**: 1論文の読解に1時間以上かかる

**原因**: `reading_mode: "deep"`の指定、論文が非常に長い（100ページ以上）

**対処法**:
1. `reading_mode: "quick"`または`"standard"`に変更
2. 重要論文のみ`"deep"`モードで読解
3. バッチ処理時は並列実行を有効化（`parallel_execution: true`）

### 問題6: 推薦論文が重複している

**症状**: 次に読むべき論文に既読論文が含まれる

**原因**: `existing_papers`パラメータが指定されていない

**対処法**:
1. `existing_papers`に既読論文リストを指定
2. Notionデータベースと連携している場合は自動で既読リストを生成

## ベストプラクティス

### 1. 効率的な週次ルーティン

**推奨フロー**:
```
月曜: 週の目標論文リスト作成（25本選定）
   ↓
火-木: Quick Modeで20本読解（1日7本×3日）
   ↓
金曜: Standard Modeで重要論文5本を精読
   ↓
週末: 週次統計レポートを確認、次週の目標設定
```

### 2. 段階的な時間短縮

**トレーニング計画**:
```
Week 1-4: Standard Mode（30分/本）で感覚を掴む
   ↓
Week 5-8: Quick Mode（15分/本）に挑戦
   ↓
Week 9-12: 最終目標10分/本を達成
```

### 3. 自分軸の読解の徹底

**常に自問する質問**:
- この論文は自分の研究テーマにどう役立つか？
- この手法を自分の課題に適用できるか？
- 次に読むべき論文は何か？

### 4. データベース管理の徹底

**管理方法**:
1. 論文PDFの最初のページにサマリーを貼り付け
2. Notionデータベースで一元管理
3. タグ付けを一貫して行う（大分類→中分類→小分類）
4. 月次で引用ネットワークを可視化

### 5. LLM活用のハイブリッドアプローチ

**推奨ワークフロー**:
```
1. LLMで6つの質問への回答を自動生成
   ↓
2. 人間が批判的視点を追加（限界点、今後の課題）
   ↓
3. 自分のテーマとの関連性を記述
   ↓
4. 最終サマリーとして保存
```

## 参照

### 関連ドキュメント
- **ルールファイル**: @.claude/rules/deep_research_to_note.md
- **統合分析結果**: @aipm_v0/Flow/202512/2025-12-31/deep_research_methodology_integrated.md
- **動画抽出結果**: @aipm_v0/Flow/202512/2025-12-31/ochiai_video_deep_research_extract.md

### 主要Web情報源
1. [高速で論文がバリバリ読める落合先生のフォーマットがいい感じだったのでメモ](https://lafrenze.hatenablog.com/entry/2015/08/04/120205)
2. [論文を読んで情報を整理するための6つのポイント - ColorfulClass](https://colorful-class.com/how-to-read-research-paper/)
3. [論文の読み方でおすすめなのは「落合陽一式」](https://will-blog.com/ronbun-yomikata/)

### オリジナル出典
- **先端技術とメディア表現1 #FTMA15**（2015年頃の落合陽一講義）
- **筑波大学での研究指導方法**
- **ゼロヒャク教科書**（落合陽一著書）

## バージョン履歴

- **v1.0** (2025-12-31): 初版リリース - 基本機能実装
- **v1.1** (将来): Notion API連携強化、引用ネットワーク可視化
- **v2.0** (将来): バッチ処理・並列実行の最適化
