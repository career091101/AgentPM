# Phase 3: ãƒªãƒã‚¹ãƒˆæŠ•ç¨¿ç”Ÿæˆ

## æ¦‚è¦

Phase 2ã§åé›†ã—ãŸæŠ•ç¨¿è©³ç´°ã¨èª¿æŸ»çµæœã‚’åŸºã«ã€takanoå¼ï¼ˆé«˜é‡ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰è§£èª¬æ–‡ä»˜ããƒªãƒã‚¹ãƒˆæŠ•ç¨¿ã‚’ç”Ÿæˆã™ã‚‹ãƒ•ã‚§ãƒ¼ã‚ºã€‚

**æ‰€è¦æ™‚é–“**: 30-40åˆ†
**ä¸¦åˆ—åŒ–**: å¯èƒ½ï¼ˆæŠ•ç¨¿æ¯ã«ä¸¦åˆ—å®Ÿè¡Œï¼‰
**æ¨å¥¨ãƒ¢ãƒ‡ãƒ«**: sonnetï¼ˆé«˜å“è³ªãªæ–‡ç« ç”Ÿæˆã«ãƒãƒ©ãƒ³ã‚¹é‡è¦–ï¼‰

---

## ç›®çš„

1. takanoå¼è§£èª¬æ–‡ï¼ˆ700-1500å­—ï¼‰ã‚’è‡ªå‹•ç”Ÿæˆ
2. é«˜é‡ãƒ¡ã‚½ãƒƒãƒ‰7è¦ç´ ã‚’ã™ã¹ã¦æº€ãŸã™ï¼ˆ70ç‚¹ä»¥ä¸Šå¿…é ˆï¼‰
3. URLåŸ‹ã‚è¾¼ã¿æ–¹å¼ã§ãƒªãƒã‚¹ãƒˆæŠ•ç¨¿JSONã‚’ç”Ÿæˆ
4. 4-6ä»¶ã®æœ€çµ‚æŠ•ç¨¿æ¡ˆã‚’é¸å®š

---

## å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«

### `tweet_details_full_{date}.json`

æŠ•ç¨¿è©³ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆPhase 2å‡ºåŠ›ï¼‰ã€‚

**ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: `Flow/{YYYYMM}/{YYYY-MM-DD}/tweet_details_full_{date}.json`

### `reply_insights_{date}.json`

ãƒªãƒ—ãƒ©ã‚¤åˆ†æçµæœï¼ˆPhase 2å‡ºåŠ›ï¼‰ã€‚

### `research_findings_{date}.json`

Webèª¿æŸ»çµæœï¼ˆPhase 2å‡ºåŠ›ï¼‰ã€‚

---

## å‡¦ç†ãƒ•ãƒ­ãƒ¼

### STEP 1: æŠ•ç¨¿é¸å®šï¼ˆ4-6ä»¶ï¼‰

ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆé †ã«ä¸Šä½4-6ä»¶ã‚’é¸å®šã€‚

```python
import json

# Phase 2å‡ºåŠ›èª­ã¿è¾¼ã¿
with open('Flow/{date_path}/tweet_details_full_{date}.json', 'r') as f:
    tweet_details = json.load(f)

with open('Flow/{date_path}/reply_insights_{date}.json', 'r') as f:
    reply_insights = json.load(f)

with open('Flow/{date_path}/research_findings_{date}.json', 'r') as f:
    research_findings = json.load(f)

# repost_config.jsonã‹ã‚‰æœ€çµ‚é¸å®šæ•°èª­ã¿è¾¼ã¿
with open('.claude/skills/x-deck-repost-automation/repost_config.json', 'r') as f:
    config = json.load(f)

final_selection = config['data_collection']['final_selection']  # 6

# ä¸Šä½6ä»¶ã‚’é¸å®š
selected_tweets = tweet_details['tweets'][:final_selection]

print(f"æœ€çµ‚é¸å®š: {len(selected_tweets)}ä»¶")
```

### STEP 2: takanoå¼è§£èª¬æ–‡ç”Ÿæˆ

**ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå‚ç…§**: `../takano_repost_template.md`

#### 2.1 ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰

å„æŠ•ç¨¿ã«å¯¾ã—ã¦ã€takanoå¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã«åŸºã¥ããƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰ã€‚

```python
# takano_repost_template.mdã‚’èª­ã¿è¾¼ã¿
with open('.claude/skills/x-deck-repost-automation/takano_repost_template.md', 'r') as f:
    template = f.read()

repost_drafts = []

for tweet in selected_tweets:
    # ãƒªãƒ—ãƒ©ã‚¤åˆ†æãƒ»Webèª¿æŸ»çµæœã‚’çµ±åˆ
    reply_insight = next((r for r in reply_insights['insights'] if r['tweet_url'] == tweet['url']), {})
    research_finding = next((r for r in research_findings['findings'] if r['tweet_url'] == tweet['url']), {})

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    prompt = f"""
{template}

## å…ƒãƒ„ã‚¤ãƒ¼ãƒˆæƒ…å ±

**æŠ•ç¨¿è€…**: @{tweet['author']} ({tweet['author_name']})
**URL**: {tweet['url']}
**ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ**: {tweet['impressions']:,}ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã€{tweet['likes']:,}ã„ã„ã­ã€{tweet['retweets']:,}RT

**å…¨æ–‡**:
---
{tweet['full_text']}
---

**æ·»ä»˜ãƒ¡ãƒ‡ã‚£ã‚¢**: {json.dumps(tweet.get('media_items', []), ensure_ascii=False)}

**ãƒªãƒ—ãƒ©ã‚¤åˆ†æçµæœ**:
{json.dumps(reply_insight.get('insights', {}), indent=2, ensure_ascii=False)}

**Webèª¿æŸ»çµæœ**:
{json.dumps(research_finding.get('findings', {}), indent=2, ensure_ascii=False)}

## ä½œæˆæŒ‡ç¤º

ä¸Šè¨˜ã®æƒ…å ±ã‚’åŸºã«ã€takanoå¼è§£èª¬æ–‡ï¼ˆ700-1500å­—ï¼‰ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

**é‡è¦**:
- é«˜é‡ãƒ¡ã‚½ãƒƒãƒ‰7è¦ç´ ï¼ˆHook/Data/Empathy/Insight/Advice/Question/Proper nounsï¼‰ã‚’å¿…ãšæº€ãŸã™
- ç·åˆç‚¹70ç‚¹ä»¥ä¸Šã‚’ç›®æŒ‡ã™
- ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«ãƒ»è¦ªã—ã¿ã‚„ã™ã„ãƒˆãƒ¼ãƒ³ï¼ˆã€Œãƒã‚¸ã§ã€ã€Œãƒ¤ãƒã„ã€æ–­å®šå‹ï¼‰
- CEOãƒ»çµŒå–¶è€…å‘ã‘ã®ãƒ“ã‚¸ãƒã‚¹æˆ¦ç•¥è¦³ç‚¹
- å›ºæœ‰åè©10å€‹ä»¥ä¸Šã€æ•°å€¤5å€‹ä»¥ä¸Šå¿…é ˆ

**å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**:
ä»¥ä¸‹ã®å½¢å¼ã§1æ¡ˆã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

---

## Xé•·æ–‡ãƒªãƒã‚¹ãƒˆæŠ•ç¨¿æ¡ˆï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³X: [é¸æŠã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³å]ï¼‰

**ãƒˆãƒ”ãƒƒã‚¯**: [å…ƒãƒ„ã‚¤ãƒ¼ãƒˆã®è¦ç´„ã‚¿ã‚¤ãƒˆãƒ«]

---

[takanoå¼è§£èª¬æ–‡ï¼ˆ700-1500å­—ï¼‰]

ğŸ”— å…ƒã®æŠ•ç¨¿: {tweet['url']}

---

## å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆè‡ªå·±è©•ä¾¡ï¼‰

| è¦ç´  | é…ç‚¹ | è‡ªå·±è©•ä¾¡ | ç¢ºèªé …ç›® |
|------|------|---------|---------|
| Hook | 15ç‚¹ | X/15ç‚¹ | å†’é ­ã§æ³¨æ„ã‚’å¼•ã‘ã¦ã„ã‚‹ã‹ |
| Data/Evidence | 20ç‚¹ | X/20ç‚¹ | æ•°å€¤5å€‹ä»¥ä¸Šã€ä¼æ¥­å3ç¤¾ä»¥ä¸Š |
| Empathy | 10ç‚¹ | X/10ç‚¹ | CEOå‘ã‘å…±æ„Ÿè¦ç´  |
| Insight | 15ç‚¹ | X/15ç‚¹ | ã€Œã¤ã¾ã‚Šã€ã€Œãƒã‚¤ãƒ³ãƒˆã¯ã€ã§æ´å¯Ÿ |
| Advice | 10ç‚¹ | X/10ç‚¹ | å…·ä½“çš„è¡Œå‹•ææ¡ˆ |
| Question ending | 15ç‚¹ | X/15ç‚¹ | CEOå‘ã‘å•ã„ã‹ã‘ |
| Proper nouns | 15ç‚¹ | X/15ç‚¹ | å›ºæœ‰åè©10å€‹ä»¥ä¸Š |
| **ç·åˆç‚¹** | **100ç‚¹** | **X/100ç‚¹** | **70ç‚¹ä»¥ä¸Šã§åˆæ ¼** |

**æ–‡å­—æ•°**: {{å®Ÿéš›ã®æ–‡å­—æ•°}}å­—ï¼ˆç›®æ¨™: 700-1500å­—ï¼‰

**å›ºæœ‰åè©ãƒªã‚¹ãƒˆ**: [ä½¿ç”¨ã—ãŸå›ºæœ‰åè©10å€‹ä»¥ä¸Š]

---
    """

    # LLMå®Ÿè¡Œï¼ˆtakanoå¼è§£èª¬æ–‡ç”Ÿæˆï¼‰
    generated_content = llm_generate(
        prompt=prompt,
        model="sonnet",
        temperature=0.7,
        max_tokens=4000
    )

    repost_drafts.append({
        'tweet_url': tweet['url'],
        'tweet_rank': tweet['rank'],
        'generated_content': generated_content
    })

print(f"è§£èª¬æ–‡ç”Ÿæˆå®Œäº†: {len(repost_drafts)}ä»¶")
```

#### 2.2 å“è³ªãƒã‚§ãƒƒã‚¯ï¼ˆ70ç‚¹ä»¥ä¸Šå¿…é ˆï¼‰

ç”Ÿæˆã•ã‚ŒãŸè§£èª¬æ–‡ã®å“è³ªã‚’è‡ªå‹•è©•ä¾¡ã€‚

```python
approved_drafts = []

for draft in repost_drafts:
    content = draft['generated_content']

    # å“è³ªãƒã‚§ãƒƒã‚¯è¡¨ã‚’ãƒ‘ãƒ¼ã‚¹
    quality_check = parse_quality_check(content)

    if quality_check['total_score'] >= 70:
        draft['quality_score'] = quality_check['total_score']
        draft['quality_details'] = quality_check
        approved_drafts.append(draft)
        print(f"âœ“ Rank {draft['tweet_rank']}: {quality_check['total_score']}ç‚¹ - åˆæ ¼")
    else:
        print(f"âœ— Rank {draft['tweet_rank']}: {quality_check['total_score']}ç‚¹ - ä¸åˆæ ¼ï¼ˆå†ç”Ÿæˆï¼‰")
        # å†ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¾Œè¿°ï¼‰

print(f"åˆæ ¼æŠ•ç¨¿: {len(approved_drafts)}ä»¶")
```

#### 2.3 ä¸åˆæ ¼æ™‚ã®å†ç”Ÿæˆ

70ç‚¹æœªæº€ã®å ´åˆã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ã—ã¦å†ç”Ÿæˆï¼ˆæœ€å¤§2å›ï¼‰ã€‚

```python
def regenerate_with_feedback(draft, max_retries=2):
    """å“è³ªä¸è¶³æ™‚ã®å†ç”Ÿæˆ"""
    quality_score = parse_quality_check(draft['generated_content'])['total_score']

    for retry in range(1, max_retries + 1):
        if quality_score >= 70:
            return draft

        # ä¸è¶³è¦ç´ ã‚’ç‰¹å®š
        weak_elements = [
            elem for elem, score in quality_score['details'].items()
            if score < elem['threshold']
        ]

        # ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        feedback_prompt = f"""
å‰å›ã®ç”ŸæˆçµæœãŒå“è³ªåŸºæº–ï¼ˆ70ç‚¹ï¼‰ã‚’æº€ãŸã—ã¦ã„ã¾ã›ã‚“ã§ã—ãŸã€‚

**å‰å›ã®ç·åˆç‚¹**: {quality_score}ç‚¹

**ä¸è¶³è¦ç´ **:
{json.dumps(weak_elements, indent=2, ensure_ascii=False)}

**æ”¹å–„æŒ‡ç¤º**:
- {weak_elements[0]}: [å…·ä½“çš„ãªæ”¹å–„æ–¹æ³•]
- {weak_elements[1]}: [å…·ä½“çš„ãªæ”¹å–„æ–¹æ³•]

ä¸Šè¨˜ã‚’è¸ã¾ãˆã€takanoå¼è§£èª¬æ–‡ã‚’å†ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
        """

        # å†ç”Ÿæˆ
        regenerated = llm_generate(
            prompt=original_prompt + "\n\n" + feedback_prompt,
            model="sonnet",
            temperature=0.7,
            max_tokens=4000
        )

        draft['generated_content'] = regenerated
        quality_score = parse_quality_check(regenerated)['total_score']

        print(f"  å†ç”Ÿæˆ {retry}å›ç›®: {quality_score}ç‚¹")

    return draft
```

### STEP 3: ãƒªãƒã‚¹ãƒˆæŠ•ç¨¿JSONç”Ÿæˆ

**Late APIä»•æ§˜**: URLåŸ‹ã‚è¾¼ã¿æ–¹å¼ï¼ˆå¼•ç”¨ãƒªãƒã‚¹ãƒˆæœªå¯¾å¿œã®ãŸã‚ï¼‰

```python
import datetime

# æŠ•ç¨¿æ™‚é–“å¸¯è¨­å®šèª­ã¿è¾¼ã¿
time_slots = config['posting']['time_slots']

# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç”Ÿæˆï¼ˆç¿Œæ—¥ã®æŠ•ç¨¿æ™‚é–“ï¼‰
tomorrow = datetime.datetime.now() + datetime.timedelta(days=1)
tomorrow_str = tomorrow.strftime('%Y-%m-%d')

schedule = []
for slot_config in time_slots:
    for time_str in slot_config['slots']:
        schedule.append(f"{tomorrow_str}T{time_str}:00+09:00")

# æŠ•ç¨¿JSONç”Ÿæˆ
repost_posts = []

for i, draft in enumerate(approved_drafts[:6]):  # æœ€å¤§6ä»¶
    # takanoå¼è§£èª¬æ–‡ã‚’æŠ½å‡ºï¼ˆå“è³ªãƒã‚§ãƒƒã‚¯è¡¨ã®å‰ã¾ã§ï¼‰
    content_text = extract_content_text(draft['generated_content'])

    # URLåŸ‹ã‚è¾¼ã¿
    url_embed = f"\n\nğŸ”— å…ƒã®æŠ•ç¨¿: {draft['tweet_url']}"
    full_content = content_text + url_embed

    # Late APIä»•æ§˜æº–æ‹ ã®JSON
    post_json = {
        "content": full_content,
        "platforms": [
            {
                "platform": "twitter",
                "accountId": "LATE_TWITTER_ACCOUNT_ID"  # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
            }
        ],
        "scheduledFor": schedule[i] if i < len(schedule) else schedule[-1],
        "timezone": "Asia/Tokyo"
    }

    repost_posts.append({
        'tweet_url': draft['tweet_url'],
        'tweet_rank': draft['tweet_rank'],
        'quality_score': draft['quality_score'],
        'scheduled_time': schedule[i] if i < len(schedule) else schedule[-1],
        'post_json': post_json
    })

print(f"æŠ•ç¨¿JSONç”Ÿæˆå®Œäº†: {len(repost_posts)}ä»¶")
```

---

## å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«

### `repost_drafts_{date}.json`

ãƒªãƒã‚¹ãƒˆæŠ•ç¨¿æ¡ˆï¼ˆ4-6ä»¶ï¼‰ã€‚

**ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹**: `Flow/{YYYYMM}/{YYYY-MM-DD}/repost_drafts_{date}.json`

**ãƒ‡ãƒ¼ã‚¿æ§‹é€ **:
```json
{
  "generated_at": "2026-01-12T14:00:00+09:00",
  "total_drafts": 6,
  "drafts": [
    {
      "tweet_url": "https://x.com/username/status/123456789",
      "tweet_rank": 1,
      "quality_score": 85,
      "quality_details": {
        "hook": 14,
        "data_evidence": 19,
        "empathy": 9,
        "insight": 14,
        "advice": 9,
        "question_ending": 14,
        "proper_nouns": 14,
        "total": 85
      },
      "scheduled_time": "2026-01-13T07:30:00+09:00",
      "post_json": {
        "content": "[takanoå¼è§£èª¬æ–‡]\n\nğŸ”— å…ƒã®æŠ•ç¨¿: https://x.com/username/status/123456789",
        "platforms": [
          {
            "platform": "twitter",
            "accountId": "LATE_TWITTER_ACCOUNT_ID"
          }
        ],
        "scheduledFor": "2026-01-13T07:30:00+09:00",
        "timezone": "Asia/Tokyo"
      },
      "generated_content_full": "[å®Œå…¨ãªç”Ÿæˆçµæœãƒ†ã‚­ã‚¹ãƒˆ]"
    },
    ...
  ],
  "rejected_drafts": [
    {
      "tweet_rank": 7,
      "quality_score": 65,
      "reason": "ç·åˆç‚¹70ç‚¹æœªæº€ã€2å›å†ç”Ÿæˆå¾Œã‚‚åŸºæº–æœªé”"
    }
  ]
}
```

---

## ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### ã‚¨ãƒ©ãƒ¼1: å“è³ªåŸºæº–æœªé”ï¼ˆ70ç‚¹æœªæº€ï¼‰

**å¯¾ç­–**: æœ€å¤§2å›å†ç”Ÿæˆã€ãã‚Œã§ã‚‚ä¸åˆæ ¼ãªã‚‰æ¬¡ã®æŠ•ç¨¿ã«é€²ã‚€

```python
for draft in repost_drafts:
    # åˆå›ç”Ÿæˆ
    quality_score = check_quality(draft)

    if quality_score < 70:
        # å†ç”Ÿæˆï¼ˆæœ€å¤§2å›ï¼‰
        draft = regenerate_with_feedback(draft, max_retries=2)

        if check_quality(draft) >= 70:
            approved_drafts.append(draft)
        else:
            # ä¸åˆæ ¼è¨˜éŒ²
            rejected_drafts.append({
                'tweet_rank': draft['tweet_rank'],
                'quality_score': check_quality(draft),
                'reason': '2å›å†ç”Ÿæˆå¾Œã‚‚å“è³ªåŸºæº–æœªé”'
            })
```

### ã‚¨ãƒ©ãƒ¼2: æ–‡å­—æ•°è¶…éãƒ»ä¸è¶³

**ã‚¨ãƒ©ãƒ¼**: 700å­—æœªæº€ã¾ãŸã¯1500å­—è¶…é

```python
# å¯¾ç­–: æ–‡å­—æ•°èª¿æ•´ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
if len(content_text) < 700:
    adjustment_prompt = f"""
ç¾åœ¨{len(content_text)}å­—ã§ã™ã€‚700å­—ä»¥ä¸Šã«æ‹¡å……ã—ã¦ãã ã•ã„ã€‚

**è¿½åŠ æŒ‡ç¤º**:
- Data/Evidence ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«å…·ä½“ä¾‹ã‚’è¿½åŠ 
- Insight ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§æ´å¯Ÿã‚’æ·±æ˜ã‚Š
    """
elif len(content_text) > 1500:
    adjustment_prompt = f"""
ç¾åœ¨{len(content_text)}å­—ã§ã™ã€‚1500å­—ä»¥å†…ã«è¦ç´„ã—ã¦ãã ã•ã„ã€‚

**å‰Šæ¸›æŒ‡ç¤º**:
- é‡è¤‡è¡¨ç¾ã‚’å‰Šé™¤
- å†—é•·ãªèª¬æ˜ã‚’ç°¡æ½”åŒ–
    """
```

### ã‚¨ãƒ©ãƒ¼3: å›ºæœ‰åè©ãƒ»æ•°å€¤ä¸è¶³

**ã‚¨ãƒ©ãƒ¼**: å›ºæœ‰åè©10å€‹æœªæº€ã€æ•°å€¤5å€‹æœªæº€

```python
# å¯¾ç­–: ä¸è¶³è¦ç´ ã®è£œå®Œãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
if proper_nouns_count < 10:
    supplement_prompt = f"""
ç¾åœ¨ã®å›ºæœ‰åè©: {proper_nouns_count}å€‹ï¼ˆç›®æ¨™: 10å€‹ä»¥ä¸Šï¼‰

**è¿½åŠ æŒ‡ç¤º**:
- é–¢é€£ä¼æ¥­åã‚’è¿½åŠ ï¼ˆGoogle, Microsoft, OpenAIç­‰ï¼‰
- äººåã‚’è¿½åŠ ï¼ˆã‚µãƒ ãƒ»ã‚¢ãƒ«ãƒˆãƒãƒ³ã€ã‚µãƒ†ã‚£ã‚¢ãƒ»ãƒŠãƒ‡ãƒ©ç­‰ï¼‰
- è£½å“åã‚’è¿½åŠ ï¼ˆChatGPT, Azure, DeepMindç­‰ï¼‰
    """

if numbers_count < 5:
    supplement_prompt += f"""
ç¾åœ¨ã®æ•°å€¤ãƒ‡ãƒ¼ã‚¿: {numbers_count}å€‹ï¼ˆç›®æ¨™: 5å€‹ä»¥ä¸Šï¼‰

**è¿½åŠ æŒ‡ç¤º**:
- é‡‘é¡ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
- æˆé•·ç‡ã‚’è¿½åŠ 
- ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ãƒ»å¸‚å ´è¦æ¨¡ã‚’è¿½åŠ 
    """
```

---

## ä¸¦åˆ—åŒ–æˆ¦ç•¥

### æŠ•ç¨¿æ¯ã®ä¸¦åˆ—ç”Ÿæˆ

6ä»¶ã®æŠ•ç¨¿ã‚’ä¸¦åˆ—ç”Ÿæˆï¼ˆæœ€å¤§5ä¸¦åˆ—ï¼‰ã€‚

**å®Ÿè£…ä¾‹**:
```python
from concurrent.futures import ThreadPoolExecutor

def generate_repost_for_tweet(tweet, reply_insight, research_finding):
    """1ã¤ã®æŠ•ç¨¿ã®ãƒªãƒã‚¹ãƒˆè§£èª¬æ–‡ã‚’ç”Ÿæˆ"""
    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
    # LLMå®Ÿè¡Œ
    # å“è³ªãƒã‚§ãƒƒã‚¯
    # å†ç”Ÿæˆï¼ˆå¿…è¦æ™‚ï¼‰
    return draft

# ä¸¦åˆ—å®Ÿè¡Œ
with ThreadPoolExecutor(max_workers=5) as executor:
    futures = [
        executor.submit(
            generate_repost_for_tweet,
            tweet,
            get_reply_insight(tweet['url']),
            get_research_finding(tweet['url'])
        )
        for tweet in selected_tweets
    ]

    # çµæœåé›†
    repost_drafts = [future.result() for future in futures]

# ä¸¦åˆ—å®Ÿè¡Œã«ã‚ˆã‚Šã€30-40åˆ† â†’ 12-16åˆ†ã«çŸ­ç¸®å¯èƒ½
```

---

## ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### æœ€é©åŒ–1: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°

åŒä¸€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’å†åˆ©ç”¨ï¼ˆAnthropic Prompt Cachingï¼‰ã€‚

```python
# takano_repost_template.mdã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
cached_template = cache_prompt(template)

# å„æŠ•ç¨¿ã§å†åˆ©ç”¨
for tweet in selected_tweets:
    prompt = build_prompt(cached_template, tweet, ...)
```

### æœ€é©åŒ–2: å“è³ªãƒã‚§ãƒƒã‚¯ã®è‡ªå‹•ãƒ‘ãƒ¼ã‚¹

ç”Ÿæˆçµæœã‹ã‚‰JSONå½¢å¼ã§å“è³ªã‚¹ã‚³ã‚¢ã‚’æŠ½å‡ºã€‚

```python
def parse_quality_check(generated_content):
    """å“è³ªãƒã‚§ãƒƒã‚¯è¡¨ã‚’ãƒ‘ãƒ¼ã‚¹ã—ã¦JSONã«å¤‰æ›"""
    # ãƒ†ãƒ¼ãƒ–ãƒ«éƒ¨åˆ†ã‚’æŠ½å‡º
    table_match = re.search(r'\| è¦ç´  \| é…ç‚¹ \| è‡ªå·±è©•ä¾¡ \|.*?\| \*\*ç·åˆç‚¹\*\* \| \*\*100ç‚¹\*\* \| \*\*(\d+)/100ç‚¹\*\*', generated_content, re.DOTALL)

    if not table_match:
        return {'total_score': 0, 'details': {}}

    total_score = int(table_match.group(1))

    # å„è¦ç´ ã®ã‚¹ã‚³ã‚¢ã‚’æŠ½å‡º
    # ...

    return {
        'total_score': total_score,
        'details': {...}
    }
```

---

## æ¤œè¨¼é …ç›®

Phase 3å®Œäº†æ™‚ã«ä»¥ä¸‹ã‚’ç¢ºèª:

- [ ] takanoå¼è§£èª¬æ–‡ï¼ˆ700-1500å­—ï¼‰ã‚’ç”Ÿæˆã§ããŸã‹
- [ ] é«˜é‡ãƒ¡ã‚½ãƒƒãƒ‰7è¦ç´ ã‚’ã™ã¹ã¦æº€ãŸã—ãŸã‹
- [ ] ç·åˆç‚¹70ç‚¹ä»¥ä¸Šã®æŠ•ç¨¿ã‚’4-6ä»¶ç”Ÿæˆã§ããŸã‹
- [ ] URLåŸ‹ã‚è¾¼ã¿æ–¹å¼ã®Late API JSONå½¢å¼ã§å‡ºåŠ›ã§ããŸã‹
- [ ] å›ºæœ‰åè©10å€‹ä»¥ä¸Šã€æ•°å€¤5å€‹ä»¥ä¸Šã‚’å«ã‚€ã‹
- [ ] ä¸åˆæ ¼æŠ•ç¨¿ã®å†ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ãŒå‹•ä½œã—ãŸã‹
- [ ] å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ`repost_drafts_{date}.json`ï¼‰ãŒç”Ÿæˆã•ã‚ŒãŸã‹

---

## takanoå¼7è¦ç´ ã®å®Ÿè£…ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### 1. Hookï¼ˆ15ç‚¹ï¼‰

- [ ] è¡æ’ƒçš„æ•°å­—ã‚’å†’é ­ã«é…ç½®
- [ ] ä¼æ¥­åã‚’æ˜è¨˜
- [ ] æ–­å®šå‹ã®æ–‡ä½“ï¼ˆã€Œã€œã ã€‚ã€ã€Œã€œã§ã‚ã‚‹ã€‚ã€ï¼‰
- [ ] 100-150å­—ã®ç¯„å›²å†…

### 2. Data/Evidenceï¼ˆ20ç‚¹ï¼‰

- [ ] å…·ä½“çš„æ•°å€¤5å€‹ä»¥ä¸Š
- [ ] ä¼æ¥­å3ç¤¾ä»¥ä¸Š
- [ ] å‡ºå…¸æ˜è¨˜ï¼ˆå…ƒãƒ„ã‚¤ãƒ¼ãƒˆã€è¨˜äº‹ã€ãƒ¬ãƒãƒ¼ãƒˆï¼‰
- [ ] 300-500å­—ã®ç¯„å›²å†…

### 3. Empathyï¼ˆ10ç‚¹ï¼‰

- [ ] CEOãƒ»çµŒå–¶è€…ã®ç—›ã¿ãƒ»ä¸å®‰ãƒ»æ¬²æ±‚ã«è¨€åŠ
- [ ] ã€ŒCEOãªã‚‰ã€œã€ã€ŒçµŒå–¶è€…ãªã‚‰ã€œã€ã®å…±æ„Ÿå–šèµ·

### 4. Insightï¼ˆ15ç‚¹ï¼‰

- [ ] ã€Œã¤ã¾ã‚Šã€ã€Œãƒã‚¤ãƒ³ãƒˆã¯ã€ã§è‡ªå·±è§£é‡ˆ
- [ ] 3ã¤ã®ãƒã‚¤ãƒ³ãƒˆã§æ§‹é€ åŒ–
- [ ] 200-400å­—ã®ç¯„å›²å†…

### 5. Adviceï¼ˆ10ç‚¹ï¼‰

- [ ] å…·ä½“çš„ãªè¡Œå‹•ææ¡ˆ3ã¤
- [ ] ã€Œä»Šã™ãã§ãã‚‹ã“ã¨ã€ã€Œæ¬¡ã®ä¸€æ‰‹ã€ã‚’æ˜ç¤º

### 6. Question endingï¼ˆ15ç‚¹ï¼‰

- [ ] CEOå‘ã‘å•ã„ã‹ã‘ã§ç· ã‚ããã‚‹
- [ ] ã€Œã‚ãªãŸã¯ã©ã†æ€ã†ï¼Ÿã€ã€Œç”Ÿãæ®‹ã‚Œã‚‹ï¼Ÿã€
- [ ] 100-200å­—ã®ç¯„å›²å†…

### 7. Proper nounsï¼ˆ15ç‚¹ï¼‰

- [ ] å›ºæœ‰åè©10å€‹ä»¥ä¸Šä½¿ç”¨
- [ ] ä¼æ¥­åã€ã‚µãƒ¼ãƒ“ã‚¹åã€äººåã€è£½å“åç­‰

---

## æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

Phase 3å®Œäº†å¾Œã€Phase 4ï¼ˆLate APIäºˆç´„æŠ•ç¨¿ï¼‰ã«é€²ã‚€:
- Late APIçµŒç”±ã§4-6æŠ•ç¨¿ã‚’äºˆç´„æŠ•ç¨¿
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼ˆæŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ãƒªãƒˆãƒ©ã‚¤ï¼‰
- æŠ•ç¨¿çµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

**æ¬¡ã®Phase**: `phases/phase4_late_api_scheduling.md`

---

## å‚ç…§

- **ãƒ¡ã‚¤ãƒ³Skillå®šç¾©**: `../SKILL.md`
- **takanoå¼ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ**: `../takano_repost_template.md`
- **è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«**: `../repost_config.json`
- **æ—¢å­˜ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**: `Stock/programs/å‰¯æ¥­/projects/SNS/æŠ•ç¨¿æ–‡ä½œæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ_v6_takano_refined`
- **Anthropic Prompt Caching**: https://docs.anthropic.com/en/docs/prompt-caching
