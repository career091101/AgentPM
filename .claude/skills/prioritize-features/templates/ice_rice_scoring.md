# ICE/RICEスコアリング ワークシート

**プロダクト名**:
**対象機能数**:
**評価日**:
**評価者**:

---

## 評価方法ガイド

### STEP 1: ICEスコアリング（各軸1-10点）

すべての機能を3軸（Impact/Confidence/Ease）で評価します。

#### Impact（ビジネスインパクト）の判定基準

各点数に対応する具体的な基準を以下に示します。

| 点数 | 基準 | KPI影響 | 具体例 |
|------|------|--------|--------|
| **10** | ビジネスモデルの根幹 | LTV 2倍以上 | 決済機能、ユーザー認証 |
| **9** | 主要KPI大幅改善 | MRR/MAU 40-50%向上 | リアルタイム通知、AIレコメンデーション |
| **8** | 主要KPI改善 | MRR/MAU 20-40%向上 | 多言語対応、新コンテンツタイプ |
| **7** | 重要な改善効果 | MRR/MAU 10-20%向上 | ダークモード、プロフィール機能 |
| **6** | 補助的だが重要 | Retention 10%向上、Churn 2%削減 | 検索フィルター、アクティビティログ |
| **5** | 中程度の改善 | Retention 5%向上 | ホットキー設定 |
| **4** | やや限定的 | ニッチなユーザーセグメント向け | メール通知カスタマイズ |
| **1-3** | Nice-to-have、微小な改善 | 特定ユーザー向けのみ | UI微調整、色スキーム |

#### Confidence（確信度）の判定基準

データに基づく確信の程度を評価します。

| 点数 | 基準 | 根拠 | 最低サンプル数 |
|------|------|------|---------------|
| **10** | ほぼ確実 | A/Bテスト成功、成功事例多数 | A/B N=500+ |
| **9** | 非常に高い確信 | A/Bテスト成功、競合成功事例 | A/B N=200+ |
| **8** | 高い確信 | 複数ユーザーインタビュー支持（70%以上）| インタビュー N=10+ |
| **7** | かなり確信 | ユーザーインタビュー支持（50-70%）、競合事例 | インタビュー N=8+ |
| **6** | 中程度の確信 | ユーザーインタビュー支持（30-50%）、仮説段階 | インタビュー N=5+ |
| **5** | やや低い確信 | インタビュー支持数が少ない（20-30%） | インタビュー N=3-5 |
| **4** | 低い確信 | 推測、社内アイデア | アンケート or 仮説のみ |
| **1-3** | 非常に低い確信 | 根拠なし、想像のみ | 根拠データなし |

#### Ease（実装容易性）の判定基準

開発の複雑さと必要期間を評価します。

| 点数 | 基準 | 実装期間 | 技術的複雑度 | 外部依存 | 例 |
|------|------|---------|------------|--------|-----|
| **10** | ほぼ自動化 | 1日以内 | なし | なし | 設定変更、既存オプション有効化 |
| **9** | 極めて簡単 | 2-3日 | 最小 | 小 | UI調整、ローカル設定 |
| **8** | 非常に簡単 | 1週間以内 | 低 | 小 | 既存コード軽微修正 |
| **7** | 簡単 | 1-2週間 | 低 | 中 | 新規ページ追加（既存パターン） |
| **6** | 中程度 | 2-3週間 | 中 | 中 | 新規API開発 |
| **5** | やや難 | 3-4週間 | 中 | 大 | DB設計変更を伴う機能 |
| **4** | 難 | 1-2ヶ月 | 高 | 大 | 新技術スタック導入 |
| **1-3** | 非常に難 | 2ヶ月以上 | 非常に高い | 非常に大 | アーキテクチャ全面改修 |

**判定のチェックリスト**:
- [ ] 既存コードベースで実装できるか、新規開発が必要か
- [ ] 外部サービス・API連携の必要性
- [ ] データベース設計変更の有無
- [ ] テストの複雑さ（ユニットテスト、統合テスト、E2Eテスト）
- [ ] ドキュメント整備の工数

---

### STEP 2: RICEスコアリング

ICEに加えて、より詳細な評価として RICEスコアも計算します。

| 軸 | 意味 | 評価値 | 単位 |
|----|------|--------|------|
| **Reach** | 月次到達ユーザー数 | 数値 | 人/月 |
| **Impact** | 各ユーザーへのインパクト | 0.25～3.0 | ポイント |
| **Confidence** | 実現確信度 | 10～100% | パーセント |
| **Effort** | 実装に必要な工数 | 数値 | 人月 |

#### Reach（到達範囲）の定義

実装した場合、月次で何人のユーザーに影響するか。

**計算方法**:
```
Reach = 月間アクティブユーザー数 × 機能利用率想定

例：MAU 1,000人 × 80%利用 = Reach 800人
```

#### Impact（インパクト）のスケール

各ユーザーへの改善度合いを定量化します。

| Impact | 基準 | 例 |
|--------|------|-----|
| **3.0** | Massive（劇的） | LTV 2倍向上、チャーン 50%削減 |
| **2.0** | High（大きい） | LTV 50%向上、チャーン 20%削減 |
| **1.0** | Medium（中程度） | LTV 20%向上、チャーン 10%削減 |
| **0.5** | Low（小さい） | LTV 5%向上、チャーン 5%削減 |
| **0.25** | Minimal（微小） | UI改善、使いやすさ向上のみ |

#### Confidence（確信度）

RICEスコアの確信度はパーセンテージで表現します。

| Confidence | 意味 | 根拠 |
|------------|------|------|
| **100%** | 完全確実 | A/Bテスト成功、複数成功事例 |
| **80%** | 高い確信 | インタビュー支持率高い、競合成功 |
| **50%** | 中程度 | 仮説段階だが根拠あり |
| **20%** | 低い確信 | 推測レベル |

#### Effort（実装工数）

実装に必要な人月（Person-Months）を見積もります。

**計算例**:
```
チーム構成: エンジニア1人
実装期間: 2週間
1ヶ月 = 4.3週間 → Effort = 2週間 / 4.3週間 ≈ 0.5人月

チーム構成: エンジニア2人
実装期間: 4週間
Effort = (2人 × 4週間) / 4.3週間 ≈ 1.9人月 → 2人月と丸め
```

---

## スコアリング テンプレート

### STEP A: ICEスコアリング（全機能）

| 機能ID | 機能名 | Impact | Confidence | Ease | ICEスコア | 優先度 |
|--------|--------|--------|----------|------|-----------|--------|
| F001 | ユーザー認証 | 10 | 10 | 9 | 9.00 | ★★★★★ |
| F002 | ソーシャルログイン | 8 | 8 | 7 | 4.48 | ★★★★ |
| F003 | リアルタイム通知 | 9 | 8 | 6 | 4.32 | ★★★★ |
| F004 | AIレコメンデーション | 8 | 6 | 3 | 1.44 | ★★ |
| F005 | ワンクリック共有 | 8 | 7 | 9 | 5.04 | ★★★★ |
| F006 | CSVエクスポート | 7 | 6 | 10 | 4.20 | ★★★ |
| F007 | チームコラボ | 8 | 5 | 4 | 1.60 | ★★ |
| F008 | ダークモード | 7 | 6 | 8 | 3.36 | ★★★ |
| F009 | 多言語対応 | 6 | 4 | 2 | 0.48 | ★ |
| F010 | 無料トライアル | 7 | 8 | 8 | 4.48 | ★★★★ |

**計算式の確認**:
```
ICEスコア = (Impact × Confidence × Ease) / 100

F001の場合: (10 × 10 × 9) / 100 = 900 / 100 = 9.00
F005の場合: (8 × 7 × 9) / 100 = 504 / 100 = 5.04
```

### STEP B: RICEスコアリング（主要機能）

| 機能ID | 機能名 | Reach | Impact | Confidence | Effort | RICEスコア |
|--------|--------|-------|--------|-----------|--------|-----------|
| F001 | ユーザー認証 | 1,000 | 3.0 | 100% | 2 | 1,500 |
| F003 | リアルタイム通知 | 1,000 | 2.0 | 80% | 2 | 800 |
| F005 | ワンクリック共有 | 800 | 2.0 | 80% | 1 | 1,280 |
| F006 | CSVエクスポート | 500 | 1.0 | 80% | 1 | 400 |
| F010 | 無料トライアル | 200 | 2.0 | 80% | 0.5 | 640 |

**計算式の確認**:
```
RICEスコア = (Reach × Impact × Confidence%) / Effort

F001の場合: (1,000 × 3.0 × 100%) / 2 = 3,000 / 2 = 1,500
F005の場合: (800 × 2.0 × 80%) / 1 = 1,280 / 1 = 1,280
```

---

## Quick Wins分析

Impact ≥ 7 かつ Ease ≥ 7 の機能を自動抽出します。

| 機能ID | 機能名 | Impact | Ease | ICEスコア | 実装期間目安 | 推奨スプリント |
|--------|--------|--------|------|-----------|-------------|--------------|
| F001 | ユーザー認証 | 10 | 9 | 9.00 | 3-5日 | Sprint 1 |
| F005 | ワンクリック共有 | 8 | 9 | 5.04 | 3-5日 | Sprint 1 |
| F006 | CSVエクスポート | 7 | 10 | 4.20 | 1-2日 | Sprint 1 |
| F010 | 無料トライアル | 7 | 8 | 4.48 | 2-3日 | Sprint 1 |

**判定**: Quick Wins **4機能** を特定 → 2-3週間で実装可能

---

## スコアリング実行の進め方

### Day 1: 準備（30分）

1. [ ] 評価者を決定（PM、エンジニアLead、デザイナー推奨）
2. [ ] 機能候補リスト（feature_list_input.md）を準備
3. [ ] 判定基準を全員で共有
4. [ ] 質問・疑問点を事前に解決

### Day 2-3: グループ評価（3-4時間）

1. [ ] 機能ごとにディスカッション（3-5分/機能）
2. [ ] Impact軸の評価
3. [ ] Confidence軸の評価（根拠データの確認）
4. [ ] Ease軸の評価（技術チームの見積確認）
5. [ ] スコアを記入

### Day 4: 計算・ランキング（1時間）

1. [ ] ICEスコア自動計算
2. [ ] RICEスコア自動計算
3. [ ] ランキング生成
4. [ ] Quick Wins抽出

### Day 5: 確認・承認（30分）

1. [ ] トップ10機能の確認（想定通りか）
2. [ ] Quick Wins数の確認（0件の場合は再評価）
3. [ ] 評価の根拠を文書化

---

## よくある評価ミス と 修正例

### ミス1: Impactが高すぎる評価

**症状**: すべての機能が Impact 8以上 → スコアリングの意味がない

**修正**:
```
誤り: ダークモード Impact = 8
→ 理由: Retention/LTVへの直接的インパクトが不明確

正解: ダークモード Impact = 6-7
→ 理由: UX改善だが、コア価値への直接影響は限定的
```

### ミス2: Confidenceが恣意的

**症状**: 「なんとなくいい機能だから」という定性判断のみ

**修正**:
```
評価前に確認すべきデータ:
1. ユーザーインタビュー記録 → 何人が言及したか
2. 競合分析 → 成功事例があるか
3. A/Bテスト結果 → 過去の同様機能の成功率
4. NPS / Sean Ellis結果 → ユーザー満足度
```

### ミス3: Easeが楽観的

**症状**: エンジニアの見積を無視した「1週間でできるだろう」

**修正**:
```
見積時のチェックリスト:
□ DB設計変更が必要か
□ 既存コードの修正箇所（影響範囲）
□ 外部API連携の必要性
□ テスト工数（ユニット、統合、E2E）
□ ドキュメント更新
□ リグレッション（バグ発生）の可能性

楽観値ではなく「最悪ケース + 20%」を見積
```

### ミス4: Quick Winsが多すぎる

**症状**: Impact ≥ 7 かつ Ease ≥ 7 が10個以上 → 重要ではない

**修正**:
```
再評価のポイント:
- Ease を厳しく再評価（本当に1週間でできるか）
- Impact の定義を確認（10点は「LTV 2倍」レベルか）
- Quick Wins数は通常 2-5個が目安
```

---

## 出力ファイル

このワークシートを完成させたら、以下を生成：

1. **ice_rice_scores.csv** - スコアリング結果（タビュレータ用）
2. **prioritization_ranking.md** - ランキング表（マークダウン）
3. **quick_wins_list.md** - Quick Wins機能一覧
4. **roadmap_draft.md** - ロードマップ初期版

---

**参考資料**: SKILL.md の「STEP 2-3: ICE/RICEスコアリング」セクションを参照してください。
