---
name: extract-content
description: |
  ãƒ„ã‚¤ãƒ¼ãƒˆè©³ç´°ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¨˜äº‹ãƒ»YouTubeãƒ»PDFãƒªãƒ³ã‚¯ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡ºã—ã€LLMåˆ¤å®šã§AIé–¢é€£åº¦ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã€‚
  ã‚¹ã‚³ã‚¢0ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å³åº§ã«é™¤å¤–ï¼ˆãƒ¯ãƒ³ãƒ‘ã‚¹åŒ–ï¼‰ã€‚ClaudeCode LLMãŒç›´æ¥WebFetch/Readãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã€‚

  ä½¿ç”¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼š
  - SNSæŠ•ç¨¿ä½œæˆã®äº‹å‰èª¿æŸ»æ™‚
  - å‚ç…§è¨˜äº‹ã®è¦ç´„ãŒå¿…è¦ãªæ™‚
  - ãƒªãƒ³ã‚¯å…ˆã®è©³ç´°æƒ…å ±ã‚’å–å¾—ã—ãŸã„æ™‚

  æ‰€è¦æ™‚é–“ï¼š7-14åˆ†ï¼ˆãƒªãƒ³ã‚¯æ•°ã«ä¾å­˜ã€ãƒ¯ãƒ³ãƒ‘ã‚¹åŒ–ã«ã‚ˆã‚Šå¾“æ¥æ¯”â–²3-6åˆ†çŸ­ç¸®ï¼‰
  å‡ºåŠ›1ï¼šextracted_contents_filtered_{YYYYMMDD}.jsonï¼ˆAIé–¢é€£ã®ã¿ï¼‰
  å‡ºåŠ›2ï¼šnon_ai_contents_{YYYYMMDD}.jsonï¼ˆé™¤å¤–ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼‰
trigger_keywords:
  - "ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º"
  - "è¨˜äº‹æŠ½å‡º"
  - "ãƒªãƒ³ã‚¯å…ˆæŠ½å‡º"
  - "extract content"
stage: Phase 2 - Content Extraction
dependencies: ["scrape-tweet-details"]
output_file: Stock/programs/å‰¯æ¥­/projects/SNS/data/extracted_contents_filtered_{YYYYMMDD}.json
execution_time: 7-14åˆ†
framework_reference: Stock/programs/å‰¯æ¥­/projects/SNS/
priority: P1
model: claude-haiku-4-5-20251001  # Haiku 4.5 (2026å¹´1æœˆæ™‚ç‚¹ã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«)
---

# Extract Content Skill

ãƒ„ã‚¤ãƒ¼ãƒˆè©³ç´°ã‹ã‚‰è¨˜äº‹ãƒ»YouTubeãƒ»PDFã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡ºã™ã‚‹ã‚¹ã‚­ãƒ«ã€‚

---

## ã“ã®Skillã§ã§ãã‚‹ã“ã¨

1. **è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º**: WebFetchãƒ„ãƒ¼ãƒ«ã§HTMLè§£æã€ã‚¿ã‚¤ãƒˆãƒ«ãƒ»æœ¬æ–‡ãƒ»ãƒ¡ã‚¿æƒ…å ±ã‚’å–å¾—
2. **YouTubeå‹•ç”»æƒ…å ±å–å¾—**: ã‚¿ã‚¤ãƒˆãƒ«ãƒ»èª¬æ˜æ–‡ã‚’å–å¾—ï¼ˆå­—å¹•æŠ½å‡ºã¯ä»Šå¾Œå®Ÿè£…ï¼‰
3. **PDFæƒ…å ±å–å¾—**: ãƒ¡ã‚¿æƒ…å ±ã‚’å–å¾—ï¼ˆå…¨æ–‡æŠ½å‡ºã¯ä»Šå¾Œå®Ÿè£…ï¼‰
4. **è¤‡æ•°ãƒªãƒ³ã‚¯ä¸€æ‹¬å‡¦ç†**: ãƒ„ã‚¤ãƒ¼ãƒˆè©³ç´°å†…ã®å…¨ãƒªãƒ³ã‚¯ã‚’è‡ªå‹•å‡¦ç†
5. **AIé–¢é€£åº¦ã‚¹ã‚³ã‚¢ä»˜ä¸**: æŠ½å‡ºã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«AIé–¢é€£åº¦ï¼ˆ0-3ç‚¹ï¼‰ã‚’è‡ªå‹•åˆ¤å®šãƒ»ä»˜ä¸
6. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒ»403ã‚¨ãƒ©ãƒ¼ç­‰ã‚’é©åˆ‡ã«è¨˜éŒ²

---

## å…¥åŠ›ãƒ»å‡ºåŠ›

| é …ç›® | å†…å®¹ |
|------|------|
| **å…¥åŠ›** | tweet_details_ai_{YYYYMMDD}.jsonï¼ˆãƒ„ã‚¤ãƒ¼ãƒˆè©³ç´°+ãƒªãƒ³ã‚¯æƒ…å ±ï¼‰ |
| **å‡ºåŠ›1** | extracted_contents_filtered_{YYYYMMDD}.jsonï¼ˆAIé–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ã¿ï¼‰ |
| **å‡ºåŠ›2** | non_ai_contents_{YYYYMMDD}.jsonï¼ˆé™¤å¤–ã•ã‚ŒãŸéAIé–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼‰ |
| **æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³** | analyze-repliesï¼ˆãƒªãƒ—ãƒ©ã‚¤åˆ†æï¼‰ã€research-topicï¼ˆWebèª¿æŸ»ï¼‰â€»filter-extracted-contentã¯å»ƒæ­¢ |

---

## Instructions

**å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰**: ClaudeCode LLMè‡ªå¾‹å®Ÿè¡Œ
**æ¨å®šæ‰€è¦æ™‚é–“**: 7-14åˆ†ï¼ˆLLMåˆ¤å®šãƒ¯ãƒ³ãƒ‘ã‚¹åŒ–ã€å¾“æ¥æ¯”â–²3-6åˆ†çŸ­ç¸®ï¼‰

### STEP 1: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆ30ç§’ï¼‰

**Readãƒ„ãƒ¼ãƒ«ä½¿ç”¨**:
```
/Users/yuichi/AIPM/aipm_v0/Stock/programs/å‰¯æ¥­/projects/SNS/data/tweet_details_ai_{æœ€æ–°æ—¥ä»˜}.json
```

**ç¢ºèªé …ç›®**:
- ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
- `tweet_details` é…åˆ—ã®èª­ã¿è¾¼ã¿
- å„ãƒ„ã‚¤ãƒ¼ãƒˆã® `links` é…åˆ—ã‚’æŠ½å‡º

**ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯**:
- æœ€æ–°æ—¥ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€`tweet_details_*.json` ã®æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢

---

### STEP 2: ãƒªãƒ³ã‚¯åˆ†é¡ï¼ˆ1åˆ†ï¼‰

**å…¨ãƒ„ã‚¤ãƒ¼ãƒˆã‹ã‚‰ãƒªãƒ³ã‚¯ã‚’åé›†**:
```python
# ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰ï¼ˆLLMå†…ã§å®Ÿè¡Œï¼‰
all_links = []
for tweet in tweet_details:
    for link in tweet['links']:
        all_links.append({
            'tweet_id': tweet['tweet_id'],
            'username': tweet['username'],
            'url': link['url'],
            'type': link['type'],  # article, youtube, pdf, other
            'domain': link['domain']
        })

# ã‚¿ã‚¤ãƒ—åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
link_types = {
    'article': [link for link in all_links if link['type'] == 'article'],
    'youtube': [link for link in all_links if link['type'] == 'youtube'],
    'pdf': [link for link in all_links if link['type'] == 'pdf'],
    'other': [link for link in all_links if link['type'] == 'other']
}
```

**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å ±å‘Š**:
```
ğŸ“Š ãƒªãƒ³ã‚¯åˆ†é¡çµæœ
- è¨˜äº‹: Xä»¶
- YouTube: Yä»¶
- PDF: Zä»¶
- ãã®ä»–: Wä»¶

åˆè¨ˆ: Nä»¶ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
```

---

### STEP 3: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºï¼ˆ3-8åˆ†ï¼‰

#### 3A. è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºï¼ˆWebFetchãƒ„ãƒ¼ãƒ«ä½¿ç”¨ï¼‰

**å„è¨˜äº‹URLã«å¯¾ã—ã¦**:
```
WebFetch(
  url=link['url'],
  prompt="ã“ã®è¨˜äº‹ã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã€æœ¬æ–‡ï¼ˆæœ€åˆã®500ãƒ¯ãƒ¼ãƒ‰ï¼‰ã€ãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è¿”ã—ã¦ãã ã•ã„: {title: string, content: string, meta_description: string}"
)
```

**æŠ½å‡ºçµæœã®æ§‹é€ åŒ–**:
```json
{
  "url": "https://example.com/article",
  "type": "article",
  "title": "è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«",
  "content": "æœ¬æ–‡ã®æœ€åˆã®500ãƒ¯ãƒ¼ãƒ‰...",
  "meta_description": "è¨˜äº‹ã®èª¬æ˜",
  "word_count": 450,
  "extracted_at": "2026-01-02T12:00:00",
  "status": "success",
  "tweet_id": "2006...",
  "username": "cb_doge",
  "domain": "example.com"
}
```

**ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**:
- **Timeout**: `status: "timeout"`, `error: "Request timeout"`
- **403 Forbidden**: `status: "forbidden"`, `error: "Access denied"`
- **404 Not Found**: `status: "not_found"`, `error: "Page not found"`
- **ãã®ä»–**: `status: "error"`, `error: error_message`

#### 3B. YouTubeå‹•ç”»æƒ…å ±å–å¾—

**ç¾åœ¨ã®å®Ÿè£…**: åŸºæœ¬æƒ…å ±ã®ã¿
```json
{
  "url": "https://youtube.com/watch?v=xxx",
  "type": "youtube",
  "status": "partial",
  "title": "å‹•ç”»ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆURLã‹ã‚‰æ¨æ¸¬ï¼‰",
  "note": "å­—å¹•æŠ½å‡ºã¯ä»Šå¾Œå®Ÿè£…äºˆå®š",
  "tweet_id": "2006...",
  "username": "hasan28d"
}
```

**ä»Šå¾Œã®å®Ÿè£…**: youtube-transcript-api ä½¿ç”¨

#### 3C. PDFæƒ…å ±å–å¾—

**ç¾åœ¨ã®å®Ÿè£…**: ãƒ¡ã‚¿æƒ…å ±ã®ã¿
```json
{
  "url": "https://example.com/paper.pdf",
  "type": "pdf",
  "status": "partial",
  "note": "PDFå…¨æ–‡æŠ½å‡ºã¯ä»Šå¾Œå®Ÿè£…äºˆå®š",
  "tweet_id": "2006...",
  "username": "researcher"
}
```

**ä»Šå¾Œã®å®Ÿè£…**: pdfplumber + pytesseract ä½¿ç”¨

---

### STEP 3.5: AIé–¢é€£åº¦LLMåˆ¤å®š + ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆãƒ¯ãƒ³ãƒ‘ã‚¹åŒ–ã€2-4åˆ†ï¼‰

**åˆ¤å®šåŸºæº–ã®å‚ç…§**: `@.claude/skills/_shared/ai_relevance_criteria.md`

**âš¡ ãƒ¯ãƒ³ãƒ‘ã‚¹åŒ–**: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¯†åº¦åˆ¤å®šã‚’å»ƒæ­¢ã—ã€LLMï¼ˆClaude Sonnetï¼‰ã§ç›´æ¥AIé–¢é€£åº¦ã‚’åˆ¤å®šã€‚ã‚¹ã‚³ã‚¢0ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¯å³åº§ã«é™¤å¤–ã€‚

#### 3.5A. LLMã«ã‚ˆã‚‹AIé–¢é€£åº¦åˆ¤å®š

**å…¨æŠ½å‡ºã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«å¯¾ã—ã¦**:

```python
# ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰ï¼ˆLLMå†…ã§å®Ÿè¡Œï¼‰
ai_contents = []  # AIé–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆã‚¹ã‚³ã‚¢1-3ï¼‰
non_ai_contents = []  # éAIé–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆã‚¹ã‚³ã‚¢0ï¼‰

for content in extracted_contents:
    if content['status'] != 'success':
        # ã‚¨ãƒ©ãƒ¼ãƒ»ãƒ‘ãƒ¼ã‚·ãƒ£ãƒ«ã¯0ç‚¹
        content['ai_relevance_score'] = 0
        content['ai_relevance_reason'] = "æŠ½å‡ºå¤±æ•—"
        non_ai_contents.append(content)
        continue

    title = content.get('title', '')
    text = content.get('content', '')

    # LLMã§AIé–¢é€£åº¦ã‚’åˆ¤å®šï¼ˆClaude Sonnetæ¨å¥¨ï¼‰
    prompt = f"""
    ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒAIæŠ€è¡“ã«é–¢é€£ã™ã‚‹ã‹åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

    ã‚¿ã‚¤ãƒˆãƒ«: {title}
    æœ¬æ–‡: {text[:1000]}  # æœ€åˆã®1000æ–‡å­—

    åˆ¤å®šåŸºæº–ï¼ˆ@.claude/skills/_shared/ai_relevance_criteria.mdï¼‰:
    - 3ç‚¹: LLMã€ç”ŸæˆAIã€ChatGPTã€Claudeã€GPTã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ç­‰ã®æ˜ç¤ºçš„ãªAIæŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å«æœ‰
    - 2ç‚¹: OpenAIã€Anthropicã€DeepMindç­‰ã®AIä¼æ¥­åãŒæ˜è¨˜ã€ã¾ãŸã¯æŠ€è¡“çš„ãªè©³ç´°ã‚ã‚Š
    - 1ç‚¹: æ©Ÿæ¢°å­¦ç¿’ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã€äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ç­‰ãŒä¸»é¡Œ
    - 0ç‚¹: ä¸Šè¨˜ã„ãšã‚Œã«ã‚‚è©²å½“ã—ãªã„ï¼ˆä¸€èˆ¬ãƒ“ã‚¸ãƒã‚¹ã€è£½å“ç´¹ä»‹ã€ã‚¨ãƒ³ã‚¿ãƒ¡ç­‰ï¼‰

    JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§è¿”ç­”:
    {{
      "score": 0-3,
      "reason": "åˆ¤å®šç†ç”±ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰",
      "is_ai_related": true/false
    }}
    """

    # LLMåˆ¤å®šå®Ÿè¡Œ
    llm_result = claude_sonnet_judge(prompt)

    content['ai_relevance_score'] = llm_result['score']
    content['ai_relevance_reason'] = llm_result['reason']

    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°: ã‚¹ã‚³ã‚¢0ã¯å³åº§ã«é™¤å¤–
    if llm_result['score'] == 0:
        non_ai_contents.append(content)
    else:
        ai_contents.append(content)
```

#### 3.5B. LLMåˆ¤å®šã®åˆ©ç‚¹

**å¾“æ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¯†åº¦åˆ¤å®šã¨ã®æ¯”è¼ƒ**:

| é …ç›® | ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¯†åº¦åˆ¤å®š | LLMåˆ¤å®šï¼ˆãƒ¯ãƒ³ãƒ‘ã‚¹åŒ–ï¼‰ |
|------|------------------|---------------------|
| **ç²¾åº¦** | 90.9%ï¼ˆ2ç‚¹åˆ¤å®šãŒå¼±ã„ï¼‰ | **95%+**ï¼ˆæ–‡è„ˆç†è§£ï¼‰ |
| **å‡¦ç†æ™‚é–“** | 1-2åˆ† | 2-4åˆ†ï¼ˆ+1-2åˆ†ï¼‰ |
| **2ç‚¹å¢ƒç•Œã‚±ãƒ¼ã‚¹** | èª¤åˆ¤å®šãƒªã‚¹ã‚¯é«˜ | æ–‡è„ˆç†è§£ã§æ­£ç¢º |
| **ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°** | åˆ¥ã‚¹ã‚­ãƒ«å¿…è¦ | **çµ±åˆæ¸ˆã¿** |
| **ç·æ‰€è¦æ™‚é–“** | 5-10åˆ†ï¼ˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºï¼‰+ 5-10åˆ†ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰= **10-20åˆ†** | **7-14åˆ†**ï¼ˆãƒ¯ãƒ³ãƒ‘ã‚¹ï¼‰ |

**çŸ­ç¸®åŠ¹æœ**: â–²3-6åˆ†ï¼ˆ30%çŸ­ç¸®ï¼‰

#### 3.5B. ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒãƒ³ã‚°å®Ÿè£…

**ç°¡æ˜“ç‰ˆå®Ÿè£…**ï¼ˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å­˜åœ¨åˆ¤å®šï¼‰:

```python
# 3ç‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
keywords_3pt = [
    "LLM", "ChatGPT", "Claude", "GPT", "Gemini", "ç”ŸæˆAI",
    "generative AI", "transformer", "neural network",
    "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°", "RAG", "fine-tuning"
]

# 2ç‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
keywords_2pt = [
    "OpenAI", "Anthropic", "DeepMind", "Google AI",
    "Microsoft AI", "Meta AI", "æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«"
]

# 1ç‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
keywords_1pt = [
    "æ©Ÿæ¢°å­¦ç¿’", "machine learning", "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹",
    "data science", "äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«"
]

def check_title_keywords(title: str) -> int:
    """ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰AIé–¢é€£åº¦ã‚’åˆ¤å®š"""
    title_lower = title.lower()

    if any(kw.lower() in title_lower for kw in keywords_3pt):
        return 3
    if any(kw.lower() in title_lower for kw in keywords_2pt):
        return 2
    if any(kw.lower() in title_lower for kw in keywords_1pt):
        return 1

    return 0
```

**è©³ç´°ãªåˆ¤å®šåŸºæº–**: `@.claude/skills/_shared/ai_relevance_criteria.md` ã‚’å‚ç…§

---

### STEP 4: çµæœé›†è¨ˆï¼ˆ1åˆ†ï¼‰

**çµ±è¨ˆæƒ…å ±è¨ˆç®—**:
```python
# ç–‘ä¼¼ã‚³ãƒ¼ãƒ‰
all_extracted = ai_contents + non_ai_contents

success_count = len([c for c in all_extracted if c['status'] == 'success'])
partial_count = len([c for c in all_extracted if c['status'] == 'partial'])
error_count = len([c for c in all_extracted if c['status'] in ['timeout', 'forbidden', 'error']])

total_words = sum([c.get('word_count', 0) for c in all_extracted if c['status'] == 'success'])
avg_words = total_words / success_count if success_count > 0 else 0

success_rate = (success_count / len(all_links)) * 100

# AIé–¢é€£åº¦ã‚¹ã‚³ã‚¢é›†è¨ˆ
score_distribution = {
    '3ç‚¹': len([c for c in ai_contents if c.get('ai_relevance_score', 0) == 3]),
    '2ç‚¹': len([c for c in ai_contents if c.get('ai_relevance_score', 0) == 2]),
    '1ç‚¹': len([c for c in ai_contents if c.get('ai_relevance_score', 0) == 1]),
    '0ç‚¹': len(non_ai_contents)
}

# ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°çµ±è¨ˆ
filtered_count = len(ai_contents)
excluded_count = len(non_ai_contents)
retention_rate = (filtered_count / len(all_extracted)) * 100 if len(all_extracted) > 0 else 0
```

---

### STEP 5: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆ2ãƒ•ã‚¡ã‚¤ãƒ«ã€30ç§’ï¼‰

**âš¡ ãƒ¯ãƒ³ãƒ‘ã‚¹åŒ–å¯¾å¿œ**: AIé–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨éAIé–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›

#### 5A. AIé–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆextracted_contents_filtered_{date}.jsonï¼‰

**å‡ºåŠ›JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**:
```json
{
  "metadata": {
    "processed_at": "2026-01-12T12:38:00",
    "source_file": "tweet_details_ai_20260112.json",
    "filtered_at": "2026-01-12T12:40:00",
    "total_links": 12,
    "success_count": 11,
    "filtered_count": 9,
    "excluded_count": 3,
    "retention_rate": 75.0,
    "link_types": {
      "article": 11,
      "youtube": 0,
      "pdf": 1
    },
    "ai_relevance_distribution": {
      "3ç‚¹": 5,
      "2ç‚¹": 3,
      "1ç‚¹": 1
      "0ç‚¹": 3
    },
    "ai_relevant_rate": 75.0
  },
  "ai_contents": [
    {
      "url": "https://...",
      "type": "article",
      "title": "ChatGPT-4ã®RAGå®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³",
      "content": "...",
      "word_count": 530,
      "status": "success",
      "tweet_id": "...",
      "username": "...",
      "domain": "...",
      "ai_relevance_score": 3,
      "ai_relevance_reason": "LLMåˆ¤å®š: ç”ŸæˆAIæŠ€è¡“ã®è©³ç´°è§£èª¬"
    }
  ]
}
```

**ä¿å­˜å…ˆ**: `Stock/programs/å‰¯æ¥­/projects/SNS/data/extracted_contents_filtered_{YYYYMMDD}.json`

---

#### 5B. éAIé–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆnon_ai_contents_{date}.jsonï¼‰

**å‡ºåŠ›JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**:
```json
{
  "metadata": {
    "excluded_at": "2026-01-12T12:40:00",
    "excluded_count": 3,
    "reason": "AIé–¢é€£åº¦ã‚¹ã‚³ã‚¢0ç‚¹ï¼ˆAIæŠ€è¡“éé–¢é€£ï¼‰"
  },
  "non_ai_contents": [
    {
      "url": "https://rakuten.com/fashion/...",
      "type": "article",
      "title": "æ¥½å¤©ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³å…¨é¡ãƒã‚¤ãƒ³ãƒˆãƒãƒƒã‚¯",
      "content": "...",
      "word_count": 200,
      "status": "success",
      "ai_relevance_score": 0,
      "ai_relevance_reason": "LLMåˆ¤å®š: ä¸€èˆ¬è£½å“ç´¹ä»‹ï¼ˆAIéé–¢é€£ï¼‰"
    }
  ]
}
```

**ä¿å­˜å…ˆ**: `Stock/programs/å‰¯æ¥­/projects/SNS/data/non_ai_contents_{YYYYMMDD}.json`

---

### STEP 6: ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆ30ç§’ï¼‰

**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å ±å‘Š**:
```
âœ… ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºå®Œäº†

ğŸ“Š Summary:
  - Total links processed: 12
  - Success: 11 (91.7%)
  - Errors: 1 (8.3%)

ğŸ“ Content statistics:
  - Total words extracted: 1,322
  - Average words per article: 120

ğŸ¯ AIé–¢é€£åº¦åˆ†å¸ƒ:
  - 3ç‚¹ï¼ˆé«˜é–¢é€£åº¦ï¼‰: 5ä»¶ (41.7%)
  - 2ç‚¹ï¼ˆä¸­é–¢é€£åº¦ï¼‰: 3ä»¶ (25.0%)
  - 1ç‚¹ï¼ˆä½é–¢é€£åº¦ï¼‰: 1ä»¶ (8.3%)
  - 0ç‚¹ï¼ˆéAIé–¢é€£ï¼‰: 3ä»¶ (25.0%)
  - AIé–¢é€£ç‡: 75.0%

ğŸ† Top 3 AIé–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„:
  1. [3ç‚¹] ChatGPT-4ã®RAGå®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ (530 words)
  2. [3ç‚¹] Claude 3.5ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° (412 words)
  3. [2ç‚¹] OpenAIæ–°ãƒ¢ãƒ‡ãƒ«ç™ºè¡¨ (298 words)

ğŸ’¾ Output: extracted_contents_ai_20260102.json (35KB)

ğŸ“Œ Next: filter-extracted-contentï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰ã€analyze-repliesï¼ˆãƒªãƒ—ãƒ©ã‚¤åˆ†æï¼‰ã€research-topicï¼ˆWebèª¿æŸ»ï¼‰
```

---

## ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### WebFetchã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
- **åŸå› **: ã‚µãƒ¼ãƒãƒ¼å¿œç­”é…å»¶ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¸å®‰å®š
- **å¯¾å¿œ**: `status: "timeout"` ã§è¨˜éŒ²ã€æ¬¡ã®ãƒªãƒ³ã‚¯ã¸é€²ã‚€
- **ãƒªãƒˆãƒ©ã‚¤**: ãªã—ï¼ˆæ™‚é–“åŠ¹ç‡å„ªå…ˆï¼‰

### 403 Forbidden
- **åŸå› **: User-Agentåˆ¶é™ã€ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™
- **å¯¾å¿œ**: `status: "forbidden"` ã§è¨˜éŒ²ã€æ¬¡ã®ãƒªãƒ³ã‚¯ã¸é€²ã‚€
- **ä¾‹**: help.x.comï¼ˆXå…¬å¼ãƒ˜ãƒ«ãƒ—ã¯ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™ã‚ã‚Šï¼‰

### ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡ºå¤±æ•—
- **åŸå› **: HTMLæ§‹é€ ãŒäºˆæ¸¬å¤–
- **å¯¾å¿œ**: `content: ""`, `word_count: 0` ã§è¨˜éŒ²
- **ãƒ­ã‚°**: `status: "success"` ã ãŒ `word_count: 0` ã®å ´åˆã¯è­¦å‘Š

---

## ãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼

| å“è³ªæŒ‡æ¨™ | ç›®æ¨™ | å®Ÿç¸¾ï¼ˆ2026-01-02ï¼‰ |
|---------|------|------------------|
| **æˆåŠŸç‡** | â‰¥80% | 91.7% (11/12) |
| **ç·æŠ½å‡ºãƒ¯ãƒ¼ãƒ‰æ•°** | â‰¥500 | 1,322 |
| **å¹³å‡ãƒ¯ãƒ¼ãƒ‰æ•°/è¨˜äº‹** | â‰¥50 | 120 |
| **AIé–¢é€£ç‡** | â‰¥60% | 75.0% (9/12) |
| **é«˜é–¢é€£åº¦ï¼ˆ3ç‚¹ï¼‰æ¯”ç‡** | â‰¥30% | 41.7% (5/12) |

---

## ä½¿ç”¨ä¾‹

### åŸºæœ¬çš„ãªä½¿ç”¨

```
User: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æŠ½å‡º
```

ã‚·ã‚¹ãƒ†ãƒ ãŒè‡ªå‹•çš„ã«ï¼š
1. æœ€æ–°ã® `tweet_details_ai_*.json` ã‚’èª­ã¿è¾¼ã¿
2. å…¨ãƒªãƒ³ã‚¯ã‚’åˆ†é¡
3. WebFetchãƒ„ãƒ¼ãƒ«ã§å„ãƒªãƒ³ã‚¯ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡º
4. AIé–¢é€£åº¦ã‚¹ã‚³ã‚¢ã‚’ä»˜ä¸ï¼ˆ0-3ç‚¹ï¼‰
5. çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—ï¼ˆAIé–¢é€£åº¦åˆ†å¸ƒå«ã‚€ï¼‰
6. JSONå‡ºåŠ›ç”Ÿæˆ
7. ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º

---

## ä¾å­˜ãƒ„ãƒ¼ãƒ«

**å¿…é ˆ**:
- `Read`: å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
- `WebFetch`: è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å–å¾—
- `Write`: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜

**å‚ç…§**:
- `@.claude/skills/_shared/ai_relevance_criteria.md`: AIé–¢é€£åº¦åˆ¤å®šåŸºæº–

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆä»Šå¾Œå®Ÿè£…ï¼‰**:
- `Bash`: youtube-transcript-apiã€pdfplumberå®Ÿè¡Œ

---

## æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ææ¡ˆ

æŠ½å‡ºå®Œäº†å¾Œã€ä»¥ä¸‹ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ææ¡ˆã—ã¾ã™ï¼š

1. **filter-extracted-content**: AIé–¢é€£åº¦ã§ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆæ¨å¥¨ï¼‰
2. **analyze-replies**: ãƒªãƒ—ãƒ©ã‚¤ã‹ã‚‰åéŸ¿ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡º
3. **research-topic**: WebSearchã§æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯
4. **generate-sns-posts**: AIé–¢é€£ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å…ƒã«æŠ•ç¨¿æ–‡ç”Ÿæˆ

---

## æ›´æ–°å±¥æ­´

- 2026-01-02: åˆç‰ˆä½œæˆï¼ˆClaudeCode LLMç›´æ¥å®Ÿè¡Œå‹ï¼‰
  - å®Ÿç¸¾: 11/12ãƒªãƒ³ã‚¯æˆåŠŸï¼ˆ91.7%ï¼‰ã€1,322ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
- 2026-01-12: AIé–¢é€£åº¦ã‚¹ã‚³ã‚¢ä»˜ä¸æ©Ÿèƒ½ã‚’è¿½åŠ ï¼ˆSTEP 3.5ï¼‰
  - AIé–¢é€£åº¦åˆ¤å®šåŸºæº–: `ai_relevance_criteria.md` v1.0æº–æ‹ 
  - å‡ºåŠ›ã«ai_relevance_score, ai_relevance_reasonã‚’è¿½åŠ 
  - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ai_relevance_distribution, ai_relevant_rateã‚’è¿½åŠ 
