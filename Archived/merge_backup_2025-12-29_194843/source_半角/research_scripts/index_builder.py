#!/usr/bin/env python3
"""
Index Builder for Founder Research Case Studies

ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚
6ç¨®é¡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆ:
- by_industry.md (æ¥­ç•Œåˆ¥)
- by_stage.md (ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥)
- by_pivot_type.md (Pivoté¡å‹åˆ¥)
- by_failure_pattern.md (å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥)
- by_10x_axis.md (10å€å„ªä½æ€§è»¸åˆ¥)
- by_cpf_score.md (CPFã‚¹ã‚³ã‚¢åˆ¥)
"""

import os
import re
import yaml
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Any

class IndexBuilder:
    """ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è‡ªå‹•ç”Ÿæˆ"""

    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.documents_path = self.base_path / "documents"
        self.index_path = self.base_path / "_index"
        self.case_studies = []

    def load_all_case_studies(self):
        """å…¨ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã®YAML Front Matterã‚’èª­ã¿è¾¼ã¿"""
        print("ğŸ“š ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚’èª­ã¿è¾¼ã¿ä¸­...")

        for category_dir in self.documents_path.iterdir():
            if not category_dir.is_dir():
                continue

            for md_file in category_dir.glob("FOUNDER_*.md"):
                try:
                    with open(md_file, 'r', encoding='utf-8') as f:
                        content = f.read()

                    # YAML Front MatteræŠ½å‡º
                    match = re.match(r'^---\n(.*?)\n---', content, re.DOTALL)
                    if match:
                        yaml_content = match.group(1)
                        metadata = yaml.safe_load(yaml_content)

                        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¿½åŠ 
                        metadata['_file_path'] = str(md_file.relative_to(self.base_path))
                        metadata['_file_name'] = md_file.name

                        self.case_studies.append(metadata)

                except Exception as e:
                    print(f"âš ï¸  {md_file.name}: {e}")

        print(f"âœ… {len(self.case_studies)}ä»¶ã®ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

    def build_industry_index(self):
        """æ¥­ç•Œåˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        print("\nğŸ­ æ¥­ç•Œåˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆä¸­...")

        industry_map = defaultdict(list)

        for cs in self.case_studies:
            # ã‚¿ã‚°ã‹ã‚‰æ¥­ç•Œã‚’æŠ½å‡º
            tags = cs.get('tags', [])
            industry = cs.get('company', {}).get('industry', 'ä¸æ˜')

            # æ¥­ç•Œåˆ†é¡
            if any(tag in ['saas', 'enterprise', 'b2b'] for tag in tags):
                category = 'SaaS'
            elif any(tag in ['marketplace', 'ecommerce', 'e-commerce'] for tag in tags):
                category = 'Marketplace / E-commerce'
            elif any(tag in ['fintech', 'finance', 'payment'] for tag in tags):
                category = 'Fintech'
            elif any(tag in ['healthtech', 'medtech', 'health'] for tag in tags):
                category = 'Healthtech'
            elif any(tag in ['ai', 'ml', 'machine_learning'] for tag in tags):
                category = 'AI / ML'
            else:
                category = industry

            industry_map[category].append(cs)

        # Markdownç”Ÿæˆ
        md_content = "# ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£æ¥­ç•Œåˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n\n"
        md_content += f"**ç·ä»¶æ•°**: {len(self.case_studies)}ä»¶\n"
        md_content += f"**æœ€çµ‚æ›´æ–°**: {self._get_today()}\n\n"

        for industry, cases in sorted(industry_map.items(), key=lambda x: len(x[1]), reverse=True):
            md_content += f"## {industry}ï¼ˆ{len(cases)}ä»¶ï¼‰\n\n"

            for cs in sorted(cases, key=lambda x: x.get('id', '')):
                title = cs.get('title', 'ä¸æ˜')
                file_path = cs.get('_file_path', '')
                cpf_score = cs.get('validation_data', {}).get('cpf', {}).get('problem_commonality', 'N/A')
                ten_x_count = len(cs.get('validation_data', {}).get('psf', {}).get('ten_x_axes', []))

                md_content += f"- [{title}]({file_path})\n"
                md_content += f"  - CPF: {cpf_score}%, PSF: {ten_x_count}è»¸\n"

            md_content += "\n"

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        self.index_path.mkdir(exist_ok=True)
        with open(self.index_path / "by_industry.md", 'w', encoding='utf-8') as f:
            f.write(md_content)

        print(f"âœ… by_industry.md ä½œæˆå®Œäº†ï¼ˆ{len(industry_map)}æ¥­ç•Œï¼‰")

    def build_stage_index(self):
        """ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        print("\nğŸ“Š ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆä¸­...")

        stage_map = defaultdict(list)

        for cs in self.case_studies:
            tier = cs.get('tier', 'unknown')

            # ã‚¹ãƒ†ãƒ¼ã‚¸åˆ†é¡
            if tier in ['legendary', 'ipo_japan', 'ipo_global']:
                stage = 'IPO / Legendary'
            elif tier == 'unicorn':
                stage = 'Unicorn ($1B+)'
            elif tier == 'vc_backed':
                # è³‡é‡‘èª¿é”ãƒ©ã‚¦ãƒ³ãƒ‰ã§ç´°åˆ†åŒ–
                rounds = cs.get('funding', {}).get('funding_rounds', [])
                if any(r.get('round', '') in ['series_d', 'series_e'] for r in rounds):
                    stage = 'Series D+'
                elif any(r.get('round', '') == 'series_c' for r in rounds):
                    stage = 'Series C'
                elif any(r.get('round', '') == 'series_b' for r in rounds):
                    stage = 'Series B'
                elif any(r.get('round', '') == 'series_a' for r in rounds):
                    stage = 'Series A'
                else:
                    stage = 'Seed / Early'
            elif tier == 'emerging':
                stage = 'Emerging (2020-)'
            else:
                stage = 'ãã®ä»–'

            stage_map[stage].append(cs)

        # Markdownç”Ÿæˆ
        md_content = "# ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚¹ãƒ†ãƒ¼ã‚¸åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n\n"
        md_content += f"**ç·ä»¶æ•°**: {len(self.case_studies)}ä»¶\n"
        md_content += f"**æœ€çµ‚æ›´æ–°**: {self._get_today()}\n\n"

        # ã‚¹ãƒ†ãƒ¼ã‚¸é †åºå®šç¾©
        stage_order = ['IPO / Legendary', 'Unicorn ($1B+)', 'Series D+', 'Series C',
                       'Series B', 'Series A', 'Seed / Early', 'Emerging (2020-)', 'ãã®ä»–']

        for stage in stage_order:
            if stage not in stage_map:
                continue

            cases = stage_map[stage]
            md_content += f"## {stage}ï¼ˆ{len(cases)}ä»¶ï¼‰\n\n"

            for cs in sorted(cases, key=lambda x: x.get('id', '')):
                title = cs.get('title', 'ä¸æ˜')
                file_path = cs.get('_file_path', '')
                valuation = cs.get('company', {}).get('valuation', 'N/A')

                md_content += f"- [{title}]({file_path})\n"
                md_content += f"  - è©•ä¾¡é¡: {valuation}\n"

            md_content += "\n"

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(self.index_path / "by_stage.md", 'w', encoding='utf-8') as f:
            f.write(md_content)

        print(f"âœ… by_stage.md ä½œæˆå®Œäº†ï¼ˆ{len(stage_map)}ã‚¹ãƒ†ãƒ¼ã‚¸ï¼‰")

    def build_10x_axis_index(self):
        """10å€å„ªä½æ€§è»¸åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        print("\nğŸš€ 10å€å„ªä½æ€§è»¸åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆä¸­...")

        axis_map = defaultdict(list)

        for cs in self.case_studies:
            ten_x_axes = cs.get('validation_data', {}).get('psf', {}).get('ten_x_axes', [])

            for axis_data in ten_x_axes:
                axis = axis_data.get('axis', 'ä¸æ˜')
                multiplier = axis_data.get('multiplier', 0)

                # Convert to float for comparison (handle string values)
                try:
                    multiplier_num = float(multiplier) if multiplier else 0
                except (ValueError, TypeError):
                    multiplier_num = 0

                if multiplier_num >= 3:  # 3å€ä»¥ä¸Šã®ã¿
                    axis_map[axis].append({
                        'case_study': cs,
                        'multiplier': multiplier
                    })

        # Markdownç”Ÿæˆ
        md_content = "# ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£10å€å„ªä½æ€§è»¸åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n\n"
        md_content += f"**ç·ä»¶æ•°**: {len(self.case_studies)}ä»¶\n"
        md_content += f"**æœ€çµ‚æ›´æ–°**: {self._get_today()}\n\n"

        for axis, items in sorted(axis_map.items(), key=lambda x: len(x[1]), reverse=True):
            md_content += f"## {axis}ï¼ˆ{len(items)}ä»¶ï¼‰\n\n"

            # å€ç‡é™é †ã§ã‚½ãƒ¼ãƒˆ
            for item in sorted(items, key=lambda x: x['multiplier'], reverse=True):
                cs = item['case_study']
                multiplier = item['multiplier']
                title = cs.get('title', 'ä¸æ˜')
                file_path = cs.get('_file_path', '')

                md_content += f"- [{title}]({file_path}) - **{multiplier}å€**\n"

            md_content += "\n"

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(self.index_path / "by_10x_axis.md", 'w', encoding='utf-8') as f:
            f.write(md_content)

        print(f"âœ… by_10x_axis.md ä½œæˆå®Œäº†ï¼ˆ{len(axis_map)}è»¸ï¼‰")

    def build_cpf_score_index(self):
        """CPFã‚¹ã‚³ã‚¢åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        print("\nğŸ“ˆ CPFã‚¹ã‚³ã‚¢åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆä¸­...")

        score_ranges = {
            '90-100%ï¼ˆå„ªç§€ï¼‰': [],
            '80-89%ï¼ˆè‰¯å¥½ï¼‰': [],
            '70-79%ï¼ˆåˆæ ¼ï¼‰': [],
            '60-69%ï¼ˆåŸºæº–å€¤ï¼‰': [],
            '60%æœªæº€ï¼ˆè¦æ”¹å–„ï¼‰': [],
            'ãƒ‡ãƒ¼ã‚¿ãªã—': []
        }

        for cs in self.case_studies:
            cpf_score = cs.get('validation_data', {}).get('cpf', {}).get('problem_commonality')

            if cpf_score is None:
                score_ranges['ãƒ‡ãƒ¼ã‚¿ãªã—'].append(cs)
            elif cpf_score >= 90:
                score_ranges['90-100%ï¼ˆå„ªç§€ï¼‰'].append(cs)
            elif cpf_score >= 80:
                score_ranges['80-89%ï¼ˆè‰¯å¥½ï¼‰'].append(cs)
            elif cpf_score >= 70:
                score_ranges['70-79%ï¼ˆåˆæ ¼ï¼‰'].append(cs)
            elif cpf_score >= 60:
                score_ranges['60-69%ï¼ˆåŸºæº–å€¤ï¼‰'].append(cs)
            else:
                score_ranges['60%æœªæº€ï¼ˆè¦æ”¹å–„ï¼‰'].append(cs)

        # Markdownç”Ÿæˆ
        md_content = "# ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£CPFã‚¹ã‚³ã‚¢åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n\n"
        md_content += f"**ç·ä»¶æ•°**: {len(self.case_studies)}ä»¶\n"
        md_content += f"**æœ€çµ‚æ›´æ–°**: {self._get_today()}\n\n"
        md_content += "**CPFåŸºæº–å€¤**: 60%ä»¥ä¸Š\n\n"

        for range_name, cases in score_ranges.items():
            if not cases:
                continue

            md_content += f"## {range_name}ï¼ˆ{len(cases)}ä»¶ï¼‰\n\n"

            # Sort with safe numeric conversion
            def get_cpf_score(cs):
                val = cs.get('validation_data', {}).get('cpf', {}).get('problem_commonality', 0)
                try:
                    return float(val) if val is not None else 0
                except (ValueError, TypeError):
                    return 0

            for cs in sorted(cases, key=get_cpf_score, reverse=True):
                title = cs.get('title', 'ä¸æ˜')
                file_path = cs.get('_file_path', '')
                cpf_score = cs.get('validation_data', {}).get('cpf', {}).get('problem_commonality', 'N/A')
                interview_count = cs.get('validation_data', {}).get('cpf', {}).get('interview_count', 'N/A')

                md_content += f"- [{title}]({file_path})\n"
                md_content += f"  - CPF: {cpf_score}%, ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼æ•°: {interview_count}\n"

            md_content += "\n"

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(self.index_path / "by_cpf_score.md", 'w', encoding='utf-8') as f:
            f.write(md_content)

        print(f"âœ… by_cpf_score.md ä½œæˆå®Œäº†")

    def build_pivot_index(self):
        """Pivoté¡å‹åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ"""
        print("\nğŸ”„ Pivoté¡å‹åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆä¸­...")

        pivot_map = defaultdict(list)

        for cs in self.case_studies:
            pivot_occurred = cs.get('validation_data', {}).get('pivot', {}).get('occurred', False)

            if pivot_occurred:
                pivot_trigger = cs.get('validation_data', {}).get('pivot', {}).get('pivot_trigger', 'ä¸æ˜')
                pivot_map[pivot_trigger].append(cs)

        # Markdownç”Ÿæˆ
        md_content = "# ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£Pivoté¡å‹åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n\n"
        md_content += f"**ç·ä»¶æ•°**: {len(self.case_studies)}ä»¶\n"
        md_content += f"**Pivotå®Ÿæ–½**: {sum(len(cases) for cases in pivot_map.values())}ä»¶\n"
        md_content += f"**æœ€çµ‚æ›´æ–°**: {self._get_today()}\n\n"

        for trigger, cases in sorted(pivot_map.items(), key=lambda x: len(x[1]), reverse=True):
            md_content += f"## {trigger}ï¼ˆ{len(cases)}ä»¶ï¼‰\n\n"

            for cs in sorted(cases, key=lambda x: x.get('id', '')):
                title = cs.get('title', 'ä¸æ˜')
                file_path = cs.get('_file_path', '')
                original_idea = cs.get('validation_data', {}).get('pivot', {}).get('original_idea', 'N/A')
                pivoted_to = cs.get('validation_data', {}).get('pivot', {}).get('pivoted_to', 'N/A')

                md_content += f"- [{title}]({file_path})\n"
                md_content += f"  - å…ƒ: {original_idea}\n"
                md_content += f"  - å¾Œ: {pivoted_to}\n"

            md_content += "\n"

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(self.index_path / "by_pivot_type.md", 'w', encoding='utf-8') as f:
            f.write(md_content)

        print(f"âœ… by_pivot_type.md ä½œæˆå®Œäº†ï¼ˆ{len(pivot_map)}é¡å‹ï¼‰")

    def build_failure_pattern_index(self):
        """å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆï¼ˆèµ·æ¥­ã®ç§‘å­¦P11-P30å¯¾å¿œï¼‰"""
        print("\nâŒ å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆä¸­...")

        failure_map = defaultdict(list)

        for cs in self.case_studies:
            failure_pattern = cs.get('outcome', {}).get('failure_pattern', '')

            if failure_pattern:
                failure_map[failure_pattern].append(cs)

        # Markdownç”Ÿæˆ
        md_content = "# ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n\n"
        md_content += "**èµ·æ¥­ã®ç§‘å­¦P11-P30å¤±æ•—ãƒ‘ã‚¿ãƒ¼ãƒ³å¯¾å¿œ**\n\n"
        md_content += f"**ç·ä»¶æ•°**: {len(self.case_studies)}ä»¶\n"
        md_content += f"**å¤±æ•—äº‹ä¾‹**: {sum(len(cases) for cases in failure_map.values())}ä»¶\n"
        md_content += f"**æœ€çµ‚æ›´æ–°**: {self._get_today()}\n\n"

        for pattern, cases in sorted(failure_map.items(), key=lambda x: len(x[1]), reverse=True):
            md_content += f"## {pattern}ï¼ˆ{len(cases)}ä»¶ï¼‰\n\n"

            for cs in sorted(cases, key=lambda x: x.get('id', '')):
                title = cs.get('title', 'ä¸æ˜')
                file_path = cs.get('_file_path', '')

                md_content += f"- [{title}]({file_path})\n"

            md_content += "\n"

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(self.index_path / "by_failure_pattern.md", 'w', encoding='utf-8') as f:
            f.write(md_content)

        print(f"âœ… by_failure_pattern.md ä½œæˆå®Œäº†ï¼ˆ{len(failure_map)}ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰")

    def build_master_index(self):
        """ãƒã‚¹ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆï¼ˆå…¨ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã®ãƒªã‚¹ãƒˆï¼‰"""
        print("\nğŸ“‹ ãƒã‚¹ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆä¸­...")

        md_content = "# ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ãƒã‚¹ã‚¿ãƒ¼ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n\n"
        md_content += f"**ç·ä»¶æ•°**: {len(self.case_studies)}ä»¶\n"
        md_content += f"**æœ€çµ‚æ›´æ–°**: {self._get_today()}\n\n"

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥
        categories = defaultdict(list)
        for cs in self.case_studies:
            tier = cs.get('tier', 'unknown')
            categories[tier].append(cs)

        for tier, cases in sorted(categories.items()):
            tier_name = self._tier_name(tier)
            md_content += f"## {tier_name}ï¼ˆ{len(cases)}ä»¶ï¼‰\n\n"

            md_content += "| ID | ã‚¿ã‚¤ãƒˆãƒ« | æ¥­ç•Œ | CPF | PSFè»¸æ•° | ãƒ•ã‚¡ã‚¤ãƒ« |\n"
            md_content += "|:--:|---------|------|:---:|:------:|--------|\n"

            for cs in sorted(cases, key=lambda x: x.get('id', '')):
                cs_id = cs.get('id', 'N/A')
                title = cs.get('title', 'ä¸æ˜')
                industry = cs.get('company', {}).get('industry', 'N/A')
                cpf = cs.get('validation_data', {}).get('cpf', {}).get('problem_commonality', 'N/A')
                psf_axes = len(cs.get('validation_data', {}).get('psf', {}).get('ten_x_axes', []))
                file_path = cs.get('_file_path', '')

                md_content += f"| {cs_id} | {title} | {industry} | {cpf}% | {psf_axes} | [{cs.get('_file_name', '')}]({file_path}) |\n"

            md_content += "\n"

        # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        with open(self.index_path / "master_index.md", 'w', encoding='utf-8') as f:
            f.write(md_content)

        print(f"âœ… master_index.md ä½œæˆå®Œäº†")

    def build_all_indexes(self):
        """å…¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¸€æ‹¬ä½œæˆ"""
        print("\n" + "="*60)
        print("ğŸš€ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è‡ªå‹•ç”Ÿæˆé–‹å§‹")
        print("="*60)

        self.load_all_case_studies()

        if not self.case_studies:
            print("âš ï¸  ã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return

        self.build_industry_index()
        self.build_stage_index()
        self.build_10x_axis_index()
        self.build_cpf_score_index()
        self.build_pivot_index()
        self.build_failure_pattern_index()
        self.build_master_index()

        print("\n" + "="*60)
        print(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆå®Œäº†: {len(self.case_studies)}ä»¶")
        print("="*60)

    def _get_today(self):
        """ä»Šæ—¥ã®æ—¥ä»˜å–å¾—"""
        from datetime import datetime
        return datetime.now().strftime('%Y-%m-%d')

    def _tier_name(self, tier: str) -> str:
        """Tieråã‚’æ—¥æœ¬èªã«å¤‰æ›"""
        tier_map = {
            'legendary': '01_Legendaryï¼ˆãƒ¬ã‚¸ã‚§ãƒ³ãƒ‰ï¼‰',
            'unicorn': '02_Unicornï¼ˆãƒ¦ãƒ‹ã‚³ãƒ¼ãƒ³ï¼‰',
            'vc_backed': '03_VC_Backedï¼ˆVCèª¿é”æ¸ˆã¿ï¼‰',
            'ipo_japan': '04_IPO_Japanï¼ˆæ—¥æœ¬ä¸Šå ´ï¼‰',
            'ipo_global': '05_IPO_Globalï¼ˆæµ·å¤–ä¸Šå ´ï¼‰',
            'pivot': '06_Pivot_Successï¼ˆãƒ”ãƒœãƒƒãƒˆæˆåŠŸï¼‰',
            'failure': '07_Failure_Studyï¼ˆå¤±æ•—äº‹ä¾‹ï¼‰',
            'emerging': '08_Emergingï¼ˆæ–°èˆˆï¼‰'
        }
        return tier_map.get(tier, tier)


if __name__ == "__main__":
    # å®Ÿè¡Œ
    base_path = "/Users/yuichi/AIPM/aipm_v0/Stock/programs/å‰µæ¥­æ”¯æ´ãƒ»æ–°è¦äº‹æ¥­é–‹ç™ºï¼ˆAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰/projects/Founder_Research"

    builder = IndexBuilder(base_path)
    builder.build_all_indexes()
