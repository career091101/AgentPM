#!/usr/bin/env python3
"""
Auto Parallel Executor for Founder Research
This script prepares batch execution instructions for Claude Code's Task tool
"""

import json
from pathlib import Path
from datetime import datetime

class AutoParallelExecutor:
    def __init__(self, project_root):
        self.project_root = Path(project_root)
        self.scripts_dir = self.project_root / "scripts"
        self.wave_defs_file = self.scripts_dir / "wave_definitions.json"
        self.progress_file = self.scripts_dir / "progress.json"
        self.load_definitions()
        self.load_progress()

    def load_definitions(self):
        with open(self.wave_defs_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            self.waves = data['waves']
            self.strategy = data.get('execution_strategy', {})

    def load_progress(self):
        if self.progress_file.exists():
            with open(self.progress_file, 'r', encoding='utf-8') as f:
                self.progress = json.load(f)
        else:
            self.progress = {
                'started_at': None,
                'completed': [],
                'failed': [],
                'in_progress': [],
                'waves': {}
            }

    def save_progress(self):
        with open(self.progress_file, 'w', encoding='utf-8') as f:
            json.dump(self.progress, f, indent=2, ensure_ascii=False)

    def get_batch_targets(self, wave_id, batch_size=10):
        """Get next batch of targets to process"""
        wave = next((w for w in self.waves if w['id'] == wave_id), None)
        if not wave:
            return []

        completed = set(self.progress.get('completed', []))
        in_progress = set(self.progress.get('in_progress', []))

        batch = []
        for target in wave['targets']:
            target_id = target['id']
            if target_id not in completed and target_id not in in_progress:
                batch.append({
                    'id': target_id,
                    'type': target['type'],
                    'category': target['category'],
                    'wave_id': wave_id,
                    'wave_name': wave['name']
                })
                if len(batch) >= batch_size:
                    break

        return batch

    def generate_task_prompts(self, wave_id, batch_size=10):
        """Generate prompts for Claude Code Task tool"""
        batch = self.get_batch_targets(wave_id, batch_size)

        if not batch:
            print(f"\nâœ… No pending targets for {wave_id} - all completed!\n")
            return []

        print(f"\n{'='*80}")
        print(f"Batch Execution Plan for {wave_id}")
        print(f"{'='*80}")
        print(f"Batch size: {len(batch)} agents")
        print(f"Targets: {', '.join([t['id'] for t in batch])}")
        print(f"{'='*80}\n")

        prompts = []
        for target in batch:
            prompt = self._create_prompt(target)
            prompts.append({
                'target': target,
                'prompt': prompt
            })

        return prompts

    def _create_prompt(self, target):
        """Create detailed prompt for a single document generation"""
        target_id = target['id']
        target_type = target['type']
        category = target['category']
        wave_name = target['wave_name']

        base_path = f"aipm_v0/Stock/programs/å‰µæ¥­æ”¯æ´ãƒ»æ–°è¦äº‹æ¥­é–‹ç™º(AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ)/projects/Founder_Research"

        if target_type == 'founder':
            return f"""# {target_id} - Founder Research Document Generation

## Objective
Generate a comprehensive founder research document for {target_id}.

## Document Structure
Follow the format in documents/08_Emerging/EMERGING_068_bereal.md with these 12 sections:
1. å‰µæ¥­ã®çµŒç·¯ãƒ»èª²é¡Œèªè­˜
2. ã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»äº‹æ¥­å†…å®¹
3. å¸‚å ´ç’°å¢ƒãƒ»ç«¶åˆåˆ†æ
4. æˆé•·ãƒ—ãƒ­ã‚»ã‚¹
5. è³‡é‡‘èª¿é”ãƒ»æŠ•è³‡å®¶
6. æŠ€è¡“ãƒ»ã‚¤ãƒãƒ™ãƒ¼ã‚·ãƒ§ãƒ³
7. ãƒãƒ¼ãƒ ãƒ»çµ„ç¹”æ–‡åŒ–
8. èª²é¡Œã¨è§£æ±ºã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
9. å­¦ã³ãƒ»æ´å¯Ÿ
10. ãƒ‡ãƒ¼ã‚¿ãƒ»KPI
11. å‰µæ¥­è€…ã®ç‰¹å¾´ãƒ»æ€è€ƒ
12. è¿½åŠ æƒ…å ±ãƒ»ç‰¹è¨˜äº‹é … (including ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢)

## Research Instructions
1. Use WebSearch to find information about this company/founder
2. Look for: company background, founder bio, funding history, growth metrics, business model
3. Analyze failure patterns, pivot stories, or success factors as applicable
4. Include specific data points: revenue, funding, user numbers, etc.
5. Provide quality score (0-100) based on source reliability and data completeness

## Output
- File path: {base_path}/documents/{category}/{target_id}.md
- Format: Markdown with proper Japanese formatting
- Include information sources at the end

## Execution Mode
ğŸ¤– FULLY AUTOMATED - No human input required. Make best judgment based on available sources.

Wave: {wave_name}
Category: {category}
"""

        elif target_type == 'failure':
            return f"""# {target_id} - Failure Study Document Generation

## Objective
Generate a comprehensive failure analysis document for {target_id}.

## Document Structure
Create detailed failure study with these sections:
1. ä¼æ¥­æ¦‚è¦ - Company overview
2. å¤±æ•—ã®æ¦‚è¦ - Failure summary
3. åˆæœŸã®æˆåŠŸè¦å›  - Early success factors
4. å¤±æ•—ã®å…†å€™ - Warning signs
5. æ±ºå®šçš„ãªå¤±æ•—è¦å›  - Critical failure factors
6. çµŒå–¶åˆ¤æ–­ã®åˆ†æ - Management decision analysis
7. ã‚¹ãƒ†ãƒ¼ã‚¯ãƒ›ãƒ«ãƒ€ãƒ¼ã¸ã®å½±éŸ¿ - Stakeholder impact
8. æ•™è¨“ãƒ»å­¦ã³ - Lessons learned
9. ãƒ‡ãƒ¼ã‚¿ãƒ»KPI - Key metrics and data
10. ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ - Timeline of events
11. è¿½åŠ æƒ…å ±ãƒ»ç‰¹è¨˜äº‹é … - Additional notes (including ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢)

## Research Instructions
1. Use WebSearch to find detailed information about this company failure
2. Look for: founding story, initial success, pivot points, failure triggers
3. Analyze root causes: market fit, execution, timing, competition, etc.
4. Include specific failure data: burn rate, user churn, revenue decline
5. Provide quality score based on source depth

## Output
- File path: {base_path}/documents/{category}/{target_id}.md
- Format: Markdown with proper Japanese formatting
- Include information sources

## Execution Mode
ğŸ¤– FULLY AUTOMATED - No human input required.

Wave: {wave_name}
Category: {category}
"""

        elif target_type == 'pivot':
            return f"""# {target_id} - Pivot Success Document Generation

## Objective
Generate a comprehensive pivot success story for {target_id}.

## Document Structure
Analyze successful pivot with these sections:
1. åˆæœŸãƒ“ã‚¸ãƒã‚¹ - Original business
2. ãƒ”ãƒœãƒƒãƒˆã®çµŒç·¯ - Pivot background/trigger
3. æ–°ãƒ“ã‚¸ãƒã‚¹ - New business model
4. ãƒ”ãƒœãƒƒãƒˆã®å®Ÿè¡Œ - Pivot execution
5. æˆæœ - Results and outcomes
6. å­¦ã³ãƒ»æ´å¯Ÿ - Insights and learnings
7. ãƒ‡ãƒ¼ã‚¿ãƒ»KPI - Metrics before/after pivot
8. ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ - Pivot timeline
9. è¿½åŠ æƒ…å ±ãƒ»ç‰¹è¨˜äº‹é … - Additional notes (including ã‚¯ã‚ªãƒªãƒ†ã‚£ã‚¹ã‚³ã‚¢)

## Research Instructions
1. Use WebSearch to find pivot story details
2. Compare before/after states: business model, target market, metrics
3. Analyze why pivot was necessary and how it was executed
4. Include specific pivot data: timeline, team changes, metrics shift
5. Provide quality score

## Output
- File path: {base_path}/documents/{category}/{target_id}.md
- Format: Markdown with proper Japanese formatting
- Include information sources

## Execution Mode
ğŸ¤– FULLY AUTOMATED - No human input required.

Wave: {wave_name}
Category: {category}
"""

    def print_execution_instructions(self, wave_id, batch_size=10):
        """Print instructions for manual parallel execution via Claude Code"""
        prompts = self.generate_task_prompts(wave_id, batch_size)

        if not prompts:
            return

        print("\n" + "="*80)
        print("PARALLEL EXECUTION INSTRUCTIONS")
        print("="*80)
        print("\nTo execute this batch in parallel, I will launch multiple Task agents.")
        print(f"Total agents: {len(prompts)}")
        print("\nEach agent will:")
        print("  1. Research the target company/founder using WebSearch")
        print("  2. Generate comprehensive markdown document")
        print("  3. Save to appropriate category folder")
        print("  4. Complete automatically without human input")
        print("\n" + "="*80 + "\n")

        return prompts

    def create_batch_file(self, wave_id, batch_size=10, output_file=None):
        """Create a batch file for execution"""
        if output_file is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = self.scripts_dir / f"batch_{wave_id}_{timestamp}.json"

        prompts = self.generate_task_prompts(wave_id, batch_size)

        batch_data = {
            'wave_id': wave_id,
            'batch_size': len(prompts),
            'created_at': datetime.now().isoformat(),
            'targets': [p['target'] for p in prompts],
            'prompts': [p['prompt'] for p in prompts]
        }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(batch_data, f, indent=2, ensure_ascii=False)

        print(f"\nâœ… Batch file created: {output_file}")
        print(f"Targets: {len(prompts)}")

        return output_file, prompts


def main():
    import argparse

    parser = argparse.ArgumentParser(description='Auto Parallel Executor for Founder Research')
    parser.add_argument('--wave', type=str, required=True, help='Wave ID (e.g., wave1)')
    parser.add_argument('--batch-size', type=int, default=10, help='Batch size')
    parser.add_argument('--create-batch', action='store_true', help='Create batch file')
    parser.add_argument('--project-root', type=str, default='.', help='Project root')

    args = parser.parse_args()

    executor = AutoParallelExecutor(project_root=args.project_root)

    if args.create_batch:
        executor.create_batch_file(args.wave, args.batch_size)
    else:
        executor.print_execution_instructions(args.wave, args.batch_size)


if __name__ == '__main__':
    main()
