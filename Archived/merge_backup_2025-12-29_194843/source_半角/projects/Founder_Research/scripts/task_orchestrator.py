#!/usr/bin/env python3
"""
Task Orchestrator for Wave6 VC-Backed Case Study Generation
============================================================

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯5ã¤ã®ä¸¦åˆ—Taskã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’èµ·å‹•ã—ã€
FOUNDER_176-200ã®25ä»¶ã®VC-Backedã‚±ãƒ¼ã‚¹ã‚¹ã‚¿ãƒ‡ã‚£ã‚’å®Œå…¨è‡ªå‹•ç”Ÿæˆã—ã¾ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
    python3 task_orchestrator.py

æ©Ÿèƒ½:
    - company_assignments.jsonã‹ã‚‰ä¼æ¥­ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    - 5ãƒãƒƒãƒåˆ†ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    - Claude Code Task toolã§5ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä¸¦åˆ—èµ·å‹•
    - å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import json
import os
from pathlib import Path
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆ
PROJECT_ROOT = Path(__file__).parent.parent
SCRIPTS_DIR = PROJECT_ROOT / "scripts"
DOCS_DIR = PROJECT_ROOT / "documents" / "03_VC_Backed"

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
COMPANY_ASSIGNMENTS_FILE = SCRIPTS_DIR / "company_assignments.json"
WAVE_DEFINITIONS_FILE = SCRIPTS_DIR / "wave_definitions.json"
TEMPLATE_FILE = DOCS_DIR / "FOUNDER_151_airbnb.md"

def load_json(filepath):
    """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)

def generate_batch_prompt(batch_data, assignments):
    """
    ãƒãƒƒãƒå°‚ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ

    Args:
        batch_data: wave_definitionsã‹ã‚‰ã®ãƒãƒƒãƒæƒ…å ±
        assignments: company_assignmentsã‹ã‚‰ã®ä¼æ¥­è©³ç´°ãƒ‡ãƒ¼ã‚¿

    Returns:
        str: å®Œå…¨ãªTaskã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    """
    batch_id = batch_data['batch_id']
    vc_focus = batch_data['vc_focus']

    # assignmentsã‹ã‚‰è©²å½“ãƒãƒƒãƒã®ä¼æ¥­ãƒ‡ãƒ¼ã‚¿å–å¾—
    batch_assignments = None
    for batch in assignments['wave6']['batches']:
        if batch['batch_id'] == batch_id:
            batch_assignments = batch
            break

    if not batch_assignments:
        raise ValueError(f"Batch {batch_id} not found in company_assignments.json")

    # ä¼æ¥­ãƒªã‚¹ãƒˆã‚’æ•´å½¢
    cases_list = []
    for idx, case in enumerate(batch_assignments['cases'], 1):
        case_text = f"""
{idx}. **{case['id']}**: {case['company']}
   - Founders: {case['founders']}
   - Founded: {case['founded_year']}
   - Valuation: {case['current_valuation']}
   - VC Angle: {case['vc_angle']}
   - Estimated Interview Count: {case['estimated_interview_count']}
   - Estimated Problem Commonality: {case['estimated_problem_commonality']}%
   - Research Notes: {case['research_notes']}
"""
        cases_list.append(case_text)

    cases_text = "\n".join(cases_list)

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
    prompt = f"""# AUTONOMOUS CASE STUDY GENERATION - {batch_id.upper()}

## CRITICAL: FULL AUTOMATION MODE
- **NO human input required**
- **NO questions or confirmations**
- Use best judgment and available online sources
- Complete all 5 cases in this batch
- Work autonomously from start to finish

## VC FOCUS: {vc_focus}
Emphasize {vc_focus}'s investment perspective, board participation, and value-add throughout all case studies.

## TEMPLATE STRUCTURE (MANDATORY)
Follow FOUNDER_151_airbnb.md format EXACTLY:

### YAML Front Matter (å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰):
```yaml
---
id: "FOUNDER_XXX"
title: "{{Founder Name}} - {{Company}}"
category: "founder"
tier: "vc_backed"
type: "case_study"
version: "1.0"
created_at: "2025-12-29"
updated_at: "2025-12-29"
tags: [relevant tags including VC name, industry, exit type]

# åŸºæœ¬æƒ…å ±
founder:
  name: "Full Name (Role)"
  birth_year: YYYY
  nationality: "Country"
  education: "University/Degree"
  prior_experience: "Previous roles/companies"

company:
  name: "Company Name"
  founded_year: YYYY
  industry: "Primary Industry / Sector"
  current_status: "ipo|acquired|active|shutdown"
  valuation: "$XXB (description)"
  employees: XXXX

# VCæŠ•è³‡æƒ…å ± (CRITICAL - è©³ç´°å¿…é ˆ)
funding:
  total_raised: "$XXB"
  funding_rounds:
    - round: "seed|series_a|series_b|series_c|..."
      date: "YYYY-MM-DD"
      amount: "$XXM"
      valuation_post: "$XXM|$XXB"
      lead_investors: ["VC Name"]
      other_investors: ["Investor 1", "Investor 2"]
  top_tier_vcs: ["{vc_focus}", "Other Top VCs"]

# æˆåŠŸ/å¤±æ•—/Pivotåˆ†é¡
outcome:
  category: "success|failure|pivot"
  subcategory: "exit_success|growth_success|..."
  failure_pattern: ""
  pivot_details:
    count: 0
    major_pivots: []

# orchestrate-phase1å¯¾å¿œ (CPF/PSFæ¤œè¨¼ãƒ‡ãƒ¼ã‚¿)
validation_data:
  cpf:
    interview_count: XX-XXX (research or estimate)
    problem_commonality: XX (percentage 0-100)
    wtp_confirmed: true|false
    urgency_score: X (1-10)
    validation_method: "æ–¹æ³•ã®èª¬æ˜"
  psf:
    ten_x_axes:
      - axis: "è»¸ã®åå‰ (ä¾‹: ã‚³ã‚¹ãƒˆå‰Šæ¸›)"
        multiplier: X (3, 5, 10, 20, 50, 100)
      - axis: "åˆ¥ã®è»¸"
        multiplier: Y
    mvp_type: "concierge|wizard_of_oz|landing_page|prototype|..."
    initial_cvr: null or percentage
    uvp_clarity: X (1-10)
    competitive_advantage: "Main differentiator"

# å“è³ªä¿è¨¼
quality:
  fact_check: "pass"
  sources_count: XX (minimum 12)
  last_verified: "2025-12-29"
  primary_sources: []
---
```

### Markdownæœ¬æ–‡ (12ã‚»ã‚¯ã‚·ãƒ§ãƒ³å¿…é ˆ):

1. **åŸºæœ¬æƒ…å ±**
   - å‰µæ¥­è€…ãƒ»ä¼æ¥­æ¦‚è¦ãƒ†ãƒ¼ãƒ–ãƒ«

2. **å‰µæ¥­ã‚¹ãƒˆãƒ¼ãƒªãƒ¼**
   - 2.1 èª²é¡Œç™ºè¦‹ (Demand Discovery)
   - 2.2 CPFæ¤œè¨¼ (Customer Problem Fit validation)
   - 2.3 PSFæ¤œè¨¼ (Problem Solution Fit with 10x axes table)

3. **ãƒ”ãƒœãƒƒãƒˆ/å¤±æ•—çµŒé¨“**
   - åˆæœŸã®è©¦è¡ŒéŒ¯èª¤ã‚„ãƒ”ãƒœãƒƒãƒˆ

4. **æˆé•·æˆ¦ç•¥**
   - 4.1 åˆæœŸãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³
   - 4.2 Flywheel/æˆé•·ãƒ«ãƒ¼ãƒ—
   - 4.3 ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æˆ¦ç•¥
   - 4.4 ãƒãƒªãƒ¥ãƒ¼ãƒã‚§ãƒ¼ãƒ³
   - **4.5 è³‡é‡‘èª¿é”å±¥æ­´** (**{vc_focus}ã®å½¹å‰²ã‚’è©³è¿°**)

5. **ä½¿ç”¨ãƒ„ãƒ¼ãƒ«ãƒ»ã‚µãƒ¼ãƒ“ã‚¹**
   - æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã€ã‚¤ãƒ³ãƒ•ãƒ©

6. **æˆåŠŸè¦å› åˆ†æ**
   - KSFã€ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã€å·®åˆ¥åŒ–

7. **æ—¥æœ¬å¸‚å ´é©ç”¨æ€§**
   - 5æ®µéšã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° (Cultural Fit, Regulatory, Market Size, Competition, Localization)

8. **orchestrate-phase1ã¸ã®ç¤ºå”†**
   - CPF/PSFæ¤œè¨¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¸ã®å­¦ã³

9. **äº‹æ¥­ã‚¢ã‚¤ãƒ‡ã‚¢å€™è£œ**
   - ã“ã®ã‚±ãƒ¼ã‚¹ã‹ã‚‰ç€æƒ³ã™ã‚‹3ã¤ã®ãƒ“ã‚¸ãƒã‚¹ã‚¢ã‚¤ãƒ‡ã‚¢

10. **ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚¯çµæœ**
    - ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ãƒ†ãƒ¼ãƒ–ãƒ« (PASS/WARN/FAIL)

11. **å‚ç…§ã‚½ãƒ¼ã‚¹**
    - 12+ã®æ¤œè¨¼æ¸ˆã¿ã‚½ãƒ¼ã‚¹ (URLs, è¨˜äº‹, æ›¸ç±)

## RESEARCH REQUIREMENTS

### Data Collection (WebSearchãƒ„ãƒ¼ãƒ«å¿…é ˆä½¿ç”¨):
- **Funding History**: å…¨ã¦ã®è³‡é‡‘èª¿é”ãƒ©ã‚¦ãƒ³ãƒ‰ (amount, date, valuation, investors)
- **{vc_focus} Role**: æŠ•è³‡åˆ¤æ–­ã®èƒŒæ™¯ã€ãƒœãƒ¼ãƒ‰å‚åŠ ã€æˆ¦ç•¥çš„æ”¯æ´å†…å®¹
- **Founder Background**: å­¦æ­´ã€è·æ­´ã€åŸä½“é¨“
- **Customer Validation**: interview_count, problem_commonality (ç ”ç©¶ã¾ãŸã¯æ¨å®š)
- **Ten_x_axes**: ç«¶åˆæ¯”è¼ƒã§ã®10å€å„ªä½æ€§ (2-5è»¸)
- **Sources**: æœ€ä½12ã®ä¿¡é ¼ã§ãã‚‹ã‚½ãƒ¼ã‚¹ (Crunchbase, TechCrunch, å…¬å¼ãƒ–ãƒ­ã‚°, ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼è¨˜äº‹)

### Estimation Guidelines (ãƒªã‚µãƒ¼ãƒä¸ååˆ†æ™‚):
- **interview_count**:
  - Seedæ®µéš: 40-80
  - Series A: 80-120
  - Series B+: 120-150+
- **problem_commonality**:
  - B2B SaaS: 60-80%
  - Consumer: 70-90%
  - Deep Tech: 40-60%
- æ¨å®šå€¤ã¯ `(estimated)` ãƒ•ãƒ©ã‚°ä»˜ä¸

## OUTPUT LOCATION
Save each file to:
```
/Users/yuichi/AIPM/aipm_v0/Stock/programs/å‰µæ¥­æ”¯æ´ãƒ»æ–°è¦äº‹æ¥­é–‹ç™º(AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ)/projects/Founder_Research/documents/03_VC_Backed/FOUNDER_XXX_{{company_slug}}.md
```

File naming: `FOUNDER_176_stripe.md`, `FOUNDER_177_reddit.md`, etc.

## ASSIGNED CASES FOR {batch_id.upper()}
{cases_text}

## EXECUTION INSTRUCTIONS

1. **Start Immediately**: No confirmations, no delays
2. **Research Thoroughly**: Use WebSearch for each company extensively
3. **Generate Complete Files**: YAML + 12 markdown sections for all 5 cases
4. **Quality Assurance**: 12+ sources, fact_check: "pass", all CPF/PSF data populated
5. **Save Files**: Use Write tool to save to correct directory
6. **Report Completion**: After all 5 cases complete, report file paths

## SUCCESS CRITERIA
- [ ] 5 files created
- [ ] All follow FOUNDER_151 template
- [ ] All have 12+ sources
- [ ] All have fact_check: "pass"
- [ ] All have CPF/PSF data (research or estimated)
- [ ] All emphasize {vc_focus} investment perspective

## BEGIN EXECUTION NOW
Start with {batch_assignments['cases'][0]['id']} ({batch_assignments['cases'][0]['company']}) and proceed through all 5 cases.
"""

    return prompt

def generate_all_prompts():
    """å…¨ãƒãƒƒãƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ"""
    print("ğŸ“– Loading configuration files...")
    assignments = load_json(COMPANY_ASSIGNMENTS_FILE)
    wave_defs = load_json(WAVE_DEFINITIONS_FILE)

    wave6 = wave_defs['waves'][0]
    print(f"\nâœ… Loaded Wave6: {wave6['name']}")
    print(f"   Total batches: {len(wave6['batches'])}")
    print(f"   Total cases: {wave6['count']}\n")

    prompts = {}
    for batch in wave6['batches']:
        batch_id = batch['batch_id']
        print(f"ğŸ”¨ Generating prompt for {batch_id} ({batch['vc_focus']})...")
        prompt = generate_batch_prompt(batch, assignments)
        prompts[batch_id] = {
            'vc_focus': batch['vc_focus'],
            'prompt': prompt
        }

    return prompts

def save_prompts_for_manual_execution(prompts):
    """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ (æ‰‹å‹•å®Ÿè¡Œç”¨)"""
    output_dir = SCRIPTS_DIR / "generated_prompts"
    output_dir.mkdir(exist_ok=True)

    for batch_id, data in prompts.items():
        output_file = output_dir / f"{batch_id}_prompt.md"
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(data['prompt'])
        print(f"   ğŸ’¾ Saved: {output_file}")

    print(f"\nâœ… All prompts saved to: {output_dir}\n")

def print_task_tool_instructions(prompts):
    """Task toolå®Ÿè¡Œæ‰‹é †ã‚’å‡ºåŠ›"""
    print("\n" + "="*80)
    print("ğŸš€ TASK TOOL PARALLEL EXECUTION INSTRUCTIONS")
    print("="*80)
    print("\nClaude Code UIã§ä»¥ä¸‹ã®Task toolã‚³ãƒãƒ³ãƒ‰ã‚’5ã¤ä¸¦åˆ—å®Ÿè¡Œã—ã¦ãã ã•ã„:\n")

    for idx, (batch_id, data) in enumerate(prompts.items(), 1):
        print(f"\n--- Task {idx}: {batch_id} ({data['vc_focus']}) ---")
        print(f"```")
        print(f"Use Task tool with:")
        print(f"  subagent_type: general-purpose")
        print(f"  description: Generate {batch_id} VC-backed cases")
        print(f"  prompt: <paste from scripts/generated_prompts/{batch_id}_prompt.md>")
        print(f"```")

    print("\n" + "="*80)
    print("â±ï¸  Expected completion time: 35-45 minutes")
    print("ğŸ“Š Total cases to generate: 25")
    print("="*80 + "\n")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\n" + "="*80)
    print("ğŸ¯ WAVE6 VC-BACKED CASE STUDY ORCHESTRATOR")
    print("="*80 + "\n")

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
    prompts = generate_all_prompts()

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    print("\nğŸ’¾ Saving prompts to files...")
    save_prompts_for_manual_execution(prompts)

    # Task toolå®Ÿè¡Œæ‰‹é †ã‚’è¡¨ç¤º
    print_task_tool_instructions(prompts)

    print("âœ… Orchestrator setup complete!")
    print("\næ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. Claude Code UIã‚’é–‹ã")
    print("2. ä¸Šè¨˜ã®5ã¤ã®Taskãƒ„ãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰ã‚’1ã¤ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§åŒæ™‚å®Ÿè¡Œ")
    print("3. 35-45åˆ†å¾…æ©Ÿ")
    print("4. validate_wave6.pyå®Ÿè¡Œã§å“è³ªæ¤œè¨¼\n")

if __name__ == "__main__":
    main()
