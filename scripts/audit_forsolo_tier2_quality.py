#!/usr/bin/env python3
"""
ForSolo Tier 2 Case Studies Quality Audit Script

å“è³ªç›£æŸ»åŸºæº–ï¼ˆ100ç‚¹æº€ç‚¹ï¼‰:
1. å®šé‡ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§ (30ç‚¹): MRR, é–‹ç™ºæœŸé–“, ã‚³ã‚¹ãƒˆ, ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°ç­‰
2. ã‚½ãƒ¼ã‚¹ä¿¡é ¼æ€§ (25ç‚¹): 1æ¬¡ã‚½ãƒ¼ã‚¹ãƒªãƒ³ã‚¯ (X/Twitter, å…¬å¼ã‚µã‚¤ãƒˆ, Product Hunt)
3. 1äººå®Ÿè¡Œå¯èƒ½æ€§ (30ç‚¹): Solo Fitè©•ä¾¡ (6è»¸)
4. ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸ (15ç‚¹): å¯¾è±¡ã‚¹ã‚­ãƒ«ã®æ¤œè¨¼ãƒã‚¤ãƒ³ãƒˆç¶²ç¾…

ç›®æ¨™: å…¨ãƒ•ã‚¡ã‚¤ãƒ«95ç‚¹ä»¥ä¸Š
"""

import os
import re
from pathlib import Path
from typing import Dict, List, Tuple
import json

# Base path
BASE_PATH = Path("/Users/yuichi/AIPM/aipm_v0/Stock/programs/å‰µæ¥­æ”¯æ´ãƒ»æ–°è¦äº‹æ¥­é–‹ç™ºï¼ˆAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰/projects/Founder_Agent_ForSolo/knowledge_base/tier2_case_studies")

# Required elements for 95+ quality score
REQUIRED_ELEMENTS = {
    "yaml_frontmatter": {
        "weight": 10,
        "keywords": ["---", "id:", "solo_fit_score:", "category:", "mrr:"]
    },
    "solo_fit_evaluation": {
        "weight": 30,
        "keywords": ["Solo Fit", "æŠ€è¡“å®Ÿè¡Œå¯èƒ½æ€§", "ã‚¹ã‚­ãƒ«å……è¶³åº¦", "æ™‚é–“ç¢ºä¿å¯èƒ½æ€§", "ã‚³ã‚¹ãƒˆå®Ÿç¾å¯èƒ½æ€§", "ãƒžãƒ¼ã‚±å®Ÿè¡Œå¯èƒ½æ€§", "ã‚µãƒãƒ¼ãƒˆå®Ÿè¡Œå¯èƒ½æ€§"]
    },
    "quality_score_section": {
        "weight": 15,
        "keywords": ["Quality Score", "å®šé‡ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§", "ã‚½ãƒ¼ã‚¹ä¿¡é ¼æ€§", "1äººå®Ÿè¡Œå¯èƒ½æ€§", "ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸"]
    },
    "primary_sources": {
        "weight": 25,
        "keywords": ["twitter.com", "x.com", "producthunt.com", "https://"],
        "min_count": 2
    },
    "japan_market_adaptation": {
        "weight": 10,
        "keywords": ["æ—¥æœ¬å¸‚å ´", "Japanese Market", "æ–‡åŒ–çš„é©å¿œ", "æŽ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆæ—¥æœ¬ï¼‰"]
    },
    "playbook": {
        "weight": 10,
        "keywords": ["Playbook", "Week 1", "Month", "ã‚¹ãƒ†ãƒƒãƒ—", "ã‚¿ã‚¹ã‚¯", "- [ ]"]
    }
}

# Quantitative data keywords
QUANTITATIVE_KEYWORDS = [
    "MRR", "ARR", "$", "ãƒ‰ãƒ«",
    "é–‹ç™ºæœŸé–“", "æ—¥", "é€±é–“", "ãƒ¶æœˆ",
    "åˆæœŸæŠ•è³‡", "ã‚³ã‚¹ãƒˆ",
    "ãƒ¦ãƒ¼ã‚¶ãƒ¼æ•°", "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼",
    "LTV", "CAC", "åˆ©ç›ŠçŽ‡"
]


def check_yaml_frontmatter(content: str) -> Tuple[bool, int]:
    """Check if file has valid YAML frontmatter"""
    if not content.startswith("---"):
        return False, 0

    # Extract YAML section
    yaml_match = re.match(r'^---\n(.*?)\n---', content, re.DOTALL)
    if not yaml_match:
        return False, 0

    yaml_content = yaml_match.group(1)
    required_fields = ["id:", "solo_fit_score:", "category:"]
    score = sum(10 for field in required_fields if field in yaml_content) / len(required_fields)

    return len([f for f in required_fields if f in yaml_content]) >= 2, int(score * 10)


def check_solo_fit_evaluation(content: str) -> Tuple[bool, int]:
    """Check for 6-axis Solo Fit evaluation"""
    axes = [
        "æŠ€è¡“å®Ÿè¡Œå¯èƒ½æ€§", "ã‚¹ã‚­ãƒ«å……è¶³åº¦", "æ™‚é–“ç¢ºä¿å¯èƒ½æ€§",
        "ã‚³ã‚¹ãƒˆå®Ÿç¾å¯èƒ½æ€§", "ãƒžãƒ¼ã‚±å®Ÿè¡Œå¯èƒ½æ€§", "ã‚µãƒãƒ¼ãƒˆå®Ÿè¡Œå¯èƒ½æ€§"
    ]

    found_axes = sum(1 for axis in axes if axis in content)

    # Check for scoring (X/10 pattern)
    score_patterns = re.findall(r'(\d+)/10', content)
    has_scores = len(score_patterns) >= 6

    if found_axes >= 6 and has_scores:
        return True, 30
    elif found_axes >= 4:
        return False, 20
    else:
        return False, 10


def check_quality_score_section(content: str) -> Tuple[bool, int]:
    """Check for Quality Score breakdown section"""
    required_criteria = ["å®šé‡ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§", "ã‚½ãƒ¼ã‚¹ä¿¡é ¼æ€§", "1äººå®Ÿè¡Œå¯èƒ½æ€§", "ã‚¹ã‚­ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸"]
    found_criteria = sum(1 for criterion in required_criteria if criterion in content)

    has_score_heading = "Quality Score" in content or "å“è³ªã‚¹ã‚³ã‚¢" in content

    if has_score_heading and found_criteria >= 4:
        return True, 15
    elif found_criteria >= 2:
        return False, 8
    else:
        return False, 0


def check_primary_sources(content: str) -> Tuple[bool, int]:
    """Check for primary source links (X/Twitter, Product Hunt, official sites)"""
    # Count URLs
    urls = re.findall(r'https?://[^\s\)]+', content)

    # Check for primary sources
    primary_sources = [
        url for url in urls
        if any(domain in url.lower() for domain in ["twitter.com", "x.com", "producthunt.com"])
    ]

    # Check for References section
    has_references_section = "## References" in content or "## å‚ç…§" in content

    if len(primary_sources) >= 2 and has_references_section:
        return True, 25
    elif len(primary_sources) >= 1:
        return False, 15
    elif len(urls) >= 1:
        return False, 8
    else:
        return False, 0


def check_japan_market_adaptation(content: str) -> Tuple[bool, int]:
    """Check for Japan market adaptation section"""
    keywords = ["æ—¥æœ¬å¸‚å ´", "Japanese Market", "æ–‡åŒ–çš„é©å¿œ", "æŽ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼ˆæ—¥æœ¬ï¼‰"]
    found = sum(1 for keyword in keywords if keyword in content)

    has_section = any(heading in content for heading in ["## æ—¥æœ¬å¸‚å ´é©ç”¨", "## Japanese Market", "### æ–‡åŒ–çš„é©å¿œ"])

    if has_section and found >= 2:
        return True, 10
    elif found >= 1:
        return False, 5
    else:
        return False, 0


def check_playbook(content: str) -> Tuple[bool, int]:
    """Check for actionable playbook section"""
    playbook_keywords = ["Playbook", "å®Ÿè¡Œãƒ—ãƒ©ãƒ³", "Week 1", "Month", "ãƒ•ã‚§ãƒ¼ã‚º"]
    has_playbook_heading = any(keyword in content for keyword in playbook_keywords)

    # Check for task checkboxes
    task_checkboxes = re.findall(r'- \[ \]', content)

    if has_playbook_heading and len(task_checkboxes) >= 5:
        return True, 10
    elif has_playbook_heading:
        return False, 5
    else:
        return False, 0


def check_quantitative_data(content: str) -> int:
    """Check for quantitative data completeness"""
    found_keywords = sum(1 for keyword in QUANTITATIVE_KEYWORDS if keyword in content)

    # Bonus for specific metrics
    has_mrr = bool(re.search(r'\$\d+[,\d]*', content))
    has_timeline = bool(re.search(r'\d+æ—¥|\d+é€±é–“|\d+ãƒ¶æœˆ', content))

    score = min(15, found_keywords * 2)
    if has_mrr:
        score += 5
    if has_timeline:
        score += 5

    return min(25, score)


def audit_file(file_path: Path) -> Dict:
    """Audit a single file and return quality assessment"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        return {
            "file": str(file_path),
            "error": str(e),
            "total_score": 0
        }

    # Perform checks
    results = {}
    total_score = 0

    # 1. YAML Frontmatter (10 points)
    has_yaml, yaml_score = check_yaml_frontmatter(content)
    results["yaml_frontmatter"] = {"present": has_yaml, "score": yaml_score}
    total_score += yaml_score

    # 2. Solo Fit Evaluation (30 points)
    has_solo_fit, solo_fit_score = check_solo_fit_evaluation(content)
    results["solo_fit_evaluation"] = {"present": has_solo_fit, "score": solo_fit_score}
    total_score += solo_fit_score

    # 3. Quality Score Section (15 points)
    has_quality, quality_score = check_quality_score_section(content)
    results["quality_score_section"] = {"present": has_quality, "score": quality_score}
    total_score += quality_score

    # 4. Primary Sources (25 points)
    has_sources, sources_score = check_primary_sources(content)
    results["primary_sources"] = {"present": has_sources, "score": sources_score}
    total_score += sources_score

    # 5. Japan Market Adaptation (10 points)
    has_japan, japan_score = check_japan_market_adaptation(content)
    results["japan_market_adaptation"] = {"present": has_japan, "score": japan_score}
    total_score += japan_score

    # 6. Playbook (10 points)
    has_playbook_section, playbook_score = check_playbook(content)
    results["playbook"] = {"present": has_playbook_section, "score": playbook_score}
    total_score += playbook_score

    # Calculate word count
    word_count = len(content)

    return {
        "file": str(file_path.relative_to(BASE_PATH)),
        "skill": file_path.parent.name,
        "word_count": word_count,
        "total_score": total_score,
        "elements": results,
        "needs_improvement": total_score < 95,
        "priority": "é«˜" if total_score < 80 else "ä¸­" if total_score < 90 else "ä½Ž"
    }


def generate_report(audit_results: List[Dict]) -> str:
    """Generate markdown audit report"""

    # Statistics
    total_files = len(audit_results)
    avg_score = sum(r["total_score"] for r in audit_results) / total_files if total_files > 0 else 0
    files_below_95 = sum(1 for r in audit_results if r["total_score"] < 95)
    files_below_90 = sum(1 for r in audit_results if r["total_score"] < 90)
    files_below_80 = sum(1 for r in audit_results if r["total_score"] < 80)

    # Group by skill
    by_skill = {}
    for result in audit_results:
        skill = result["skill"]
        if skill not in by_skill:
            by_skill[skill] = []
        by_skill[skill].append(result)

    # Generate report
    report = f"""# ForSolo Tier 2 Case Studies - å“è³ªç›£æŸ»ãƒ¬ãƒãƒ¼ãƒˆ

**ç›£æŸ»æ—¥**: 2026-01-03
**å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {total_files}
**å¹³å‡å“è³ªã‚¹ã‚³ã‚¢**: {avg_score:.1f}/100

---

## 1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒžãƒªãƒ¼

### ç¾çŠ¶åˆ†æž
- **95ç‚¹æœªé”**: {files_below_95}ä»¶ ({files_below_95/total_files*100:.1f}%)
- **90ç‚¹æœªé”**: {files_below_90}ä»¶ ({files_below_90/total_files*100:.1f}%)
- **80ç‚¹æœªé”**: {files_below_80}ä»¶ ({files_below_80/total_files*100:.1f}%)

### æ”¹å–„å¿…è¦æ€§
- **ç›®æ¨™**: å…¨ãƒ•ã‚¡ã‚¤ãƒ«95ç‚¹ä»¥ä¸Š
- **ç¾çŠ¶å¹³å‡**: {avg_score:.1f}ç‚¹
- **ã‚®ãƒ£ãƒƒãƒ—**: {95 - avg_score:.1f}ç‚¹

### ä¸»è¦ãªä¸è¶³è¦ç´ ï¼ˆå…¨ä½“å‚¾å‘ï¼‰

"""

    # Calculate missing elements statistics
    element_stats = {
        "yaml_frontmatter": 0,
        "solo_fit_evaluation": 0,
        "quality_score_section": 0,
        "primary_sources": 0,
        "japan_market_adaptation": 0,
        "playbook": 0
    }

    for result in audit_results:
        for element, data in result["elements"].items():
            if not data["present"]:
                element_stats[element] += 1

    element_names = {
        "yaml_frontmatter": "YAML Frontmatter",
        "solo_fit_evaluation": "Solo Fitè©•ä¾¡ï¼ˆ6è»¸ï¼‰",
        "quality_score_section": "Quality Scoreã‚»ã‚¯ã‚·ãƒ§ãƒ³",
        "primary_sources": "1æ¬¡ã‚½ãƒ¼ã‚¹ãƒªãƒ³ã‚¯",
        "japan_market_adaptation": "æ—¥æœ¬å¸‚å ´é©ç”¨",
        "playbook": "Actionable Playbook"
    }

    for element, count in sorted(element_stats.items(), key=lambda x: x[1], reverse=True):
        percentage = count / total_files * 100
        report += f"- **{element_names[element]}**: {count}ä»¶ä¸è¶³ ({percentage:.1f}%)\n"

    report += f"""

---

## 2. ã‚¹ã‚­ãƒ«åˆ¥å“è³ªã‚µãƒžãƒªãƒ¼

| ã‚¹ã‚­ãƒ« | ãƒ•ã‚¡ã‚¤ãƒ«æ•° | å¹³å‡ã‚¹ã‚³ã‚¢ | 95ç‚¹æœªé” | å„ªå…ˆåº¦ |
|--------|-----------|-----------|---------|--------|
"""

    for skill, results in sorted(by_skill.items()):
        skill_avg = sum(r["total_score"] for r in results) / len(results)
        skill_below_95 = sum(1 for r in results if r["total_score"] < 95)
        priority = "é«˜" if skill_avg < 85 else "ä¸­" if skill_avg < 92 else "ä½Ž"
        report += f"| {skill} | {len(results)} | {skill_avg:.1f} | {skill_below_95} | {priority} |\n"

    report += f"""

---

## 3. è©³ç´°ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ç›£æŸ»çµæžœ

"""

    # Sort by score (lowest first)
    sorted_results = sorted(audit_results, key=lambda x: x["total_score"])

    for result in sorted_results:
        file_name = result["file"]
        score = result["total_score"]
        priority = result["priority"]

        report += f"""### {file_name}
**ã‚¹ã‚³ã‚¢**: {score}/100 | **å„ªå…ˆåº¦**: {priority}

| è¦ç´  | çŠ¶æ…‹ | ã‚¹ã‚³ã‚¢ |
|------|------|--------|
"""

        for element, data in result["elements"].items():
            status = "âœ…" if data["present"] else "âŒ"
            report += f"| {element_names[element]} | {status} | {data['score']} |\n"

        # Missing elements
        missing = [element_names[elem] for elem, data in result["elements"].items() if not data["present"]]
        if missing:
            report += f"\n**ä¸è¶³è¦ç´ **: {', '.join(missing)}\n"

        report += "\n---\n\n"

    report += f"""
## 4. æ”¹å–„æŽ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³

### å„ªå…ˆåº¦ã€Œé«˜ã€ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ80ç‚¹æœªæº€ï¼‰: {files_below_80}ä»¶
- å…¨è¦ç´ ã‚’è¿½åŠ 
- Solopreneur_Researchã‹ã‚‰å…ƒãƒ‡ãƒ¼ã‚¿å†å–å¾—
- 1æ¬¡ã‚½ãƒ¼ã‚¹ãƒªãƒ³ã‚¯å¿…é ˆè¿½åŠ 

### å„ªå…ˆåº¦ã€Œä¸­ã€ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ80-94ç‚¹ï¼‰: {files_below_95 - files_below_80}ä»¶
- ä¸è¶³è¦ç´ ã®ã¿è¿½åŠ 
- Solo Fitè©•ä¾¡ã€æ—¥æœ¬å¸‚å ´é©ç”¨ã‚’é‡ç‚¹çš„ã«

### å„ªå…ˆåº¦ã€Œä½Žã€ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ95ç‚¹ä»¥ä¸Šï¼‰: {total_files - files_below_95}ä»¶
- å¾®èª¿æ•´ã®ã¿
- å“è³ªã‚¹ã‚³ã‚¢ã‚»ã‚¯ã‚·ãƒ§ãƒ³è¿½åŠ ã§å®Œäº†

---

## 5. æŽ¨å®šä½œæ¥­æ™‚é–“

| å„ªå…ˆåº¦ | ãƒ•ã‚¡ã‚¤ãƒ«æ•° | æ™‚é–“/ãƒ•ã‚¡ã‚¤ãƒ« | åˆè¨ˆæ™‚é–“ |
|--------|-----------|--------------|---------|
| é«˜ | {files_below_80} | 2æ™‚é–“ | {files_below_80 * 2}æ™‚é–“ |
| ä¸­ | {files_below_95 - files_below_80} | 1æ™‚é–“ | {(files_below_95 - files_below_80) * 1}æ™‚é–“ |
| ä½Ž | {total_files - files_below_95} | 0.5æ™‚é–“ | {(total_files - files_below_95) * 0.5}æ™‚é–“ |
| **åˆè¨ˆ** | **{total_files}** | - | **{files_below_80 * 2 + (files_below_95 - files_below_80) * 1 + (total_files - files_below_95) * 0.5}æ™‚é–“** |

---

**ç›£æŸ»å®Œäº†**: Phase 1-1å®Œäº†ã€Phase 1-2ï¼ˆãƒ‡ãƒ¼ã‚¿è£œå®Œï¼‰ã¸ç§»è¡Œå¯èƒ½
"""

    return report


def main():
    """Main audit execution"""
    print("ForSolo Tier 2 å“è³ªç›£æŸ»é–‹å§‹...")
    print(f"å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {BASE_PATH}")

    # Find all markdown files
    all_files = list(BASE_PATH.rglob("*.md"))
    print(f"ç™ºè¦‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(all_files)}")

    # Audit each file
    audit_results = []
    for i, file_path in enumerate(all_files, 1):
        print(f"ç›£æŸ»ä¸­ ({i}/{len(all_files)}): {file_path.name}")
        result = audit_file(file_path)
        audit_results.append(result)

    # Generate report
    print("\nç›£æŸ»ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
    report = generate_report(audit_results)

    # Save report
    report_path = Path("/Users/yuichi/AIPM/aipm_v0/Stock/programs/å‰µæ¥­æ”¯æ´ãƒ»æ–°è¦äº‹æ¥­é–‹ç™ºï¼ˆAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰/projects/Founder_Agent_ForSolo/existing_files_quality_audit_report.md")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)

    # Save JSON data
    json_path = report_path.with_suffix('.json')
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(audit_results, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ç›£æŸ»å®Œäº†")
    print(f"ðŸ“„ ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
    print(f"ðŸ“Š JSONãƒ‡ãƒ¼ã‚¿: {json_path}")

    # Print summary
    avg_score = sum(r["total_score"] for r in audit_results) / len(audit_results)
    files_below_95 = sum(1 for r in audit_results if r["total_score"] < 95)
    print(f"\nðŸ“Š ã‚µãƒžãƒªãƒ¼:")
    print(f"  - å¹³å‡ã‚¹ã‚³ã‚¢: {avg_score:.1f}/100")
    print(f"  - 95ç‚¹æœªé”: {files_below_95}ä»¶ ({files_below_95/len(audit_results)*100:.1f}%)")


if __name__ == "__main__":
    main()
