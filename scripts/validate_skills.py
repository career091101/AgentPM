#!/usr/bin/env python3
"""
ForStartup Skills Validation Script

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯ä»¥ä¸‹ã®æ¤œè¨¼ã‚’è¡Œã„ã¾ã™:
1. YAML ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ¤œè¨¼
2. ForRecruitæ®‹éª¸ã®æ¤œå‡º
3. ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã®æ¤œè¨¼
4. MarkdownåŸºæœ¬æ§‹æ–‡ã®æ¤œè¨¼
"""

import os
import sys
import json
import yaml
import re
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, asdict
from datetime import datetime


@dataclass
class ValidationError:
    """æ¤œè¨¼ã‚¨ãƒ©ãƒ¼æƒ…å ±"""
    file: str
    message: str
    severity: str = "error"  # "error" or "warning"


@dataclass
class ValidationReport:
    """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ"""
    timestamp: str
    errors: List[Dict]
    warnings: List[Dict]
    summary: Dict


class SkillValidator:
    """ForStartup Skillsã®æ¤œè¨¼ã‚¯ãƒ©ã‚¹"""

    # å¿…é ˆãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    REQUIRED_FIELDS = [
        'trigger_keywords',
        'stage',
        'output_file',
        'dependencies'
    ]

    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å‹
    FIELD_TYPES = {
        'trigger_keywords': (list,),
        'stage': (str,),
        'output_file': (str,),
        'dependencies': (list,),
        'name': (str,),
        'description': (str,),
    }

    def __init__(self, base_dir: str = '.'):
        self.base_dir = Path(base_dir)
        self.skills_dir = self.base_dir / '.claude' / 'skills' / 'for_startup'
        self.errors: List[ValidationError] = []
        self.warnings: List[ValidationError] = []

    def validate_all(self) -> bool:
        """å…¨ã‚¹ã‚­ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼ã‚’å®Ÿè¡Œ"""
        print(f"Validating ForStartup Skills in: {self.skills_dir}")

        if not self.skills_dir.exists():
            print(f"âš ï¸  Skills directory not found: {self.skills_dir}")
            return True  # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—

        # SKILL.md ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        skill_files = list(self.skills_dir.glob('**/SKILL.md'))

        if not skill_files:
            print("âš ï¸  No SKILL.md files found")
            return True

        print(f"Found {len(skill_files)} SKILL.md files\n")

        for skill_file in skill_files:
            print(f"Validating: {skill_file.relative_to(self.base_dir)}")
            self._validate_skill_file(skill_file)

        # ForRecruitæ®‹éª¸ã‚’ãƒã‚§ãƒƒã‚¯
        print("\nChecking for ForRecruit remnants...")
        self._check_for_recruit_remnants()

        # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
        self._generate_report()

        return len(self.errors) == 0

    def _validate_skill_file(self, file_path: Path) -> None:
        """å€‹åˆ¥ã‚¹ã‚­ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼"""
        try:
            content = file_path.read_text(encoding='utf-8')

            # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’æŠ½å‡º
            frontmatter, body = self._extract_frontmatter(content)

            if frontmatter is None:
                self.errors.append(ValidationError(
                    str(file_path.relative_to(self.base_dir)),
                    "YAML frontmatter not found or invalid",
                    "error"
                ))
                return

            # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ¤œè¨¼
            self._validate_required_fields(file_path, frontmatter)

            # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å‹ã‚’æ¤œè¨¼
            self._validate_field_types(file_path, frontmatter)

            # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã®å†…å®¹ã‚’æ¤œè¨¼
            self._validate_field_content(file_path, frontmatter)

            # ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã‚’æ¤œè¨¼
            self._validate_file_structure(file_path, content)

            print(f"  âœ… {file_path.name} is valid")

        except Exception as e:
            self.errors.append(ValidationError(
                str(file_path.relative_to(self.base_dir)),
                f"Error during validation: {str(e)}",
                "error"
            ))

    def _extract_frontmatter(self, content: str) -> Tuple[Optional[Dict], str]:
        """YAML ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’æŠ½å‡º"""
        # ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã¯ ---ã§å›²ã¾ã‚ŒãŸæœ€åˆã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        pattern = r'^---\s*\n(.*?)\n---\s*\n'
        match = re.match(pattern, content, re.DOTALL)

        if not match:
            return None, content

        yaml_text = match.group(1)
        body = content[match.end():]

        try:
            frontmatter = yaml.safe_load(yaml_text)
            return frontmatter, body
        except yaml.YAMLError as e:
            raise ValueError(f"Invalid YAML frontmatter: {str(e)}")

    def _validate_required_fields(self, file_path: Path, frontmatter: Dict) -> None:
        """å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ã‚’æ¤œè¨¼"""
        missing_fields = [
            field for field in self.REQUIRED_FIELDS
            if field not in frontmatter
        ]

        if missing_fields:
            self.errors.append(ValidationError(
                str(file_path.relative_to(self.base_dir)),
                f"Missing required fields: {', '.join(missing_fields)}",
                "error"
            ))

    def _validate_field_types(self, file_path: Path, frontmatter: Dict) -> None:
        """ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å‹ã‚’æ¤œè¨¼"""
        for field, expected_types in self.FIELD_TYPES.items():
            if field in frontmatter:
                value = frontmatter[field]
                if not isinstance(value, expected_types):
                    self.errors.append(ValidationError(
                        str(file_path.relative_to(self.base_dir)),
                        f"Field '{field}' has invalid type. "
                        f"Expected {expected_types}, got {type(value).__name__}",
                        "error"
                    ))

    def _validate_field_content(self, file_path: Path, frontmatter: Dict) -> None:
        """ãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼å†…å®¹ã®æ¤œè¨¼"""
        # trigger_keywords ãŒç©ºã§ãªã„ã‹ç¢ºèª
        if 'trigger_keywords' in frontmatter:
            keywords = frontmatter['trigger_keywords']
            if isinstance(keywords, list):
                if len(keywords) == 0:
                    self.warnings.append(ValidationError(
                        str(file_path.relative_to(self.base_dir)),
                        "trigger_keywords is empty (should contain at least one keyword)",
                        "warning"
                    ))
                else:
                    # å„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒæ–‡å­—åˆ—ã‹ç¢ºèª
                    for i, kw in enumerate(keywords):
                        if not isinstance(kw, str):
                            self.errors.append(ValidationError(
                                str(file_path.relative_to(self.base_dir)),
                                f"trigger_keywords[{i}] is not a string: {kw}",
                                "error"
                            ))

        # stage ãŒæœ‰åŠ¹ãªå€¤ã‹ç¢ºèª
        if 'stage' in frontmatter:
            stage = frontmatter['stage']
            valid_stages = [
                'Phase1', 'Phase2', 'Phase3', 'Phase4',
                'planning', 'discovery', 'research',
                'Phase1ï¼ˆéœ€è¦ç™ºè¦‹ï¼‰', 'Phase2ï¼ˆCPFæ¤œè¨¼ï¼‰',
                'Phase3ï¼ˆPSFæ¤œè¨¼ï¼‰', 'Phase4ï¼ˆå®Ÿè£…ï¼‰'
            ]
            if stage not in valid_stages:
                self.warnings.append(ValidationError(
                    str(file_path.relative_to(self.base_dir)),
                    f"stage '{stage}' may not be in standard format. "
                    f"Common values: {', '.join(valid_stages)}",
                    "warning"
                ))

        # output_file ãƒ‘ã‚¹ã®æ¤œè¨¼
        if 'output_file' in frontmatter:
            output_file = frontmatter['output_file']
            # å…¨è§’æ‹¬å¼§ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã‹ç¢ºèª
            if '(AIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ)' in output_file:
                self.errors.append(ValidationError(
                    str(file_path.relative_to(self.base_dir)),
                    "output_file contains half-width parentheses. "
                    "Use full-width: ï¼ˆAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼‰",
                    "error"
                ))

        # dependencies ãŒæœ‰åŠ¹ã‹ç¢ºèª
        if 'dependencies' in frontmatter:
            deps = frontmatter['dependencies']
            if isinstance(deps, list):
                for i, dep in enumerate(deps):
                    if not isinstance(dep, str):
                        self.errors.append(ValidationError(
                            str(file_path.relative_to(self.base_dir)),
                            f"dependencies[{i}] is not a string: {dep}",
                            "error"
                        ))

    def _validate_file_structure(self, file_path: Path, content: str) -> None:
        """ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã‚’æ¤œè¨¼"""
        # Markdownè¦‹å‡ºã—ã®ç¢ºèª
        has_title = re.search(r'^#\s+', content, re.MULTILINE)
        if not has_title:
            self.warnings.append(ValidationError(
                str(file_path.relative_to(self.base_dir)),
                "No H1 heading (# Title) found in content",
                "warning"
            ))

        # ã‚³ãƒ¼ãƒ‰ä¾‹ã‚„èª¬æ˜ã®æœ‰ç„¡ã‚’ç¢ºèª
        has_content = len(content.strip()) > 100
        if not has_content:
            self.warnings.append(ValidationError(
                str(file_path.relative_to(self.base_dir)),
                "Content is very short (< 100 characters)",
                "warning"
            ))

    def _check_for_recruit_remnants(self) -> None:
        """ForRecruitæ®‹éª¸ã‚’ãƒã‚§ãƒƒã‚¯"""
        pattern = re.compile(r'ForRecruit', re.IGNORECASE)

        for md_file in self.skills_dir.glob('**/*.md'):
            content = md_file.read_text(encoding='utf-8')
            matches = pattern.finditer(content)

            for match in matches:
                # ã‚¹ã‚­ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®å ´åˆã¯è­¦å‘Š
                if '_analysis' not in str(md_file) and 'PHASE' not in str(md_file):
                    self.warnings.append(ValidationError(
                        str(md_file.relative_to(self.base_dir)),
                        f"ForRecruit reference found: {match.group()}",
                        "warning"
                    ))

    def _generate_report(self) -> None:
        """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        summary = {
            'total_files': len(list(self.skills_dir.glob('**/SKILL.md'))),
            'valid_files': len(list(self.skills_dir.glob('**/SKILL.md'))) - len(self.errors),
            'invalid_files': len(self.errors),
            'total_issues': len(self.errors) + len(self.warnings),
        }

        report = {
            'timestamp': datetime.now().isoformat(),
            'errors': [asdict(e) for e in self.errors],
            'warnings': [asdict(w) for w in self.warnings],
            'summary': summary,
        }

        # JSON ãƒ¬ãƒãƒ¼ãƒˆã‚’å‡ºåŠ›
        with open('validation_report.json', 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
        print("\n" + "=" * 80)
        print("VALIDATION REPORT")
        print("=" * 80)

        if self.errors:
            print(f"\nâŒ Errors ({len(self.errors)}):")
            for error in self.errors:
                print(f"  {error.file}")
                print(f"    â†’ {error.message}")

        if self.warnings:
            print(f"\nâš ï¸  Warnings ({len(self.warnings)}):")
            for warning in self.warnings:
                print(f"  {warning.file}")
                print(f"    â†’ {warning.message}")

        print(f"\nğŸ“Š Summary:")
        print(f"  Total files: {summary['total_files']}")
        print(f"  Valid files: {summary['valid_files']}")
        print(f"  Invalid files: {summary['invalid_files']}")
        print(f"  Total issues: {summary['total_issues']}")

        if not self.errors:
            print("\nâœ… All validations passed!")
        else:
            print("\nâŒ Validation failed!")

        print("=" * 80)


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    validator = SkillValidator(base_dir='.')
    success = validator.validate_all()

    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
